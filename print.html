<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>408详细内容</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="408_note/数据结构/0_408数据结构内容概览.html"><strong aria-hidden="true">1.</strong> 数据结构</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="408_note/数据结构/CH01-绪论.html"><strong aria-hidden="true">1.1.</strong> CH01-绪论</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH02-线性表.html"><strong aria-hidden="true">1.2.</strong> CH02-线性表</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH03-栈_队列_数组.html"><strong aria-hidden="true">1.3.</strong> CH03-栈_队列_数组</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH04-串.html"><strong aria-hidden="true">1.4.</strong> CH04-串</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH05-树与二叉树.html"><strong aria-hidden="true">1.5.</strong> CH05-树与二叉树</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH06-图.html"><strong aria-hidden="true">1.6.</strong> CH06-图</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH07-查找.html"><strong aria-hidden="true">1.7.</strong> CH07-查找</a></li><li class="chapter-item expanded "><a href="408_note/数据结构/CH08-排序.html"><strong aria-hidden="true">1.8.</strong> CH08-排序</a></li></ol></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/0_408组成原理概览.html"><strong aria-hidden="true">2.</strong> 计算机组成原理</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH01-计算机系统概述.html"><strong aria-hidden="true">2.1.</strong> CH01-计算机系统概述</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH02-数据的表示和运算.html"><strong aria-hidden="true">2.2.</strong> CH02-数据的表示和运算</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH03-存储器.html"><strong aria-hidden="true">2.3.</strong> CH03-存储器</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH04-指令系统.html"><strong aria-hidden="true">2.4.</strong> CH04-指令系统</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH05-中央处理器.html"><strong aria-hidden="true">2.5.</strong> CH05-中央处理器</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH06-总线.html"><strong aria-hidden="true">2.6.</strong> CH06-总线</a></li><li class="chapter-item expanded "><a href="408_note/计算机组成原理/CH07-IO系统.html"><strong aria-hidden="true">2.7.</strong> CH07-IO系统</a></li></ol></li><li class="chapter-item expanded "><a href="408_note/操作系统/0_408操作系统概览.html"><strong aria-hidden="true">3.</strong> 操作系统</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="408_note/操作系统/CH01-操作系统概述.html"><strong aria-hidden="true">3.1.</strong> CH01-操作系统概述</a></li><li class="chapter-item expanded "><a href="408_note/操作系统/CH02-进程管理.html"><strong aria-hidden="true">3.2.</strong> CH02-进程管理</a></li><li class="chapter-item expanded "><a href="408_note/操作系统/CH03-内存管理.html"><strong aria-hidden="true">3.3.</strong> CH03-内存管理</a></li><li class="chapter-item expanded "><a href="408_note/操作系统/CH04-文件管理.html"><strong aria-hidden="true">3.4.</strong> CH04-文件管理</a></li><li class="chapter-item expanded "><a href="408_note/操作系统/CH05-IO系统.html"><strong aria-hidden="true">3.5.</strong> CH05-IO系统</a></li></ol></li><li class="chapter-item expanded "><a href="408_note/计算机网络/0_408计算机网络概述.html"><strong aria-hidden="true">4.</strong> 计算机网络</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="408_note/计算机网络/CH01-计算机网络体系结构.html"><strong aria-hidden="true">4.1.</strong> CH01-计算机网络体系结构</a></li><li class="chapter-item expanded "><a href="408_note/计算机网络/CH02-物理层.html"><strong aria-hidden="true">4.2.</strong> CH02-物理层</a></li><li class="chapter-item expanded "><a href="408_note/计算机网络/CH03-链路层.html"><strong aria-hidden="true">4.3.</strong> CH03-链路层</a></li><li class="chapter-item expanded "><a href="408_note/计算机网络/CH04-网络层.html"><strong aria-hidden="true">4.4.</strong> CH04-网络层</a></li><li class="chapter-item expanded "><a href="408_note/计算机网络/CH05-运输层.html"><strong aria-hidden="true">4.5.</strong> CH05-运输层</a></li><li class="chapter-item expanded "><a href="408_note/计算机网络/CH06-应用层.html"><strong aria-hidden="true">4.6.</strong> CH06-应用层</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">408详细内容</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p>排序算法：选择题为重，性能比较</p>
<p>查找算法：考察重点，各种处理方法和性能分析</p>
<p>图：难度较大，主要掌握基本思想和实现步骤，深度优先搜索和广度有限搜索为重。</p>
<p>树和二叉树：考察重点。多以选择题形式，但会设计树遍历相关算法题。</p>
<p>串：字符串模式匹配，KMP匹配算法的原理及next数组的推理过程。</p>
<p>栈、队列和数组：通常以选择题形式考察，由于是线性表的扩展，也容易出现在算法题中。</p>
<p>线性表：算法题的重点，要求具有最有的性能（时间复杂度、空间复杂度）</p>
<h2 id="答题策略"><a class="header" href="#答题策略">答题策略</a></h2>
<p>算法题：直接暴力解，13分能够得到10分左右</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="数据结构的概念"><a class="header" href="#数据结构的概念">数据结构的概念</a></h2>
<h2 id="算法和算法评价"><a class="header" href="#算法和算法评价">算法和算法评价</a></h2>
<p>重点注意算法的时间复杂度的计算。需要注意其规范的推导过程：</p>
<ul>
<li>循环主体中的变量参与循环条件的判断：找出主体语句中与T(n)成正比的循环变量，将其代入条件中计算</li>
<li>循环主体中的变量与循环条件无关：采用数学归纳法或直接累计循环次数。多层循环从内向外分析，忽略单步、条件判断语句。递归程序使用公式进行递推。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="线性表的定义和基本操作"><a class="header" href="#线性表的定义和基本操作">线性表的定义和基本操作</a></h2>
<h3 id="定义"><a class="header" href="#定义">定义</a></h3>
<p>线性表是具有相同数据类型的n个数据元素的有限序列，其中n为表长，当n=0时线性表是一个空表。</p>
<p>特点：</p>
<ul>
<li>表中元素个数有限</li>
<li>表中元素有逻辑上的顺序</li>
<li>表中元素都是数据元素</li>
<li>表中数据类型都相同，即每个元素占有相同存储空间</li>
</ul>
<h3 id="基本操作"><a class="header" href="#基本操作">基本操作</a></h3>
<p>基本操作的实现取决于采用哪种存储结构。</p>
<ul>
<li>初始化表</li>
<li>求表长</li>
<li>按值查找操作</li>
<li>按位查找操作</li>
<li>插入操作</li>
<li>删除操作</li>
<li>输出操作</li>
<li>判空操作</li>
<li>销毁操作，销毁线性表，释放所占用的内存</li>
</ul>
<h2 id="线性表的顺序表示"><a class="header" href="#线性表的顺序表示">线性表的顺序表示</a></h2>
<h3 id="顺序表"><a class="header" href="#顺序表">顺序表</a></h3>
<p>用一组<strong>地址连续</strong>的存储单元依次存储线性表中的数据元素，使得逻辑上相邻的两个元素在物理位置上也相邻。</p>
<p>线性表中元素的位序从1开始，而数组的元素下标是从0开始的。</p>
<p>线性表中的任一元素都可以<strong>随机存取</strong>。</p>
<pre><code class="language-c">//顺序表的静态分配
#define MaxSize 50	//线性表的最大长度
typedef struct {
    ElemType data[MaxSize];	//顺序表的元素
    int length;				//顺序表的当前长度
}SqList;	//顺序表的类型定义
</code></pre>
<p>通过动态存储分配语句可以动态分配数组。</p>
<pre><code class="language-c">//顺序表的动态分配
#define InitSize 100	//表长度的初始定义
typedef struct {
    ElemType *data;
    int MaxSize, length;
}SeqList;	//动态分配数组顺序表的类型定义
</code></pre>
<h3 id="顺序表上的基本操作"><a class="header" href="#顺序表上的基本操作">顺序表上的基本操作</a></h3>
<p><strong>插入操作</strong></p>
<pre><code class="language-c">bool ListInsert(SqList &amp;L, int i, ElemType e) {	//i为插入元素在线性表中的位置
    if (i &lt; 1 || i &gt; L.length + 1)
        return false;
    if (L.length &gt;= MaxSize)
        return false;
    for (int j = L.length; j &gt;= i; j--)
        L.data[j] = L.data[j - 1];
    L.data[i - 1] = e;
    L.length++;
    return true;
}
</code></pre>
<p>插入算法的平均时间复杂度为O(n)</p>
<p><strong>删除操作</strong></p>
<p>将删除元素后的所有元素前移一位；首先要判断要删除的位置是否合法；删除后使用引用变量e返回</p>
<pre><code class="language-c">bool ListDelete (SqList &amp;L, int i, ElemType &amp;e) {
    if (i &lt; 1 || i &gt; L.length)
        return false;
    e = L.data[i - 1];
    for (int j = i; j &lt; L.length; j++)
        L.data[j - 1] = L.data[j];
    L.length--;
    return true;
}
</code></pre>
<p>删除算法的平均时间复杂度为O(n)</p>
<p><strong>按值查找（顺序查找）</strong></p>
<p>如果找到该值，则返回该值的位序；否则查找失败，返回0</p>
<pre><code class="language-c">int LocataElem (SqList &amp;L, ElemType e) {
    for (int i = 0; i &lt; L.length; i++)
    {
        if (L.data[i] == e)
            return i + 1;
    }
    return 0;
}
</code></pre>
<p>顺序查找算法的平均时间复杂度为O(n)</p>
<h3 id="习题"><a class="header" href="#习题">习题</a></h3>
<ol start="2">
<li></li>
</ol>
<p>思路：将顺序表L的所有元素逆置并且空间复杂度为O(1)，则不能通过创建新的顺序表来实现。通过设置一个辅助变量，把L的前半部分的每一个元素(<code>L.data[i]</code>)依次与后半部分的对应元素(<code>L.data[n - i]</code>)进行交换，最终得到交换后的顺序表。</p>
<pre><code class="language-c">void SqList_invert(SqList &amp;L)
{
    int m = L.length / 2;	//顺序表长度的一半
    int n = L.length - 1;
    ElemType s;	//辅助变量s
    for (int i = 0; i &lt; m; i++)
    {//交换顺序表前后两部分的对应元素
        s = L.data[i];
        L.data[i] = L.data[n - i];
        L.data[n - i] = s;
    }
}
</code></pre>
<ol start="3">
<li></li>
</ol>
<p>思路：从头开始循环遍历顺序表的所有元素，使用k记录值为x的元素的个数，每循环遍历一次，就将当前元素根据k的值移动一次，向前移动k个位置。</p>
<pre><code class="language-c">bool Del_x(SqList &amp;L, Elemtype x)
{
    int k = 0;	//用k记录L中等于x元素的个数
    for (int i = 0; i &lt; L.length; i++)
    {//循环遍历整个顺序表
        if (L.data[i] == x)	
            k++;
        else
        	L.data[i - k] = L.data[i];	//将当前元素前移k个位置
    }
    L.length = L.length - k;	//修改表长
    return true;
}
</code></pre>
<ol start="6">
<li></li>
</ol>
<p>思路：顺序表是有序的，值相同的元素在位置上连续。用类似插入排序的思想，初始时将第一个元素看作非重复有序表，然后依次判断后面的元素是否与前面的非重复元素相等，若相等则继续向后判断；若不相等则将当前判断的元素插入非重复有序表的最后，直至判断到表尾。最后更新顺序表的长度。</p>
<pre><code class="language-c">bool Del_same(SqList &amp;L)
{
	if (L.length == 0)	//判断顺序表是否为空
        return false;
    int i, j;	//i用来指明非重复有序表的表尾，j用来指明当前判断的元素的位置
    for (i = 0, j = 1; j &lt; L.length; j++)
    {
        if (L.data[i] != L.data[j])
            L.data[++i] = L.data[j];
    }
    L.length = i + 1;	//修改表长
    return true;
}
</code></pre>
<ol start="7">
<li></li>
</ol>
<p>思路：创建一个新的顺序表，因为题中给出两个顺序表有序，所以按顺序取两表的表头进行比较，依次将较小的放入新的顺序表中，然后将有剩余表的剩下部分直接放入新的顺序表末尾。</p>
<pre><code class="language-c">bool New_SqList(SqList A, SqList B, SqList &amp;C)
{
    //首先判断A、B量表长度之和是否超过C允许的最大长度
    if (A.length + B.length &gt; C.maxSize)
        return false;
    int i = 0, j = 0, k = 0;	//i,j,k分别用来指明三个顺序表当前元素的位置，初始化为0
    for (;i &lt; A.length &amp;&amp; j &lt; B.length;)
    {
        if (A.data[i] &lt; B.data[j])
            C.data[k++] = A.data[i++];
        else
            C.data[k++] = B.data[j++];
    }
    if (i == A.length)
    {
        for (; j &lt; B.length; j++)
            C.data[k++] = B.data[j];
    }
    else
    {
        for (; i &lt; A.length; i++)
            C.data[k++] = A.data[i]
    }
    C.length = k;
    
    return true;
}
</code></pre>
<ol start="8">
<li></li>
</ol>
<p>思路：使用3次第2题中的逆置算法。首先将整个数组进行逆置，得到数组$(b_n, b_{n-1},...,b_1,a_m, a_{m-1},...,a_1)$，然后分别对b部分的数组和a部分的数组使用逆置算法即可得到最终结果。</p>
<ol start="9">
<li></li>
</ol>
<p>在元素递增的顺序表中最快地查找数值为x的元素。</p>
<h2 id="线性表的链式表示"><a class="header" href="#线性表的链式表示">线性表的链式表示</a></h2>
<p>链式存储<strong>不需要使用地址连续的存储单元</strong>，通过链建立起数据之间的逻辑关系，插入和删除操作不需要移动元素，只需要修改指针，单会失去顺序表可随机存取的优点。</p>
<h3 id="单链表"><a class="header" href="#单链表">单链表</a></h3>
<p>通过一组任意的存储单元来存储线性表中的数据元素。</p>
<pre><code class="language-c">typedef struct LNode {	//定义单链表结点类型
	ElemType data;	//数据域
	struct LNode *next;	//指针域
}LNode, *LinkList;
</code></pre>
<p>通常用<strong>头指针</strong>来<strong>标识一个单链表</strong>，如单链表L，<strong>头指针为NULL</strong>时表示一个<strong>空表</strong>。另外为了操作方便，在单链表第一个结点之前附加一个结点，称为<strong>头结点</strong>。头结点的数据域可以不设任何信息，也可以记录表长等信息。<strong>头结点的指针域</strong>指向<strong>线性表的第一个元素结点</strong>。</p>
<p>头结点和头指针的区分：<strong>不管带不带头结点，头指针都始终指向链表的第一个结点</strong>，而头结点是带头结点链表的第一个结点，结点内通常不存储信息。由此带来的好处是链表的<strong>第一个位置上的操作</strong>和在表的其他位置上的操作完全相同。</p>
<h3 id="单链表上的基本操作"><a class="header" href="#单链表上的基本操作">单链表上的基本操作</a></h3>
<p><strong>采用头插法建立单链表</strong></p>
<p>从一个空表开始，生成新结点，将读取的数据放入新结点的数据域中，然后将新结点放入当前链表的表头，即头结点之后。</p>
<pre><code class="language-c">LinkList List_HeadInsert(LinkList &amp;L) {
    LNode *s; int x;
}
</code></pre>
<p><strong>采用尾插法建立单链表</strong></p>
<p>采用这种方法时生成链表中结点的次序和输入数据的顺序一致。</p>
<p><strong>按序号查找结点值</strong></p>
<p>从第一个结点出发，顺指针next域逐个往下搜索，直到找到第i个结点为止。</p>
<p><strong>按值查找表结点</strong></p>
<p>从单链表第一个结点开始由前往后依次比较表中各结点数据域的值，找到则返回指针。</p>
<p><strong>插入结点操作</strong></p>
<p>检查插入位置的合法性，然后找到待插入位置的前驱结点，再在其后插入新结点。</p>
<p><strong>删除结点操作</strong></p>
<p>改变指针，然后释放内存。</p>
<p><strong>求表长操作</strong></p>
<p>设置一个计数变量，每访问一个结点，计数器加1.</p>
<h3 id="双链表"><a class="header" href="#双链表">双链表</a></h3>
<p>单链表如果要访问某个结点的前驱结点（插入、删除操作），只能从头开始遍历，时间复杂度为O(n)，访问后继结点的时间复杂度为O(1)。</p>
<p>双链表结点中有两个指针prior和next，分别<strong>指向其前驱结点和后继结点</strong>。</p>
<pre><code class="language-c">typedef struct DNode {
    ElemType data;
    struct DNode *prior, *next;
}DNode, *DLinkList;
</code></pre>
<p>双链表可以方便地找到其前驱结点，因此插入和删除操作的复杂度仅为O(1)。</p>
<p><strong>双链表的插入操作</strong></p>
<p><strong>双链表的删除操作</strong></p>
<h3 id="循环链表"><a class="header" href="#循环链表">循环链表</a></h3>
<p><strong>循环单链表</strong>
循环链表的<strong>最后一个结点</strong>的指针不是NULL，而是<strong>指向头结点</strong>，从而整个链表形成一个环。</p>
<p>循环单链表在任何一个位置的操作都是等价的，无须判断是否是表尾。</p>
<p>对于循环单链表一般<strong>不设头指针而仅设尾指针</strong>，使得操作效率更高。因为只设头指针时对表尾进行操作需要O(n)的时间复杂度，而若设的是尾指针r，r-&gt;next即为头指针，对表头和表尾进行操作都只需要O(1)的时间复杂度。</p>
<p><strong>循环双链表</strong></p>
<p>循环双链表的<strong>头结点的prior</strong>指针要指向<strong>表尾结点</strong>。</p>
<p>当循环双链表为空表时，其头结点的prior域和next域都等于L。</p>
<h3 id="静态链表"><a class="header" href="#静态链表">静态链表</a></h3>
<p>静态链表借助<strong>数组</strong>来描述线性表的链式存储结构，结点也有数据域data和指针域next，与前面链表的指针不同的是，这里的指针是结点的<strong>相对地址(数组下标)</strong>，又称游标。</p>
<pre><code class="language-c">#define MaxSize 50
typedef struct {
    ElemType data;
    int next;	//下一个元素的数组下标
} SLinkList[MaxSize];
</code></pre>
<p>静态链表以next==-1作为结束的标志。静态链表的插入、删除操作与动态链表相同，只需要修改指针，不需要移动元素。</p>
<h3 id="习题-1"><a class="header" href="#习题-1">习题</a></h3>
<ol>
<li></li>
</ol>
<p>思路：每次递归都对下一个结点的值进行判断，若值为x则将该节点</p>
<pre><code class="language-c">void Del_x_recur(LinkList &amp;L, ElemType x) {
    LNode *p;	//p指向待删除结点
    if (L == NULL)	return;	//递归的出口
    if (L-&gt;data == x) {
        p = L;	//删除*L，并让L指向下一个结点
        L = L-&gt;next;
        free(p);
        Del_x_recur(L, x);	//递归调用
    }
    else
        Del_x_recur(L-&gt;next, x);	//递归调用
}
</code></pre>
<ol start="2">
<li></li>
</ol>
<p>思路：使用p和pre两个指针来控制，p指向当前扫描的结点，pre指向p的前一个结点。依次扫描单链表，当p指向结点的值为x时，使用一个新指针q指向该结点，将p后移(<code>p=p-&gt;next</code>)，然后将pre指向p，最后释放*q结点的内存；当p指向结点的值不是x时，将p和pre同时后移一位，然后继续判断。当p为NULL时结束扫描。</p>
<pre><code class="language-c">void Del_x(LinkList &amp;L, ElemType x) {
	LNode *p = L-&gt;next, *pre = L, *q;
	while (p != NULL)
	{
		if (p-&gt;data == x)
		{
			q = p;	//q指向该值为x的结点
			p = p-&gt;next;
			pre-&gt;next = p;
			free(q);	//释放内存
		}	
		else	//当p指向的结点值不是x时
		{
			p = p-&gt;next;
			pre = pre-&gt;next;
		}
	}
}
</code></pre>
<ol start="3">
<li></li>
</ol>
<p>之后可以使用第3章栈的思想来直接解决。这里使用递归的方法来解决。每访问一个结点，先递归打印出去其之后的结点，然后再输出自身结点。</p>
<pre><code class="language-c">void Reverse_print(LinkList &amp;L) {
	if (L-&gt;next != NULL)
	{
		Reverse_print(L-&gt;next);
	}
	if (L != NULL)	print(L-&gt;data);
}
</code></pre>
<ol start="4">
<li></li>
</ol>
<p>思路：用p从头到尾扫描单链表，*pre指向p结点的前驱，用minp保存最小值的结点，用minpre保存最小值结点的前驱结点。当p-&gt;data小于minp-&gt;data时，将p、pre赋给minp和minpre。扫描完毕后，minp指向最小值结点，minpre指向最小值结点的前驱结点，删除最小值结点并释放内存即可。</p>
<pre><code class="language-c">LinkList Del_min(LinkList &amp;L)
{
	LNode *p = L-&gt;next, *pre = L;
    LNode *minp = p, *minpre = pre;
    while (p != NULL)
    {
        if (p-&gt;data &lt; minp-&gt;data)	//判断当前结点的值和当最小值的大小关系
        {
            minp = p;
            minpre = pre;
            pre = p;
            p = p-&gt;next;
        }
        else
        {
            pre = p;
            p = p-&gt;next;
        }
    }
    minpre-&gt;next = minp-&gt;next;	//删除最小值结点
    free(minp);
    
    return L;
}
</code></pre>
<ol start="5">
<li></li>
</ol>
<p>思路：使用递归方法来实现，判断当前结点的下一个是否为空，如不为空则递归调用至下一个结点继续判断，当结点为空时到达尾结点，依次将每个尾结点指向头结点。</p>
<pre><code class="language-c">LNode *p = L-&gt;next;
void Reverse_List(LinkList &amp;L)
{
    if (L-&gt;next != NULL)
    {
        Reverse_List(L-&gt;next);
    }
    if (L != NULL)
    {
        p = L;
        p = p-&gt;next;
    }
}
</code></pre>
<ol start="22">
<li></li>
</ol>
<pre><code class="language-c"></code></pre>
<ol start="23">
<li></li>
</ol>
<pre><code class="language-c">typedef struct node {
    int data;
    struct node *next;
}NODE;

void delete_list(NODE *head, int n)
{
    int num[n+1];	//辅助数组num
    num = (int *)malloc(sizeof(int) * (n+1));	//分配内存
    for (int i = 0; i &lt; n+1; i++)	//将num数组初始化为全0
        num[i] = 0;
    
	NODE p = head-&gt;next;
    NODE r;
    while (p != NULL)	//遍历整个链表，依次进行判断和删除
    {
        int m = p-&gt;data&gt;0 ? p-&gt;data : -p-&gt;data;		//判断数值的正负，若为负则将其变为正数后判断
        if (num[m] == 0)
        {
            num[m] = 1;
        	p = p-&gt;next;
        }
        else
        {
            r = p;
            p = r-&gt;next;
            free(r);
        }
    } 
    free(num);	//释放辅助数组占据的空间
}
</code></pre>
<p>该算法的时间复杂度为O(m)，空间复杂度为O(n)</p>
<ol start="25">
<li></li>
</ol>
<pre><code class="language-c">void change_list(NODE *h)	//h为头结点
{
    //首先来查找链表的中点，可以通过设置两个指针，一个每次走一步，另一个每次走两步，直到第二个的后继结点为NULL，则第一个指针指向的结点就是中点
    NODE *p, *q, *r, *s;
    p = q = h;
    while (q-&gt;next != NULL)
    {
        p = p-&gt;next;
        q = q-&gt;next;
        if (q-&gt;next != NULL)	q = q-&gt;next;
    }
    q = p-&gt;next;	//把q指向第二段的第一个元素
    //进行原地逆置操作。具体方法为：从第一个结点开始，使用头插法再次插入链表
    p-&gt;next = NULL;
    while (q != NULL)
    {
        r = q-&gt;next;	//r用来保存下一个结点
        q-&gt;next = p-&gt;next;	//插入开头
        q = r;
    }
    //将后半段的元素依次间隔地插入前半段
    s = h-&gt;next;	//s指向前半段的第一个数据结点
    q = p-&gt;next;	//q指向后半段的第一个数据结点
    p-&gt;next = NULL;	
    while (q != NULL)	//将链表的后半段插入前半段的指定位置
    {
        r = q-&gt;next;	//r指向后半段的下一个结点
        s-&gt;next = q;	//插入
        s = q-&gt;next;	//s指向下一个插入位置
        q = r;
    }
}
</code></pre>
<p>时间复杂度为O(n)</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="栈"><a class="header" href="#栈">栈</a></h2>
<h3 id="基本概念"><a class="header" href="#基本概念">基本概念</a></h3>
<p><strong>定义</strong></p>
<p>栈（stack）是只允许在一端插入或删除操作的线性表。</p>
<ul>
<li>栈顶：允许进行插入删除的那一端</li>
<li>栈底：不允许进行插入删除操作的另一端，是固定的</li>
</ul>
<p>栈的特性可以概括为<strong>后进先出</strong></p>
<p><strong>栈的基本操作</strong></p>
<ul>
<li><code>InitStack(&amp;S)</code>：初始化一个空栈S</li>
<li><code>StackEmpty(S)</code>：判断一个栈是否为空</li>
<li><code>Push(&amp;S, x)</code>：进栈，若栈S未满，将x加入使之称为新栈顶</li>
<li><code>Pop(&amp;S, &amp;x)</code>：出栈，若栈S非空，则弹出栈顶元素，用x返回</li>
<li><code>GetTop(S, &amp;x)</code>：读栈顶元素</li>
<li><code>DestroyStack(&amp;S)</code>：销毁栈S，并释放其占用的内存</li>
</ul>
<p>解答算法题时，一般可以直接使用这些基本函数。</p>
<h3 id="顺序存储结构"><a class="header" href="#顺序存储结构">顺序存储结构</a></h3>
<p><strong>顺序栈的实现</strong></p>
<p>利用一组地址连续的存储单元存放<strong>自栈底到栈顶</strong>的数据元素，同时附设一个指针(top)指示当前栈顶元素。</p>
<pre><code class="language-c">#define MaxSize 50	//定义栈中最大元素个数
typedef struct{
	Elemtype data[MaxSize];	//存放栈中元素
	int top;	//栈顶指针
} SqStack;
</code></pre>
<ul>
<li>栈顶指针：<strong>S.top</strong>，初始时设置为-1；栈顶元素：<code>S.data[S.top]</code></li>
<li>进栈操作：栈不满时，栈顶指针先加1，再送值到栈顶元素</li>
<li>出栈操作：栈非空时，先取栈顶元素值，再将栈顶指针减去1</li>
<li>栈空条件：<code>S.top=-1</code>；栈满条件：<code>S.top=MaxSize-1</code>；栈长：<code>S.top+1</code></li>
</ul>
<p>顺序栈的入栈操作收到数组上界的约束，要注意可能发生的栈溢出。</p>
<p><strong>顺序栈的基本运算</strong></p>
<ul>
<li>初始化</li>
</ul>
<pre><code class="language-c">void InitStack(SqStack &amp;S){
	S.top = -1;
}
</code></pre>
<ul>
<li>判断栈空</li>
</ul>
<pre><code class="language-c">bool StackEmpty(SqStack S){
	if (S.top == -1)
		return true;
	else
		return false;
}
</code></pre>
<ul>
<li>进栈</li>
</ul>
<pre><code class="language-c">bool Push(SqStack &amp;S, ElemType x){
	if (S.top == MaxSize - 1)
		return false;
	S.data[++S.top] = x;
	return true;
}
</code></pre>
<ul>
<li>出栈</li>
</ul>
<pre><code class="language-c">bool Pop(SqStack &amp;S, ElemType &amp;x){
	if (S.top == -1)
		return false;
	x = S.data[S.top--];	//先出栈，指针再减1
	return true;
}
</code></pre>
<ul>
<li>读栈顶元素</li>
</ul>
<pre><code class="language-c">bool GetTop (SqStack S, ElemType &amp;x) {
    if (S.top = -1)
        return false;
    x = S.data[S.top];	//取栈顶元素
    return true;
}
</code></pre>
<p><strong>共享栈</strong></p>
<p>利用栈底位置相对不变的特定，可以让两个顺序栈共享一个一维数组空间，将两个栈的栈底分别设置在共享空间的两端，两个栈顶向空间的中间延申。</p>
<h3 id="链式存储结构"><a class="header" href="#链式存储结构">链式存储结构</a></h3>
<p>链栈的优点是便于<strong>多个栈共享存储空间和提高其效率</strong>，且不存在栈满上溢的情况。通常采用单链表来实现，并且规定所有操作在单链表的<strong>表头</strong>完成。</p>
<p>这里规定链栈没有头结点，Lhead指向栈顶元素。</p>
<pre><code class="language-c">typedef struct Linknode{
	ElemType data;			//数据域
	struct Linknode *next;	//指针域
} *LiStack;		//栈类型定义
</code></pre>
<p>链栈操作与链表类似，入栈和出栈操作都在表头进行。</p>
<h2 id="队列"><a class="header" href="#队列">队列</a></h2>
<h3 id="基本概念-1"><a class="header" href="#基本概念-1">基本概念</a></h3>
<p><strong>定义</strong></p>
<p>也是一种受限的线性表，只允许在<strong>表的一端进行插入</strong>，而在<strong>另一端进行删除</strong>。向队列中插入元素称为<strong>入队</strong>，删除元素称为<strong>出队</strong>。操作特性是<strong>先进先出</strong>。</p>
<p><strong>基本操作</strong></p>
<ul>
<li><code>InitQueue(&amp;Q)</code>：初始化队列，构造一个空队列</li>
<li><code>QueueEmpty(Q)</code>：判断队列是否为空</li>
<li><code>EnQueue(&amp;Q, x)</code>：入队，若队列未满，将x加入，使之称为新队列</li>
<li><code>DeQueue(&amp;Q, &amp;x)</code>：出队，若队列非空，删除队头元素并用x返回</li>
<li><code>GetHead(Q, &amp;x)</code>：读队头元素，若队列Q非空，则将队头元素赋值给x</li>
</ul>
<h3 id="顺序存储结构-1"><a class="header" href="#顺序存储结构-1">顺序存储结构</a></h3>
<p><strong>队列的顺序存储</strong></p>
<p>分配一块连续的存储单元存放队列中的元素，并附设两个指针：</p>
<ul>
<li>队头指针front：指向队头元素</li>
<li>队尾指针rear：指向队尾元素的下一个位置</li>
</ul>
<p>（不同教材对front和rear的定义可能不一样）</p>
<pre><code class="language-c">#define MaxSize 50
typedef struct{
	ElemType data[MaxSize];	//存放队列元素
	int front, rear;	//两个指针
} SqQueue;
</code></pre>
<p>初始状态（队空条件）：<code>Q.front == Q.rear == 0</code></p>
<p>进队操作：队不满时，先送值到队尾元素，再将队尾指针加一</p>
<p>出队操作：队不空时，先取队头元素，再将队头指针加一</p>
<p>不能用<code>Q.rear==MaxSize</code>作为队列满的条件。当队列中正好有一个元素并且放在队尾所在的存储单元时，这时为上溢出，但并不是真正的溢出。</p>
<p><strong>循环队列</strong></p>
<p>把存储队列元素的表从逻辑上视为一个环，称为循环队列。当队首指针<code>Q.front=MaxSize-1</code>后，再前进一个位置就自动到0，这可以用除法取余运算(%)实现。</p>
<ul>
<li>
<p>初始时：<code>Q.front=Q.rear=0</code></p>
</li>
<li>
<p>队首指针进1：<code>Q.front=(Q.front+1)%MaxSize</code></p>
</li>
<li>
<p>队尾指针进1：<code>Q.rear=(Q.rear+1)%MaxSize</code></p>
</li>
<li>
<p>队列长度：<code>(Q.rear+MaxSize-Q.front)%MaxSize</code></p>
</li>
<li>
<p>出队入队时：指针按顺时针发方向进1</p>
</li>
</ul>
<p>区分队空队满的方法：</p>
<ul>
<li>牺牲一个存储单元来区分队空和队满，入队时少用一个队列单元。约定以队头指针在队尾指针的下一个位置作为队满的标志。
<ul>
<li>队满条件：(Q.rear+1)%MaxSize==Q.front</li>
<li>队空条件：Q.front=Q.rear</li>
<li>队列中元素个数：(Q.rear+MaxSize-Q.front)%MaxSize</li>
</ul>
</li>
<li>类型中增设表示元素个数的数据成员size，这样空队条件：Q.size==0；队满条件：Q.size==MaxSize</li>
<li>类型中增设tag数据成员，来区分是队满还是队空。</li>
</ul>
<p><strong>循环队列的操作</strong></p>
<ul>
<li>初始化：</li>
</ul>
<pre><code class="language-c">void InitQueue(SqQueue &amp;Q){
	Q.rear=Q.front=0;
}
</code></pre>
<ul>
<li>判断队空</li>
</ul>
<pre><code class="language-c">bool isEmpty(SqQueue Q){
	if(Q.rear==Q.front)		return true;
	else return false;
}
</code></pre>
<ul>
<li>入队</li>
</ul>
<pre><code class="language-c">bool EnQueue(SqQueue &amp;Q, ElemType x){
	if((Q.rear+1)%MaxSize==Q.front)		return false;	//队满则报错
	Q.data[Q.rear]=x;
	Q.rear = (Q.rear+1)%MaxSize;	//队尾指针加一取模
	return true;
}
</code></pre>
<ul>
<li>出队</li>
</ul>
<pre><code class="language-c">bool DeQueue(SqQueue &amp;Q, ElemType &amp;x){
	if (Q.rear == Q.front)	return false;
	x = Q.data[Q.front];
	Q.front = (Q.front + 1) % MaxSize;
	return true;
}
</code></pre>
<h3 id="链式存储结构-1"><a class="header" href="#链式存储结构-1">链式存储结构</a></h3>
<p><strong>队列的链式存储</strong></p>
<p>链队列；是一个同时带有队头指针和队尾指针的单链表。头指针指向队头结点，尾指针指向队尾结点，即单链表的最后一个结点（与顺序存储不同）。</p>
<pre><code class="language-c">typedef struct{		//链式队列结点
	ElemType data;
	struct LinkNode *next;
} LinkNode;
typedef struct{		//链式队列
	LinkNode *front, *rear;	//队头和队尾指针
} LinkQueue;
</code></pre>
<p>当Q.front==NULL且Q.rear==NULL时，链式队列为空。</p>
<p>链式队列通常都设计为<strong>带头结点</strong>的单链表。这样插入和删除操作就统一了。</p>
<p>用单链表表示的链式队列适合于数据元素变动比较大的情形，而且不存在队列满且产生溢出的问题。</p>
<p><strong>链式队列的基本操作</strong></p>
<p>初始化、判空队、入队、出队。</p>
<h3 id="双端队列"><a class="header" href="#双端队列">双端队列</a></h3>
<p>允许<strong>两端</strong>都可以进行<strong>入队和出队操作</strong>的队列。元素的逻辑结构仍是线性的，将队列的两端分别称为前端和后端，两端都可以入队和出队。</p>
<ul>
<li>
<p>输出受限的双端队列：允许在一端进行插入和删除，另一端只允许插入的双端队列。</p>
</li>
<li>
<p>输入受限的双端队列：允许在一端进行插入和删除，另一端只允许删除的双端队列。</p>
</li>
</ul>
<h2 id="栈和队列的应用"><a class="header" href="#栈和队列的应用">栈和队列的应用</a></h2>
<h3 id="栈在括号匹配中的应用"><a class="header" href="#栈在括号匹配中的应用">栈在括号匹配中的应用</a></h3>
<p>表达式中有圆括号和方括号，有着任意的嵌套顺序，([]())为正确的格式，[(])为不正确的格式。</p>
<p>使用栈的思想来匹配表达式中的括号：</p>
<ul>
<li>初始设置一个空栈，顺序读入括号</li>
<li>若是右括号，则或者使其置于栈顶的最急迫期待得以消解，或是不合法的情况</li>
<li>若是左括号，则作为一个新的更急迫的期待压入栈中，自然使得原有的在栈中所有未消解的期待的急迫性降了一级。算法结束时，栈为空，否则括号序列不匹配。</li>
</ul>
<h3 id="栈在表达式求值中的应用"><a class="header" href="#栈在表达式求值中的应用">栈在表达式求值中的应用</a></h3>
<p>中缀表达式不仅以来运算符的优先级，还要处理括号。后缀表达式的运算符在操作数的后面，后缀表达式中已经考虑了运算符的优先级，没有括号，只有操作数和运算符。</p>
<p><strong>中缀表达式转化为后缀表达式</strong>的过程：</p>
<p>从左向右开始扫描中缀表达式；</p>
<p>遇到数字时，加入后缀表达式；</p>
<p>遇到运算符时：</p>
<ul>
<li>若为<code>(</code>，入栈</li>
<li>若为<code>)</code>，则依次把栈中的运算符加入后缀表达式，直到出现<code>(</code>，从栈中删除<code>(</code>；</li>
<li>若为除括号外的其他运算符，当其优先级高于除<code>(</code>外的栈顶运算符时，直接入栈；否则从栈顶开始，依次弹出比当前处理的运算符优先级高和优先级相等的运算符，直到一个比它优先级低的，或遇到了一个左括号为止。</li>
</ul>
<p>当扫描的中缀表达式结束时，栈中的所有运算符依次出栈加入后缀表达式。</p>
<p>优先级表：</p>
<table><thead><tr><th align="center">(</th><th align="center">*, /</th><th align="center">+， -</th><th align="center">)</th></tr></thead><tbody>
<tr><td align="center">1</td><td align="center">5</td><td align="center">3</td><td align="center">6</td></tr>
</tbody></table>
<p>通过后缀表达式计算值的过程：顺序扫描表达式的每一项，根据其类型做如下操作：若该项是操作数，则压入栈中；若该项是操作符&lt;op&gt;，则连续从栈中退出两个操作数Y和X，形成运算指令X&lt;op&gt;Y，然后将计算结果重新压入栈中。所有项都扫描完后，栈顶存放的就是最终的结果。</p>
<h3 id="栈在递归中的应用"><a class="header" href="#栈在递归中的应用">栈在递归中的应用</a></h3>
<p>递归：在一个函数、过程或数据结构的定义中又应用了它自身，则这个函数、过程或数据结构称为是递归定义的。</p>
<p>递归调用过程中，系统为每一层的<strong>返回点、局部变量、传入实参</strong>等开辟了递归工作栈来进行数据存储，递归次数过多容易造成栈溢出。</p>
<h3 id="队列在层次遍历中的应用"><a class="header" href="#队列在层次遍历中的应用">队列在层次遍历中的应用</a></h3>
<p>使用栈来层次遍历二叉树：</p>
<ul>
<li>根结点入队；</li>
<li>若队空，则结束遍历；否则重复下一步的操作；</li>
<li>队列中的第一个结点出队，并访问之。若其有左孩子，则将左孩子入队；若其有右孩子，则将右孩子入队，返回上一步。</li>
</ul>
<h3 id="队列在计算机系统中的应用"><a class="header" href="#队列在计算机系统中的应用">队列在计算机系统中的应用</a></h3>
<ul>
<li>解决主机与外部设备之间速度不匹配的问题，例如打印机的数据缓冲区。</li>
<li>解决由多用户引起的资源竞争问题</li>
</ul>
<h2 id="数组和特殊矩阵"><a class="header" href="#数组和特殊矩阵">数组和特殊矩阵</a></h2>
<h3 id="数组定义"><a class="header" href="#数组定义">数组定义</a></h3>
<p>数组是由n个相同类型的数据元素构成的有限序列。每个元素的n个线性关系中的序号称为该元素的下标，下标的取值范围称为数组的维界。</p>
<p>数组是线性表的推广，二维数组可视为其元素也是定长线性表的线性表。数组一旦被定义，其维数和界限就不再改变。除结构的初始化和销毁外，数组只会有存取元素和修改元素的操作。</p>
<h3 id="数组的存储结构"><a class="header" href="#数组的存储结构">数组的存储结构</a></h3>
<p>逻辑意义上的数组可采用计算机语言中的数组数据类型进行存储，一个数组的所有元素在内存中占用了一段连续的存储空间。</p>
<p>对于多维数组，有两种映射方式：<strong>行优先</strong>和<strong>列优先</strong>。</p>
<p>以二维数组为例，按行优先存储的思想：先行后列，先存储行号较小的元素，行号相等先存储列号较小的元素。</p>
<h3 id="矩阵的压缩存储"><a class="header" href="#矩阵的压缩存储">矩阵的压缩存储</a></h3>
<p>压缩存储：为多个<strong>值相同</strong>的元素只分配一个存储空间，对<strong>零元素</strong>不分配存储空间。目的是节省存储空间。</p>
<p>特殊矩阵：具有许多<strong>相同矩阵元素或零元素</strong>，并且分布具有一定规律性，例如对角矩阵、对称矩阵、上下三角矩阵。</p>
<p><strong>对称矩阵</strong></p>
<p>对于一个n阶方阵，其中的元素可划分为3个部分，即上三角区、主对角线和下三角区。</p>
<p>上下三角区的元素对应相同，因此只存储下三角部分（含对角线）即可，将对称矩阵$A[1...n][1...n]$存放在一维数组$B[n(n+1)/2]$中。</p>
<p>位于元素$a_{i,j}(i\geq j)$前面的元素个数为：</p>
<ul>
<li>第1行：1个元素</li>
<li>第2行：2个元素</li>
<li>...</li>
<li>第i-1行：i-1个元素$(a_{i-1,1},...,a_{i-1,i-1})$</li>
<li>第i行：j-1个元素$(a_{i,1},a_{i,2},...,a_{i,j-1})$</li>
</ul>
<p>则元素$a_{i,j}$在数组B中的下标为：$k=1+2+...+(i-1)+(j-1)=i(i-1)/2+j-1$</p>
<p>上三角区域将i和j对换即可。</p>
<p><strong>三角矩阵</strong></p>
<p>下三角矩阵中，上三角区的所有元素均视为同一常量。存储思想为：在存储完下三角区和主对角线上的元素后，紧接着存储对角线上方的常量一次，故可以将下三角矩阵$A[1...n][1...n]$压缩存放在一维数组$B[n(n+1)/2+1]$中。</p>
<p>上三角矩阵同理。</p>
<p><strong>三对角矩阵</strong></p>
<h3 id="稀疏矩阵"><a class="header" href="#稀疏矩阵">稀疏矩阵</a></h3>
<p>矩阵中非零元素的个数t，相对矩阵元素的个数s来说非常少，即s&gt;&gt;t的矩阵称为稀疏矩阵。</p>
<p>常规方法存储稀疏矩阵相当浪费空间，因此仅存储非零元素以及它所在的行和列，构成一个三元组（行标，列标，值），然后按照某种规律存储这些三元组。稀疏矩阵压缩存储后便失去了其随机存取特性。</p>
<p>三元组可以用数组或十字链表法存储。</p>
<div style="break-before: page; page-break-before: always;"></div><p><strong>字符串</strong>简称串，计算机上所有非数值处理的对象基本都是字符串数据。本章将详细介绍字符串的存储结构及相应的操作。</p>
<h2 id="串的定义和实现"><a class="header" href="#串的定义和实现">串的定义和实现</a></h2>
<h3 id="定义-1"><a class="header" href="#定义-1">定义</a></h3>
<p>串是由<strong>零个或多个</strong>字符组成的有限序列，一般记为：
$$
S='a_1a_2 \cdot\cdot\cdot a_n' \ (n\geq 0)
$$
S为串名，单引号括起来的为字符序列为串的值，$a_i$可以是字母、数字或其他字符，串中字符的个数n称为串的长度。</p>
<p>n=0时的串称为空串。</p>
<p>字串：串中任意多个连续的字符组成的子序列；包含子串的串称为主串；某个字符在串中的序号称为该字符在串中的位置；子串在主串中的位置以子串的第一个字符在主串中的位置来表示。当两个串的长度相等并且每个对应位置的字符都相等时，称这两个串是相等的。</p>
<h3 id="串的存储结构"><a class="header" href="#串的存储结构">串的存储结构</a></h3>
<p><strong>定长顺序存储</strong></p>
<p>类似于线性表的顺序存储结构，用一组地址连续的存储单元存储串值的字符序列。为每个串分配一个固定长度的存储区，即定长数组。</p>
<pre><code class="language-c">#define MAXLEN 255;	//预定最大串长为255
typedef struct {
	char ch[MAXLEN];	//每个分量存储一个字符
	int length;	//串的实际长度
}SString;
</code></pre>
<p>串的实际长度只能小于等于MAXLEN，超过这个长度的串值会被舍去，称为<strong>截断</strong>。</p>
<p>串长有两种表示方法：</p>
<ul>
<li>像定义描述的那样，用一个额外变量len来存放串的长度</li>
<li>在串值后面加一个不计入串长的结束标记字符<code>\0</code>，此时串长为隐含值</li>
</ul>
<p><strong>堆分配存储</strong></p>
<p>仍然以一块连续的存储单元存放串值的字符序列，但他们的存储空间是动态分配的。</p>
<pre><code class="language-c">typedef struct {
	char *ch;	//按照串长分配存储区，ch指向串的基地址
	int length;	//串的长度
}HString;
</code></pre>
<p>C语言中，存在一个称为堆的自由存储区，并用malloc()和free()函数来完成动态存储管理。利用malloc()为每个新产生的串分配一块实际串长所需的存储空间，若分配成功则返回一个指向起始地址的指针，作为串的基地址；若分配失败则返回NULL。已分配的空间可以用free()释放。</p>
<p><strong>块链存储</strong></p>
<p>类似于线性表的链式存储。在具体实现时，每个结点既可以存放一个字符，也可以存放多个字符。</p>
<h3 id="串的基本操作"><a class="header" href="#串的基本操作">串的基本操作</a></h3>
<ul>
<li>StrAssign(&amp;T, chars)：赋值操作。把串T赋值为chars</li>
<li>StrCompare(S, T)：比较操作。若S&gt;T则返回值&gt;0；若S=T，则返回值=0；若S&lt;T，则返回值&lt;0</li>
<li>StrLength(S)：求串长。返回串S的元素个数</li>
<li>Concat(&amp;T, S1, S2)：串联接。由T返回由S1和S2联接的新串</li>
<li>SubString(&amp;Sub, S, pos, len)：求子串。用Sub返回串S的第pos个字符起长度为len的子串</li>
</ul>
<p>以上5种操作构成串类型的最小操作子集，即这些操作不能利用其他串操作来实现。</p>
<h2 id="串的模式匹配"><a class="header" href="#串的模式匹配">串的模式匹配</a></h2>
<h3 id="简单模式匹配算法"><a class="header" href="#简单模式匹配算法">简单模式匹配算法</a></h3>
<p>子串的定位操作称为模式匹配。他求的是子串在主串中的位置。这里采用一种暴力匹配算法：</p>
<pre><code class="language-c">int Index(SString S, SString T) {
    int i = 1, j = 1;
    while (i &lt;= S.length &amp;&amp; j &lt;= T.length) {
        if (S.ch[i] == T.ch[j]) {
            ++i; ++j;	//继续比较后继字符
        }
        else {
            i = i - j + 2;	//指针后退重新开始匹配
            j = 1;
        }
    }
    if(j &gt; T.length)	return i - T.length;
    else return 0;
}
</code></pre>
<p>该算法的思想是：从主串S的第一个字符起，与模式T的第一个字符比较，若相等，则继续逐个比较后续字符；否则从主串的下一个字符起，重新和模式的字符比较；以此类推，直至模式T中的每个字符依次和主串S中的一个连续的字符序列相等，则匹配成功。</p>
<p>该算法的最坏时间复杂度为O(nm)，n和m分别为主串和匹配模式串的长度。</p>
<h3 id="kmp算法"><a class="header" href="#kmp算法">KMP算法</a></h3>
<p><strong>一些概念</strong></p>
<ul>
<li>前缀：除最后一个字符外，字符串的所有头部子串</li>
<li>后缀：除第一个字符外，字符串的所有尾部子串</li>
<li>部分匹配值：字符串的前缀和后缀的最长相等前后缀长度</li>
</ul>
<p>例如，字符串'ababa'的部分匹配值为00123</p>
<pre><code class="language-c">int Index_KMP(String S, String T, int next[]) {
    
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>重要内容：二叉树遍历、线索二叉树、二叉查找树、平衡二叉树、哈夫曼树和哈夫曼编码</p>
<h2 id="树的基本概念"><a class="header" href="#树的基本概念">树的基本概念</a></h2>
<h3 id="定义-2"><a class="header" href="#定义-2">定义</a></h3>
<h3 id="基本术语"><a class="header" href="#基本术语">基本术语</a></h3>
<ul>
<li>
<p>结点的度：树中一个结点的孩子个数</p>
</li>
<li>
<p>树的度：树中结点的最大度数</p>
</li>
<li>
<p>结点的深度、高度、层次：</p>
<ul>
<li>层次：从树根开始定义，根结点为第1层，其子结点为第2层</li>
<li>深度：从根结点开始自顶向下逐层累加</li>
<li>高度：从叶结点开始自底向上逐层累加</li>
</ul>
</li>
</ul>
<h3 id="性质"><a class="header" href="#性质">性质</a></h3>
<h2 id="二叉树的概念"><a class="header" href="#二叉树的概念">二叉树的概念</a></h2>
<h3 id="定义及主要特性"><a class="header" href="#定义及主要特性">定义及主要特性</a></h3>
<p><strong>定义</strong></p>
<p>每个结点至多只有两棵子树（即不存在度大于2的结点），并且二叉树的子树有左右之分，次序不能颠倒。</p>
<p>二叉树与度为2的有序树的区别：</p>
<ul>
<li>度为2的树至少有3个结点，而二叉树可以为空</li>
<li>度为2的有序树的孩子的左右次序是相对于另一个孩子而言的，如果某个结点只有一个孩子，则这个孩子就无须区分其左右次序；而二叉树无论海子叔是否为2，均需要确定其左右次序。</li>
</ul>
<p><strong>几个特殊二叉树</strong></p>
<ul>
<li>满二叉树：一颗高度为h，且含有$2^h-1$个结点的二叉树。即树中的每层都含有最多的结点。</li>
<li>完全二叉树：高度为h，有n个结点的二叉树，当且仅当其每个结点都与高度为h的满二叉树中编号为1-n的结点一一对应时，成为完全二叉树。
<ul>
<li>若有度为1的结点，则只可能有一个，且该结点只有左孩子没有右孩子</li>
</ul>
</li>
<li>二叉排序树：左子树上所有结点的关键字均小于根结点的关键字，右子树上的所有结点的关键字均大于根结点的关键字；左右子树又各自是一颗二叉排序树。</li>
<li>平衡二叉树：树上任一结点的左子树和右子树的深度之差不超过1.</li>
</ul>
<p><strong>性质</strong></p>
<ul>
<li>非空二叉树上叶子结点数等于度为2的结点数加1</li>
</ul>
<h3 id="存储结构"><a class="header" href="#存储结构">存储结构</a></h3>
<p><strong>顺序存储</strong></p>
<p>使用一组地址连续的存储单元<strong>自上而下、自左至右</strong>存储完全二叉树上的结点元素，即将完全二叉树上编号为i的结点元素存储在一维数组下标为i-1的分量中。</p>
<p><strong>完全二叉树和满二叉树</strong>采用顺序存储比较适合，树中结点的序号可以唯一地反映结点之间的逻辑关系，既能节省空间，又能利用数组元素下标值确定结点在二叉树中的位置。</p>
<p>对于一般二叉树，例如深度较深、结点较少的二叉树，使用顺序存储比较浪费空间，一般采用链式存储。</p>
<p><strong>链式存储</strong></p>
<p>用链表结点来存储二叉树中的每个结点。二叉链表一般包括3个域：数据域data、左指针域lchild、右指针域rchild。</p>
<pre><code class="language-c">typedef struct BiTNode {
	ElemType data;	//数据域
	struct BiTNode *lchild, *rchild;	//左右孩子指针
}BiTNode, *BiTree;
</code></pre>
<h2 id="二叉树的遍历和线索二叉树"><a class="header" href="#二叉树的遍历和线索二叉树">二叉树的遍历和线索二叉树</a></h2>
<h3 id="二叉树的遍历"><a class="header" href="#二叉树的遍历">二叉树的遍历</a></h3>
<p>二叉树遍历是指按照某条搜索路径<strong>访问树中每个结点</strong>，使得每个结点均被访问一次，而且仅被访问一次。要找到一种规律，使得二叉树上的结点能排列在一个线性队列上，进而便于遍历。</p>
<p>常见的遍历次序有先序、中序、后序。序指的是<strong>根结点</strong>在何时被访问。</p>
<p><strong>先序遍历</strong></p>
<p>若二叉树为空，则什么也不做；否则：</p>
<ul>
<li>访问根节点；</li>
<li>先序遍历左子树；</li>
<li>先序遍历右子树；</li>
</ul>
<pre><code class="language-c">void PreOrder(BiTree T) {
	if (T != NULL) {
		visit(T);	//访问根节点
		PreOrder(T-&gt;lchild);	//递归遍历左子树
		PreOrder(T-&gt;rchild);	//递归遍历右子树
	}
}
</code></pre>
<p><strong>中序遍历</strong></p>
<p>若二叉树为空，则什么也不做；否则：</p>
<ul>
<li>中序遍历左子树；</li>
<li>访问根节点；</li>
<li>中序遍历右子树；</li>
</ul>
<pre><code class="language-c">void InOrder(BiTree T) {
	if (T != NULL) {
		InOrder(T-&gt;lchild);	//递归遍历左子树
		visit(T);	//访问根节点
		InOrder(T-&gt;rchild);	//递归遍历右子树
	}
}
</code></pre>
<p><strong>后序遍历</strong></p>
<p>若二叉树为空，则什么也不做；否则：</p>
<ul>
<li>后序遍历左子树；</li>
<li>后序遍历右子树；</li>
<li>访问根节点。</li>
</ul>
<pre><code class="language-c">void PostOrder(BiTree T) {
	if (T != NULL)
    {
        PostOrder(T-&gt;lchild);	//递归遍历左子树
        PostOrder(T-&gt;rchild);	//递归遍历右子树
        visit(T);	//访问根节点
    }
}
</code></pre>
<p>三种遍历算法中递归遍历左右子树的顺序都是固定的，只是访问根节点的顺序不同。无论采用哪种遍历方法，每个结点都只访问一次，故时间复杂度为O(n)。递归工作栈的深度恰好为树的深度，所以在最坏的情况下二叉树是有n个结点且深度为的单支树，空间复杂度为O(n).</p>
<p><strong>递归算法和非递归算法的转换</strong></p>
<p>中序遍历的非递归算法：</p>
<pre><code class="language-c">void InOrder2(BiTree T) {
    InitStack(S); BiTree p = T;
    while (p || !IsEmpty(S)) {	//栈不为空或p不空时循环
        if(p) {	//一直向左遍历
            Push(S, p);	//将当前结点入栈
            p = p-&gt;lchild;	//左孩子不空，一直向左走
        }
        else {	//出栈，并转向出栈结点的右子树
            Pop(S, p); visit(p);	//栈顶元素出栈，访问出栈结点
            p = p-&gt;rchild;	//向右子树走，p赋值为当前结点的右孩子
        }	//返回while循环继续进行if-else
    }
}
</code></pre>
<p>先序遍历的非递归算法：</p>
<pre><code class="language-c">void PreOrder2(BiTree T) {
    InitStack(S); BiTree p = T;
    while (p || !IsEmpty(S)) {	//栈不为空或p不空时循环
    	if (p) {
            visit(p); Push(S, p);	//访问当前结点并入栈
            p = p-&gt;lchild;
        }
        else {
            Pop(S, p);
            p = p-&gt;rchild;
        }
    }
}
</code></pre>
<p>后序遍历要保证左孩子和右孩子都已经被访问并且左孩子在右孩子前访问才能访问根节点。思想为：从根节点开始，将其入栈，然后沿着左子树一直往下搜索，直到搜索到没有左孩子的结点，此时还不能出栈并访问，如果其有右子树，还要按照相同的规则对右子树进行处理，直到上述操作无法进行。栈顶元素想要被出栈访问，要么右子树为空，要么右子树刚被访问完。</p>
<p><strong>层次遍历</strong></p>
<p>按照1,2,3,4,...的层次顺序，对二叉树中的各个结点进行访问。</p>
<p>进行层次遍历需要借助一个<strong>队列</strong>。先将二叉树的根节点入队，然后出队，访问出队结点，若其有左子树，则将左子树根结点入队；若其有右子树，则将右子树根节点入队。然后出队，访问出队结点....以此类推，直到队列为空。</p>
<pre><code class="language-c">void LevelOrder(BiTree T) {
    InitQueue(Q);
    BiTree p;
    EnQueue(Q, T);	//将根节点入队
    while (!IsEmpty(Q)) {
        DeQueue(Q, p);
        visit(p);
        if(p-&gt;lchild != NULL)
            EnQueue(Q, p-&gt;lchild);
        if(p-&gt;rchild != NULL)
            EnQueue(Q, p-&gt;rchild);
    }
}
</code></pre>
<p><strong>由遍历序列构造二叉树</strong></p>
<ul>
<li>由二叉树的<strong>先序序列和中序序列</strong>可以唯一地确定一颗二叉树：</li>
</ul>
<p>在先序遍历序列中，第一个结点一定是二叉树的<strong>根结点</strong>；中序遍历中，根结点必然将中序序列<strong>分割为两个子序列</strong>，前一个子序列是根结点的左子树的中序序列，后一个子序列是根结点右子树的中序序列。根据这两个子序列，在先序序列中找到对应的左子序列和右子序列；在先序序列中，左子序列的第一个结点是左子树的根结点，右子序列的第一个结点时右子树的根结点。如此递归下去，便能唯一确定一颗二叉树。</p>
<ul>
<li>同理，由二叉树的<strong>后序序列和中序序列</strong>也可以唯一地确定一棵二叉树：</li>
</ul>
<p>后序序列的最后一个结点就如同先序序列的第一个结点，可以将中序序列分割为两个子序列，然后继续递归。</p>
<ul>
<li>只知道先序和后序序列无法确定一棵二叉树。</li>
</ul>
<p>见书上的例题。</p>
<h3 id="线索二叉树"><a class="header" href="#线索二叉树">线索二叉树</a></h3>
<p><strong>概念</strong></p>
<p>传统的二叉链表存储仅能体现一种父子关系，不能直接得到结点在遍历中的前驱或后继。这里设想用叶结点或度为1的结点的<strong>空指针</strong>来存放指向其<strong>前驱或后继</strong>的指针。这样就可以像遍历单链表一样方便地遍历二叉树。引入线索二叉树是为了<strong>加快查找结点前驱和后继</strong>的速度。</p>
<p>规定：若无左子树，令lchild指向其前驱结点；若无右子树，令rchild指向其后继结点。另外还需增加两个编制域标识指针域是指向左(右)孩子还是指向前驱(后继).</p>
<p>线索二叉树的结点结构：</p>
<table><thead><tr><th align="center">lchild</th><th align="center">ltag</th><th align="center">data</th><th align="center">rtag</th><th align="center">rchlid</th></tr></thead><tbody>
</tbody></table>
<p>标志域的含义：</p>
<p>ltag：0，lchild域指向结点的左孩子；1，lchild指向结点的前驱</p>
<p>rtag：0，rchild域指向结点的左孩子；1，rchild指向结点的前驱</p>
<p>线索二叉树的存储结构描述如下：</p>
<pre><code class="language-c">typedef struct ThreadNode {
	ElemType data;	//数据元素
	struct ThreadNode *lchild, *rchild;	//左右孩子指针
	int ltag, rtag;		//左右线索标志
} ThreadNode, *ThreadTree;
</code></pre>
<p><strong>中序线索二叉树的构造</strong></p>
<p>二叉树的线索化是将二叉链表中的空指针改为指向前驱或后继的线索。前驱或后继的信息只有在遍历时才能得到，因此线索化实质上就是遍历一次二叉树。</p>
<p>中序线索二叉树的建立：附设指针pre指向刚刚访问过的结点，指针p指向正在访问的结点，即pre指向p的前驱。中序遍历的过程中，检查p的左指针是否为空，若为空就将其指向pre；检查pre的右指针是否为空，若为空则将其指向p。</p>
<pre><code class="language-c">void InThread(ThreadTree &amp;p, ThreadTree &amp;pre) {
	if (p != NULL) {
        InThread(p-&gt;lchild, pre);	//递归，线索化左子树
        if (p-&gt;lchild == NULL) {
            p-&gt;lchild = pre;
            p-&gt;ltag = 1;
        }
        if (pre != NULL &amp;&amp; pre-&gt;rchild == NULL) {
            pre-&gt;rchild = p;	//建立前驱结点的后继线索
            pre-&gt;rtag = 1;
        }
        pre = p;
        InThread(p-&gt;rchild, pre);
    }//if(p!=NULL)
}
</code></pre>
<p>通过中序遍历建立中序线索二叉树的主过程算法：</p>
<pre><code class="language-c">void CreatInThread(ThreadTree T) {
	ThreadTree pre = NULL;
    if (T != NULL) {	//非空二叉树，线索化
        InThread(T, pre);	//线索化二叉树
        pre-&gt;rchild = NULL;	//处理遍历后的最后一个结点
        pre-&gt;rtag = 1;
    }
}
</code></pre>
<p>另外为了方便，可以在二叉树的线索链表上添加一个<strong>头结点</strong>Head，令其<strong>lchild域</strong>的指针指向二叉树的<strong>根结点</strong>，其<strong>rchild域</strong>的指针指向中序遍历时访问的<strong>最后一个结点</strong>；令二叉树中序序列中的<strong>第一个结点的lchild域</strong>和<strong>最后一个结点的rchild域</strong>指针均指向<strong>头结点</strong>。这就好比为二叉树建立了一个双线线索链表，方便从前向后或从后向前对线索二叉树进行遍历。</p>
<p><strong>中序线索二叉树的遍历</strong></p>
<p>中序线索二叉树隐含了线索二叉树的前驱和后继信息。对其遍历时，只要先找到序列中的第一个结点，然后依次找结点的后继，直至其后继为空。找结点后继的规律为：若其右标志为1，则右链为线索，指示其后继；否则遍历右子树中第一个访问的结点（即右子树中最左下的结点）为其后继。</p>
<ul>
<li>求中序线索二叉树中中序序列下的第一个结点：</li>
</ul>
<pre><code class="language-c">ThreadNode *Firstnode(ThreadNode *p) {
	while (p-&gt;ltag == 0)
        p = p-&gt;lchild;	//最左下结点
	return p;
}
</code></pre>
<ul>
<li>求结点p在中序序列下的后继：</li>
</ul>
<pre><code class="language-c">ThreadNode *Nextnode(ThreadNode *p) {
	if (p-&gt;rtag == 0)
        return Firstnode(p-&gt;rchild);
	else 
        return p-&gt;rchild;
}
</code></pre>
<p>利用以上的两个算法，可以得到不含头结点的中序线索二叉树的<strong>中序遍历</strong>的算法：</p>
<pre><code class="language-c">void Inorder (ThreadNode *T) {
	for (ThreadNode *p = Firstnode(T); p != NULL; p = Nextnode(p))
		visit(p);
}
</code></pre>
<p><strong>先序线索二叉树和后序线索二叉树</strong></p>
<p>建立先序和后序线索二叉树的代码类似于中序线索二叉树，只需变动线索化改造的代码段与调用线索化左右子树递归函数的位置。</p>
<p>在先序线索二叉树中找结点后继：</p>
<ul>
<li>如果有左孩子，则左孩子就是后继；</li>
<li>如果无左孩子，有右孩子，则右孩子就是其后继；</li>
<li>如果为叶结点，则右链域直接指示了结点的后继。</li>
</ul>
<p>在后序线索二叉树中找结点后继：</p>
<ul>
<li>若结点x是根结点，则后继为空；</li>
<li>若结点x是双亲的右孩子，或是双亲的左孩子且双亲没有右子树，则后继为双亲；</li>
<li>若结点x是双亲的左孩子且双亲有右子树，则后继为双亲右子树上按后序遍历列出的第一个结点。</li>
</ul>
<h2 id="树森林"><a class="header" href="#树森林">树、森林</a></h2>
<h3 id="树的存储结构"><a class="header" href="#树的存储结构">树的存储结构</a></h3>
<p>可以采用<strong>顺序或链式</strong>存储结构，必须要反映出树种各个结点之间的逻辑关系。</p>
<p><strong>双亲表示法</strong></p>
<p>采用连续空间存储每个结点，同时在每个结点中增设一个伪指针，指示其<strong>双亲结点在数组中的位置</strong>。根节点下标为0，其伪指针域为-1.</p>
<p>存储结构描述如下：</p>
<pre><code class="language-c">#define MAX_TREE_SIZE 100	//树中最多结点数
typedef struct {	//树的结点的定义
	ElemType data;	//数据元素
	int parent;	//双亲位置域
} PTNode;
typedef struct {	//树类型的定义
	PTNode nodes[MAX_TREE_SIZE];	//双亲表式
	int n;	//结点数
} PTree;
</code></pre>
<p>该结构利用了每个结点（除根节点）只有一个双亲的性质，可以很快地得到每个结点的双亲，但是求结点的孩子时需要遍历整个结构。</p>
<blockquote>
<p>树的顺序存储结构与二叉树的顺序存储结构有些不同。书的顺序存储中，数组下标代表结点的编号，下表中存储的内容指示了结点之间的关系；二叉树的顺序存储中，数组的下标既代表了结点的编号，又指示了二叉树中各结点之间的关系。</p>
</blockquote>
<p><strong>孩子表示法</strong></p>
<p>这种方法将每个结点的孩子都用单链表链接起来形成一个线性结构，此时n个结点就有n个孩子链表，叶子结点的孩子链表为空。</p>
<p>这种存储方式<strong>寻找子女</strong>的操作很直接，而寻找双亲需要遍历n个结点中孩子链表指针域指向的n个孩子链表。</p>
<p><strong>孩子兄弟表示法</strong></p>
<p>又称<strong>二叉树表示法</strong>，即以二叉链表作为树的存储结构。每个结点包括三部分内容：结点值、指向结点的<strong>第一个孩子</strong>的指针以及指向结点<strong>下一个兄弟结点</strong>的指针。沿此域可以找到结点的所有兄弟结点。</p>
<p>该方法的存储结构描述如下：</p>
<pre><code class="language-c">typedef struct CSNode {
	ElemType data;
	struct CSNode *firstchild, *nextsibling;
}CSNode, *CSTree;
</code></pre>
<p>此方法的最大优点是可以方便地实现树转换为二叉树的操作，易于查找结点的孩子。</p>
<h3 id="树森林与二叉树的转换"><a class="header" href="#树森林与二叉树的转换">树、森林与二叉树的转换</a></h3>
<p>二叉树和树都可以用<strong>二叉链表</strong>作为存储结构，因此以二叉链表作为媒介可以导出树与二叉树的对应关系，即给定一棵树，可以找到<strong>唯一的一个二叉树与之对应</strong>。</p>
<p>树转换为二叉树的规则：每个结点左指针指向它的<strong>第一个孩子</strong>，右指针指向它在树中<strong>相邻的右兄弟</strong>，这个规则称为<strong>左孩子右兄弟</strong>。</p>
<p>将森林转换为二叉树的规则与树类似，先将森林中的每一棵树转换为二叉树，由于<strong>任何一棵树</strong>对应的<strong>二叉树的右子树必为空</strong>，若把第二棵树的二叉树视为第一颗二叉树树根的右兄弟，将第三棵树对应的二叉树当作第二课二叉树树根的右兄弟，以此类推，就可以将森林转换为二叉树。</p>
<h3 id="树和森林的遍历"><a class="header" href="#树和森林的遍历">树和森林的遍历</a></h3>
<p>用某种方式访问树中的每个结点。</p>
<ul>
<li>先根遍历：先访问根结点，再依次遍历根结点的每棵子树，遍历子树时仍然遵循<strong>先根后子树</strong>的规则。其遍历序列与该树对应的二叉树的<strong>先序序列</strong>相同。</li>
<li>后根遍历：先依次遍历根结点的每棵子树，再访问根结点，遍历子树时仍遵循<strong>先子树后根</strong>的规则。其遍历序列与该树对应的二叉树的<strong>中序序列</strong>相同。</li>
</ul>
<p>按照树和森林相互递归的定义，可得到森林的两种遍历方法：</p>
<ul>
<li>先序遍历森林：
<ul>
<li>访问呢森林中第一棵树的根结点</li>
<li>先序遍历第一棵树中根结点的子树森林</li>
<li>先序遍历除去第一棵树之后剩余树构成的森林</li>
</ul>
</li>
<li>中序遍历森林：
<ul>
<li>中序遍历森林中第一棵树的根结点的子树森林</li>
<li>访问第一棵树的根结点</li>
<li>中序遍历除去第一棵树之后剩余的树构成的森林</li>
</ul>
</li>
</ul>
<h3 id="树的应用并查集"><a class="header" href="#树的应用并查集">树的应用——并查集</a></h3>
<h2 id="树与二叉树的应用"><a class="header" href="#树与二叉树的应用">树与二叉树的应用</a></h2>
<h3 id="二叉排序树bst"><a class="header" href="#二叉排序树bst">二叉排序树（BST）</a></h3>
<p><strong>定义</strong></p>
<p>也称<strong>二叉查找树</strong>，是一个具有以下特性的二叉树：</p>
<ul>
<li>若左子树非空，则<strong>左子树</strong>上所有结点的值均<strong>小于根结点</strong>；</li>
<li>若右子树非空，则<strong>右子树</strong>上所有结点的值均<strong>大于根结点</strong>；</li>
<li>左右子树也分别是一颗二叉排序树</li>
</ul>
<p>根据以上定义，左子树结点值&lt;根结点值&lt;右子树结点值，所以可以通过<strong>中序遍历</strong>得到一个<strong>递增的有序序列</strong>。</p>
<p><strong>二叉排序树的查找</strong></p>
<p>从根结点开始，沿着某个分支逐层向下比较的过程。若二叉排序树非空，先将给定值与根结点进行比较，若相等则查找成功，若不等，如果小于根节点关键字则在左子树上查找，否则在右子树上查找。这是一个递归的过程。</p>
<pre><code class="language-c">BSTNode *BST_Search(BiTree T, ElemType key) {
    while(T != NULL &amp;&amp; key != T-&gt;data) {
        if(key &lt; T-&gt;data)	T = T-&gt;lchild;
        else	T = T-&gt;rchild;
    }
    return T;
}
</code></pre>
<p><strong>二叉排序树的插入</strong></p>
<p>二叉排序树作为一种<strong>动态树表</strong>，特点是树的结构不是一次生成的，而是在查找过程中，当树中不存在关键字值等于给定值的结点时再进行插入。</p>
<p>插入结点过程如下：若原二叉排序树为空，则直接插入；否则，若关键字k小于根结点值，插入到左子树，否则插入到右子树。插入的结点一定是一个<strong>新添加的叶子结点</strong>，且是查找失败时查找路径上访问的<strong>最后一个结点的左孩子或右孩子</strong>。</p>
<p>算法描述如下：</p>
<pre><code class="language-c">int BST_Insert(BiTree &amp;T, KeyType k) {
	if (T == NULL) {
		T = (BiTree)malloc(sizeof(BSTNode));
		T-&gt;key = k;
		T-&gt;lchild = T-&gt;rchild = NULL;
		return 1;
	}
	else if (k == T-&gt;key)
		return 0;
	else if (k &lt; T-&gt;key)
		return BST_Insert(T-&gt;lchild, k);
	else
		return BST_Insert(T-&gt;rchild, k);
}
</code></pre>
<p><strong>二叉排序树的构造</strong></p>
<p>从一颗<strong>空树</strong>出发，依次输入元素，将它们<strong>插入</strong>二叉排序树的合适位置。</p>
<p>算法描述如下：</p>
<pre><code class="language-c">void Creat_BST(BiTree &amp;T, KeyType str[], int n) {
	T = NULL;	//初始化T为空树
	int i = 0;
	while (i &lt; n) {
		BST_Insert(T, str[i]);	//依次将每个关键字插入二叉排序树中
		i++;
	}
}
</code></pre>
<p><strong>二叉排序树的删除</strong></p>
<p>删除操作按照以下3种情况来处理：</p>
<ul>
<li>若被删除的结点z是<strong>叶子结点</strong>，则直接删除，不会破坏二叉排序树的性质；</li>
<li>若结点z<strong>只有一棵左子树或右子树</strong>，则让z的子树成为z父结点的子树，替代z的位置；</li>
<li>若结点z<strong>有左右两棵子树</strong>，则令z的<strong>直接后继</strong>替代z，然后从二叉排序树中<strong>删去这个直接后继</strong>，这样就转换为了第一或第二种情况。</li>
</ul>
<p><strong>查找效率分析</strong></p>
<p>查找效率主要取决于树的高度。若二叉排序树的左右子树高度之差的绝对值不超过1，则这样的二叉树成为平衡二叉树，其平均查找长度为$O(\log_2n)$。若二叉排序树是一个只有左（右）孩子的单支树，则平均查找长度为$O(n)$。</p>
<h3 id="平衡二叉树"><a class="header" href="#平衡二叉树">平衡二叉树</a></h3>
<p><strong>定义</strong></p>
<p>为了避免树的高度增长过快，降低二叉排序树的性能，规定在插入和删除二叉树的结点时，要保证其任意结点的左右子树<strong>高度差的绝对值不超过1</strong>。</p>
<ul>
<li><strong>平衡因子</strong>：结点左子树与右子树的高度差；平衡二叉树的平衡因子只可能是-1，0，1。</li>
</ul>
<p><strong>插入</strong></p>
<p>每当插入或删除一个结点时，首先检查其插入路径上的结点是否因此导致了不平衡。若导致了不平衡，先找到插入路径上离插入结点最近的平衡因子的绝对值大于1的结点A，再对以A为根的子树，在保持二叉排序树的特定的前提下，调整各个结点的位置关系，使之重新达到平衡。</p>
<p>将调整规律归纳为以下4种情况：</p>
<ul>
<li>
<p>LL平衡旋转（右单旋转）：由于在结点A的左孩子的左子树上插入了新的结点，A的平衡因子由1增至2.</p>
</li>
<li>
<p>RR平衡旋转（左单旋转）：由于在极点A的右孩子的右子树插入了新的结点，A的平衡因子由-1减至-2</p>
</li>
<li>
<p>LR平衡旋转（先左后右双旋转）：</p>
</li>
<li>
<p>RL平衡旋转（先右后左双旋转）：</p>
</li>
</ul>
<p><strong>查找</strong></p>
<p>在平衡二叉树上进行查找的过程与二叉排序树相同。在查找过程中，与给定值进行比较的关键词个数不超过树的深度。含有n个结点的平衡二叉树的最大深度为$O(\log_2n)$，因此平衡二叉树的平均查找长度为$O(\log_2n)$。</p>
<h3 id="哈夫曼树和哈夫曼编码"><a class="header" href="#哈夫曼树和哈夫曼编码">哈夫曼树和哈夫曼编码</a></h3>
<p><strong>定义</strong></p>
<p>树中的结点被赋予了<strong>权值</strong>；从树的根到任意结点的路径长度与该结点上权值的乘积称为该结点的<strong>带权路径长度</strong>。</p>
<p>树中所有<strong>叶子结点</strong>的带权路径长度之和称为该树的带权路径长度，记为：
$$
WPL=\sum_{i=1}^{n}w_il_i
$$
在含有n个带权叶结点的二叉树中，其中<strong>带权路径长度WPL</strong>最小的<strong>二叉树</strong>称为哈夫曼树，也成为最优二叉树。</p>
<p><strong>哈夫曼树的构造</strong></p>
<ul>
<li>将这n个结点分别作为n棵仅含有一个结点的二叉树，构成森林F</li>
<li>构造一个新结点，从F中选取两棵根结点权值最小的树作为新结点的左右子树，并且将新结点的权值置为左右子树上根结点的权值之和</li>
<li>从F中删除刚才选出的两棵树，同时将新得到的树加入F中</li>
<li>重复上两个步骤，直到F中剩余一棵树为止</li>
</ul>
<p>从以上构造过程可以看出：</p>
<ul>
<li>每个初始结点都成为了叶结点，且权值越小的结点到根结点的路径长度越长</li>
<li>构造过程共新建了n-1个结点，因此哈夫曼树的结点总数为2n-1</li>
<li>每次构造都选择2棵树作为新结点的孩子，因此哈夫曼树不存在度为1的结点</li>
</ul>
<p><strong>哈夫曼编码</strong></p>
<p>被广泛应用且非常有效的数据压缩编码。是一种可变长度编码，即允许对不同字符用不等长的二进制位表示，对频率高的字符赋予短编码，对频率低的字符赋予长编码，这样能够压缩数据。</p>
<ul>
<li><strong>前缀编码</strong>：没有一个编码是另一个编码的前缀。例如0，101，100就是一组前缀编码。</li>
</ul>
<p>哈夫曼编码的过程：</p>
<ul>
<li>首先将每个出现的字符当作一个独立的结点，权值为其出现的频度，构造出对应的哈夫曼树</li>
<li>所有字符结点都出现在叶子结点中</li>
<li>将字符的编码解释为从根至该字符路径上<strong>边标记</strong>的序列，边标记为0表示转向左孩子，边标记为1表示转向右孩子。</li>
</ul>
<p>由此得到的哈夫曼树拥有最优的WPL。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="图的基本概念"><a class="header" href="#图的基本概念">图的基本概念</a></h2>
<h3 id="定义-3"><a class="header" href="#定义-3">定义</a></h3>
<p>图G是由顶点集V和边集E组成，记作$G=(V,E)$，其中V(G)表示图中顶点的有限非空集；E(G)表示图G中顶点之间的关系。</p>
<p>图不可是空图。图的顶点集V一定非空，但边集可以为空。</p>
<p><strong>有向图和无向图</strong></p>
<p><strong>简单图、多重图</strong></p>
<p><strong>完全图</strong></p>
<p>分为完全图（无向）、有向完全图</p>
<p><strong>子图</strong></p>
<p><strong>连通、连通图和连通分量</strong></p>
<p>无向图中的概念：任意两个顶点之间都存在路径。连通分量：无向图中的极大连通子图</p>
<p><strong>强连通图、强连通分量</strong></p>
<p>有向图任何一对顶点相互之间都有路径。强连通分量：有向图的极大连通子图</p>
<p><strong>生成树、生成森林</strong></p>
<p>连通图的生成树：包含图中全部顶点的极小连通子图。</p>
<p>非连通图中的连通分量的生成树构成了非连通图的生成森林。</p>
<p><strong>顶点的度、入度和出度</strong></p>
<p>无向图中，顶点v的度指的是依附于顶点v的边的条数。无向图的全部顶点的度的和等于边数的2倍。</p>
<p>有向图顶点v的度分为入度和出度，入度是以顶点v为终点的有向边的数目；出度是以顶点v为起点的有向边的数目。</p>
<p><strong>边的权和网</strong></p>
<p>带权图。</p>
<p><strong>稠密图、稀疏图</strong></p>
<p>一个相对概念，把图G满足$|E|&lt;|V|\log|V|$时称为稀疏图。</p>
<p><strong>路径、路径长度、回路</strong></p>
<p>路径长度：路径上边的数目</p>
<p>若一个图有n个顶点，并且有大于n-1条边，则此图一定有环。</p>
<p><strong>简单路径、简单回路</strong></p>
<p>路径序列中顶点不重复出现的路径称为简单路径。除第一个顶点和最后一个顶点，其余顶点不重复出现的回路称为简单回路。</p>
<p><strong>距离</strong></p>
<p>两顶点间的距离：两顶点间的最短路径</p>
<p><strong>有向树</strong></p>
<p>一个顶点的入度为0、其余顶点的入度均为1的有向图。</p>
<h2 id="图的存储和基本操作"><a class="header" href="#图的存储和基本操作">图的存储和基本操作</a></h2>
<p>图的存储要完整地反映顶点集和边集的信息。</p>
<h3 id="邻接矩阵法"><a class="header" href="#邻接矩阵法">邻接矩阵法</a></h3>
<p>用一个<strong>一维数组</strong>存储图中<strong>顶点</strong>的信息，用一个<strong>二维数组</strong>存储图中<strong>边</strong>的信息。存储顶点之间邻接关系的二维数组称为邻接矩阵。</p>
<pre><code class="language-c">typedef MaxVertexNum 100
typedef char VertexType;
typedef int EdgeType;
typedef struct {
	VertexType Vex[MaxVertexNum];
	EdgeType Edge[MaxVertexNum][MaxVertexNum];
	int vexnum, arcnum;
} MGraph;
</code></pre>
<h3 id="邻接表法"><a class="header" href="#邻接表法">邻接表法</a></h3>
<p>当一个图为<strong>稀疏矩阵</strong>时，使用邻接矩阵法会浪费大量空间，而邻接表法结合了顺序存储和链式存储，减少了这种不必要的浪费。</p>
<ul>
<li>
<p>边表：存储一个顶点连接的所有顶点所依附的边，为链式存储</p>
</li>
<li>
<p>顶点表：边表的头指针和顶点数据采用顺序存储</p>
</li>
</ul>
<pre><code class="language-c">#define MaxVertexNum 100
typedef struct ArcNode {	//边表结点
	int adjvex;		//该弧指向的顶点的位置
	struct ArcNode *next;	//指向下一条弧的指针
	//InfoType info;	//网的边权值
} ArcNode;
typedef struct Vnode {	//顶点表结点
	VertexType data;	//顶点信息
	ArcNode *first;	//头指针
} VNode, AdjList[MaxVertexNum];
typedef struct {	
	AdjList vertices;	//邻接表
	int vexnum, arcnum;	//顶点数和弧数
} ALGraph;	//ALGraph是以邻接表存储的图类型
</code></pre>
<h3 id="十字链表"><a class="header" href="#十字链表">十字链表</a></h3>
<p>十字链表是<strong>有向图</strong>的一种<strong>链式</strong>存储结构。在十字链表中，对应于有向图中的<strong>每条弧</strong>有一个结点，对应于<strong>每个顶点</strong>也有一个结点。</p>
<ul>
<li>弧结点：</li>
</ul>
<table><thead><tr><th align="center">tailvex</th><th align="center">headvex</th><th align="center">hlink</th><th align="center">tlink</th><th align="center">info</th></tr></thead><tbody>
</tbody></table>
<ul>
<li>顶点结点：</li>
</ul>
<table><thead><tr><th align="center">data</th><th align="center">firstin</th><th align="center">firstout</th></tr></thead><tbody>
</tbody></table>
<p>十字链表中，既容易找到以一个顶点为尾的弧，又容易找到以一个结点为头的弧。</p>
<h3 id="邻接多重表"><a class="header" href="#邻接多重表">邻接多重表</a></h3>
<p>每条边和每个顶点各用一个结点表示。</p>
<p>邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，因此每个边结点同时链接在两个链表中。</p>
<h3 id="图的基本操作"><a class="header" href="#图的基本操作">图的基本操作</a></h3>
<p>图的基本操作独立于图的存储结构。对于不同存储方式，操作算法的具体实现有着不同的性能。</p>
<p>基本操作主要包括：</p>
<ul>
<li>判断图G中是否存在边(x,y)</li>
<li>列出图G中与结点x邻接的边</li>
<li>在图中插入顶点x</li>
<li>从图中删除顶点x</li>
</ul>
<p>。。。。</p>
<h2 id="图的遍历"><a class="header" href="#图的遍历">图的遍历</a></h2>
<p>图的遍历指从图中某一顶点出发，按照某种搜索方法沿着图中的边对图中所有顶点访问一次且仅访问一次</p>
<p>图中的任一顶点都可能与其他顶点相邻接，所以在访问某个顶点后，可能沿着某条路径搜索又回到了该顶点。为避免同一顶点被多次访问，在遍历图的过程中，可以设置一个辅助数组visited[]记录下已经访问过的顶点。</p>
<h3 id="广度优先搜索bfs"><a class="header" href="#广度优先搜索bfs">广度优先搜索BFS</a></h3>
<p>Breadth-First-Search，BFS，类似于二叉树的层序遍历算法。从起始顶点v出发，一次访问v的各个未访问过的邻接顶点$w_1,w_2,...,w_i$，然后依次访问这些邻接结点的邻接结点，直到图中所有顶点都被访问过为止。如果此时图中尚有未访问过的顶点，则另选图中一个未访问过的顶点作为起始点，重复上述过程，直到所有结点都被访问。</p>
<p>为了实现BFS的逐层访问，必须借助一个<strong>辅助队列</strong>，来记忆正在访问的顶点的下一层顶点。</p>
<p>该算法的伪代码如下：</p>
<pre><code></code></pre>
<p><strong>BFS算法性能分析</strong></p>
<p>无论图采用邻接表或邻接矩阵的存储方式，BFS都需要借助辅助队列Q，n个顶点均需要入队依次，最坏的情况下，所有顶点都在队列中，<strong>空间复杂度</strong>为$O(|V|)$。</p>
<p>采用<strong>邻接表</strong>存储，每个顶点均需搜索（入队）一次，时间复杂度为$O(|V|)$，在搜索任一顶点的邻接点时，每条边至少访问一次，时间复杂度为$O(|E|)$，<strong>总时间复杂度为</strong>$O(|E|+|V|)$。采用<strong>邻接矩阵</strong>存储时，同样每个顶点均需搜索（入队）一次，时间复杂度为$O(|V|)$，在搜索任一顶点的邻接点所需的时间为$O(|V|)$，所以<strong>总时间复杂度为</strong>$O(|V|^2)$。</p>
<p><strong>BFS求解单源最短路径的问题</strong></p>
<p>在遍历的过程中<strong>顺便求解</strong>两顶点间的最短路径。以<strong>其中一个顶点为头结点</strong>进行广度优先搜索遍历。</p>
<p><strong>广度优先生成树</strong></p>
<p>给定图的邻接矩阵存储表示是唯一的，故其广度优先生成树也是唯一的；由于邻接表存储方式不唯一，其广度优先生成树不唯一。</p>
<h3 id="深度优先搜索dfs"><a class="header" href="#深度优先搜索dfs">深度优先搜索DFS</a></h3>
<p>类似于<strong>树的先序遍历</strong>。算法思想为：首先访问图中某一起始顶点v，由v出发访问与v邻接且未访问过的任一顶点$w_1$，然后继续访问与$w_1$邻接的任意顶点$w_2$，重复以上过程，直到不能继续访问下去时，依次退回最近被访问过的顶点，若它还有其他邻接顶点未被访问，从该点开始重复上述过程，直到图中所有顶点都被访问为止。</p>
<p>该算法采用递归形式实现十分简洁：</p>
<pre><code class="language-c">bool visited[MAX_VERTEX_NUM];	//访问标记数组
void DFSTraverse(Graph G) {
	for (v = 0; v &lt; G.vexnum; ++v)
		visited[v] = false;
	for (v = 0; v &lt; G.vexnum; ++v)		//需要该循环的原因是这个图不一定是连通图
		if(!visited[v])	 DFS(G, v);
}
void DFS(Graph G, int v) {
	visit(v);
	visited[v] = true;
	for (w = FirstNeighbor(G, v); w &gt;= 0; w = NextNeighbor(G, v, w))
		if(!visited[w])	 DFS(G, w);
}
</code></pre>
<p><strong>DFS的性能分析</strong></p>
<p>该算法是一个递归算法，需要一个递归工作栈，因此空间复杂度为$O(|V|)$。</p>
<p>时间复杂度与<strong>存储结构</strong>有关，遍历图的实质是对每个顶点的邻接顶点的查找过程。用邻接矩阵存储时，总时间复杂度为$O(|V|^2)$；用邻接表存储时，总时间复杂度为$O(|E|+|V|)$</p>
<p><strong>深度优先的生成树和生成森林</strong></p>
<h2 id="图的应用"><a class="header" href="#图的应用">图的应用</a></h2>
<h3 id="最小生成树"><a class="header" href="#最小生成树">最小生成树</a></h3>
<p>一个连通图的<strong>生成树</strong>包含图的<strong>所有顶点以及尽可能少的边</strong>。对于生成树来说，砍去其一条边就会变成非连通图；若增加一条边，图中就会形成一条回路。</p>
<p>一个带权连通无向图$G=(V,E)$，生成树不同，每棵树的权也可能不同。设R为G的所有生成树的集合，若T为R中边的<strong>权值之和最小的树</strong>，那么称T为G的<strong>最小生成树</strong>（MST）。</p>
<ul>
<li>最小生成树可能不唯一。</li>
<li>最小生成树的边的权值之和唯一。</li>
<li>最小生成树的边数为顶点数减1。</li>
</ul>
<p>最小生成树的构造大多利用以下<strong>性质</strong>：假设$G=(V,E)$是一个带权连通无向图，U是顶点集V的一个非空子集，若(u,v)是一条具有最小权值的边，其中$u\in U,v\in V-U$，则存必在一棵包含边(u,v)的最小生成树。</p>
<p>通用最小生成树的实现算法：</p>
<pre><code>GENERIC_MST(G) {
	T = NULL;
	while T未形成一棵树;
		do 找到一条最小代价边(u,v)并且加入T后不产生回路;
			将改变加入T;
}
</code></pre>
<p>通用算法每次加入一条边以逐渐形成一棵生成树。</p>
<p><strong>Prim算法</strong></p>
<p>初始时从图中任取一个顶点加入树T，此时树中仅含有一个顶点，之后选择一个与当前T中顶点集合距离最近的顶点，并将该顶点和相应的边加入T，每次操作后树T的顶点和边数都增加1.以此类推，直到图中所有顶点都并入树T，得到的就是最小生成树T。</p>
<p>简单实现如下：</p>
<pre><code></code></pre>
<p>Prim算法的时间复杂度为$O(|V|^2)$，不依赖于边数E，因此其适用于求解<strong>边稠密</strong>的图的最小生成树。</p>
<p><strong>Kruskal算法</strong></p>
<p>该算法是一种<strong>按权值的递增次序</strong>选择合适的边来构造最小生成树的方法。</p>
<p>初始时为只有n个顶点而无边的非连通图T，每个顶点自成一个连通分量，然后按照边的权值由小到大的顺序，不断选择当前未被选取过且权值最小的边，若该边依附的顶点落在<strong>不同连通分量</strong>上，则将该边加入T，否则舍弃此边选择下一条权值最小的边。以此类推，直到所有顶点都在一个连通分量上。</p>
<p>简单实现：</p>
<pre><code>
</code></pre>
<h3 id="最短路径"><a class="header" href="#最短路径">最短路径</a></h3>
<p>当图是带权图时，把从一个顶点$v_0$到图中其余任意一个顶点$v_i$的一条路径所经过边上权值之和定义为该路径的<strong>带权路径长度</strong>，把带权路径长度<strong>最短</strong>的那条路径称为最短路径。</p>
<p>求解最短路径的算法通常依赖于一种性质：两点之间的最短路径也包含了路径上其他顶点间的最短路径。</p>
<p><strong>Dijkstra算法求单源最短路径问题</strong></p>
<p>迪杰斯特拉算法是用来求<strong>单源</strong>最短路径，即图中某一顶点到其他各顶点的最短路径。</p>
<p>该算法会设置一个<strong>集合S</strong>记录<strong>已求得的最短路径的顶点</strong>，初始时把源点$v_0$放入S，集合S每并入一个新顶点$v_i$，都要修改源点$v_0$到集合V-S中顶点当前的最短路径长度值。</p>
<p>另外构造过程中还设置了两个辅助数组：</p>
<ul>
<li>dist[]：记录从$v_0$到其他各顶点的<strong>当前最短路径</strong>；初态为：若从$v_0$到$v_i$有弧，则dist[i]为弧上的权值；否则置dist[i]为$\infin$。</li>
<li>path[]：path[i]表示从源点到顶点i之间的<strong>最短路径的前驱结点</strong>。算法结束时可以根据其值回溯得到源点$v_0$到顶点$v_i$的最短路径。</li>
</ul>
<p>Dijkstra算法的步骤如下：（arcs[i][j]表示有向边&lt;i,j&gt;的权值）</p>
<ul>
<li>
<p>初始化：集合S初始化为${0}$，dist[i]的初始值arcs[0][i]</p>
</li>
<li>
<p>从顶点集合V-S中选出$v_j$，满足$dsit[j]=Min{\text{dist}[i]| v_i\in V-S}$，$v_j$就是当前求得的一条从$v_0$出发的最短路径的的终点，令$S=S\or {j}$</p>
</li>
<li>
<p>修改从$v_0$出发到集合V-S上任一顶点$v_k$的最短路径长度，若：</p>
<p>dist[j]+arcs[j][k]&lt;dist[k]，则更新dist[k]=dist[j]+arcs[j][k]</p>
</li>
<li>
<p>重复上面中间的两部，操作共n-1次，直到所有顶点都包含在S中</p>
</li>
</ul>
<p>使用邻接矩阵表示时，时间复杂度为$O(|V|^2)$；使用带权的邻接表时，虽然修改dist[]的时间减少，但是在dist[]中选择最小分量的时间不变，时间复杂度仍为$O(|V|^2)$</p>
<p>该算法不适用于边上带有负权值的情况。</p>
<p><strong>Floyd算法求各顶点之家最短路径问题</strong></p>
<p>弗洛伊德算法用来求<strong>每对顶点间</strong>的最短路径。</p>
<p>递推产生一个n阶方阵序列$A^{(-1)},A^{(0)},...,A^{(k)},A^{(n-1)}$，其中$A^{(k)}[i][j]$表示从顶点$v_i$到顶点$v_j$的路径长度，k表示绕行第k个顶点的运算步骤。初始时对于任意两个顶点，若他们之间存在边，则此边上的权值最为他们之间的最短路径；若它们之间不存在有向边，则以$\infin$作为它们之间的最短路径。以后逐步尝试在原路径中加入顶点k作为中间顶点，若增加顶点后，得到的路径比原来的路径减少，则以新路径代替原路径。</p>
<p>Floyd算法的时间复杂度为$O(|V|^3)$。</p>
<h3 id="有向无环图描述表达式"><a class="header" href="#有向无环图描述表达式">有向无环图描述表达式</a></h3>
<p>有向无环图：一个有向图不存在环路，简称<strong>DAG图</strong>。</p>
<p>有向无环图可以用来描述含有<strong>公共子式</strong>的表达式，能够实现对公共子式的共享，从而节省存储空间。</p>
<h3 id="拓扑排序"><a class="header" href="#拓扑排序">拓扑排序</a></h3>
<p>AOV网：<strong>顶点表示活动的网络</strong>；用DAG图表示一个工程，顶点表示活动，有向边$&lt;V_i,V_j&gt;$表示活动$V_i$必须先于$V_j$进行的关系。</p>
<p>拓扑排序：由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑序列：</p>
<ul>
<li>每个顶点出现且仅<strong>出现一次</strong></li>
<li>若顶点A出现在顶点B的前面，则<strong>不出现由B到A的路径</strong></li>
</ul>
<p>每个AOV网都有一个或多个拓扑排序序列。</p>
<p>对一个AOV网进行拓扑排序的步骤：</p>
<ul>
<li>从AOV网中选择一个没有前驱的顶点并输出</li>
<li>从网中删除该顶点和所有以它为起点的有向边</li>
<li>重复以上两步，直到当前的AOV网为空或当前网中不存在无前驱的顶点为止，后一种情况说明有向图中必然存在环。</li>
</ul>
<h3 id="关键路径"><a class="header" href="#关键路径">关键路径</a></h3>
<p>AOE网：用<strong>边表示活动的网络</strong>；以顶点表示事件，以有向边表示活动，以<strong>边上的权值</strong>表示完成该活动的<strong>开销</strong>（例如完成活动所需时间）。</p>
<p>AOE网和AOV网都是有向无环图，不同之处在于其边和顶点表示的含义不同，AOE网中的边有权值；AOV网中的边无权值，仅表示前后关系。</p>
<p>AOE网具有的性质：</p>
<ul>
<li>只有某顶点代表的事情发生后，从该顶点出发的各有向边所代表的活动才能开始</li>
<li>只有进入某顶点的各有向边所代表的活动都已结束时，该顶点代表的事件才能发生</li>
</ul>
<p>AOE网中仅有一个入度为0的顶点，称为开始顶点（源点），代表整个工程的开始；网中也仅存在一个出度为0的顶点，称为结束顶点（汇点），表示整个工程的结束。</p>
<p>从源点到汇点的所有路径中，具有<strong>最大路径长度</strong>的路径称为关键路径，关键路径上的活动称为关键活动。只要找到了关键活动就找到了关键路径。</p>
<p>一些寻找关键活动是用到的参量：</p>
<p><strong>事件$v_k$的最早发生时间$ve(k)$</strong></p>
<p>只从源点$v_1$到顶点$v_k$的最长路径长度。时间$v_k$的最早发生时间代表了所有从$v_k$开始的活动能够开工的最早时间。</p>
<p><strong>事件$v_k$的最迟发生时间$vl(k)$</strong></p>
<p>在不推迟整个工程完成的前提下，即保证后继时间$v_j$在最迟发生时间$vl(j)$能够发生时，该事件最迟必须发生的时间。</p>
<p>可以用以下公式进行计算：</p>
<ul>
<li>$vl(汇点)=ve(汇点)$</li>
<li>$vl(k)=\text{Min}{vl(j)-\text{Weight}(v_k,v_j)}$，$v_k$为$v_j$的任意前驱</li>
</ul>
<p><strong>活动$a_i$的最早开始时间$e(i)$</strong></p>
<p><strong>活动$a_i$的最早开始时间$l(i)$</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="基本概念-2"><a class="header" href="#基本概念-2">基本概念</a></h2>
<ul>
<li>查找：在数据集合中寻找满足某种条件的数据元素的过程。查找的结果分为查找成功和失败。</li>
<li>查找表（查找结构）：用于查找的数据集合。有同一类型的数据元素组成。可以是一个数据或链表等数据结构。对查找表进行的操作有：
<ul>
<li>查找某特定元素是否在查找表中；</li>
<li>检索满足条件的某特定的数据元素的各种属性；</li>
<li>在查找表中插入一个数据元素；</li>
<li>从查找表中删除一个数据元素。</li>
</ul>
</li>
<li>静态查找表：只涉及以上1和2两个操作。动态查找表：能够动态地插入和删除数据元素。
<ul>
<li>静态查找表的方法：顺序、折半、散列查找</li>
<li>动态查找表的方法：二叉排序树的查找、散列查找</li>
</ul>
</li>
<li>关键字：数据元素中唯一标识该元素的某个数据项</li>
<li>平均查找长度</li>
</ul>
<h2 id="顺序查找和折半查找"><a class="header" href="#顺序查找和折半查找">顺序查找和折半查找</a></h2>
<h3 id="顺序查找"><a class="header" href="#顺序查找">顺序查找</a></h3>
<p>又称线性查找。对顺序表和链表都适用。</p>
<h3 id="折半查找"><a class="header" href="#折半查找">折半查找</a></h3>
<p>又称二分查找，适用于有序的顺序表。该查找方法仅适合于顺序存储结构，且要求元素按关键字有序排列。</p>
<h3 id="分块查找"><a class="header" href="#分块查找">分块查找</a></h3>
<p>又称索引顺序查找，吸收了顺序和折半查找的优点。既有动态结构，又适合于快速查找。</p>
<p>基本思想：将查找表分为若干子块，字块之间是有序的，块内的元素可以无序，即第一个块中的最大关键字小于第二个块中的所有关键字，以此类推。再建立一个索引表，索引表中的每个元素含有各块的最大关键字和第一个元素的地址。</p>
<p>步骤：第一步再索引表中确定待查记录所在的块，可以使用顺序或折半查找；第二步是在块内查找。</p>
<h2 id="b树和b树"><a class="header" href="#b树和b树">B树和B+树</a></h2>
<h3 id="b树"><a class="header" href="#b树">B树</a></h3>
<p><strong>概念</strong></p>
<p><strong>B树的高度（磁盘存取次数</strong></p>
<p><strong>B树的查找</strong></p>
<p>包含两个基本操作：</p>
<ul>
<li>在B树中找结点</li>
<li>在结点内找关键字</li>
</ul>
<p><strong>B树的插入</strong></p>
<p><strong>B树的删除</strong></p>
<h3 id="b树-1"><a class="header" href="#b树-1">B+树</a></h3>
<p>是B树的一种变形。一个B+树要满足以下条件：</p>
<p><strong>与B树的差异</strong></p>
<h2 id="散列表"><a class="header" href="#散列表">散列表</a></h2>
<h3 id="基本概念-3"><a class="header" href="#基本概念-3">基本概念</a></h3>
<ul>
<li>散列函数：一个把查找表中的关键字映射成该关键字对应的地址的函数，记为：Hash(key)=Addr（这里的地址可以是数组下标、索引或内存地址等）</li>
</ul>
<p>散列函数可能会把多个不同关键字映射到同一地址，这种情况称为冲突，这些<strong>发生碰撞的不同关键词</strong>称为<strong>同义词</strong>。一方面我们要避免冲突，另一方面要设计好处理冲突的方法。</p>
<ul>
<li>散列表：根据关键字而直接进行访问的数据结构，即建立了<strong>关键字</strong>和<strong>存储地址</strong>之间的一种直接映射。理想状况下对散列表进行查找的时间复杂度为O(1)，与表中元素个数无关。</li>
</ul>
<h3 id="散列函数的构造方法"><a class="header" href="#散列函数的构造方法">散列函数的构造方法</a></h3>
<p>构造散列函数时的注意事项：</p>
<ul>
<li>散列函数的定义域要包含全部的关键字，而值域范围则依赖于散列表大小或地址范围。</li>
<li>散列函数计算出的地址应该能等概率、均匀地分布在整个地址空间中</li>
<li>散列函数应尽量简单，能在较短时间内计算出任一关键字对应的散列地址。</li>
</ul>
<p><strong>直接定址法</strong></p>
<p><strong>除留余数法</strong></p>
<p><strong>数字分析法</strong></p>
<p><strong>平方取中法</strong></p>
<h3 id="处理冲突的方法"><a class="header" href="#处理冲突的方法">处理冲突的方法</a></h3>
<p>发生冲突时的处理方法，即为产生冲突的关键字寻找下一个空的Hash地址。</p>
<p><strong>开放定址法</strong></p>
<p>开放定址法指的是可存放新表项的空闲地址既向它的同义表项开放。数学递推公式为：
$$
H_i=(H(key)+d_i)%m
$$
$H(key)$为散列函数；i=0,1,2,...,k；m表示散列表表长；$d_i$为增量序列。</p>
<p>取定某一增量序列后，对应处理方法就确定了，通常有以下四种取法：</p>
<ul>
<li>线性探测法：$d_i=0,1,2,...,m-1$。冲突发生时，顺序查看表中下一个单元，直到找出一个空闲地址或查遍全表。这种方法可能会造成大量元素在相邻散列地址上的聚集，大大降低了查找效率。</li>
<li>平方探测法：$d_i=0^2,1^2,-1^2,2^2,-2^2,...,k^2,-k^2$。其中$k\leq m/2$，散列表m的长度m必须是一个可以表示成4k+3的素数。平方探测法可变避免堆积，但是不能探测到散列表上的所有单元。</li>
<li>再散列法：$d_i=Hash_2(key)$。需要使用两个散列函数。</li>
<li>伪随机序列法：$d_i=伪随机序列$。</li>
</ul>
<p><strong>拉链法</strong></p>
<p>把所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。这种方法适用于经常进行插入和删除的情况。</p>
<h3 id="散列查找及性能分析"><a class="header" href="#散列查找及性能分析">散列查找及性能分析</a></h3>
<p>查找过程的具体举例见书上。</p>
<p><strong>性能分析</strong></p>
<ul>
<li>
<p>虽然散列表建立了关键字与记录的存储位置之间的直接映射，但由于冲突的存在，导致查找过程仍是一个给定值和关键字的比较过程，仍需以<strong>平均查找长度</strong>衡量散列表的查找效率。</p>
</li>
<li>
<p>装填因子：定义为一个表的装满程度，即：
$$
\alpha=\frac{表中记录数n}{散列表长度m}
$$
散列表的平均查找长度伊朗与装调因子a，而不直接依赖于n或m。a越大，装填得越慢，发生冲突的可能性越大。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="基本概念-4"><a class="header" href="#基本概念-4">基本概念</a></h2>
<h3 id="排序的定义"><a class="header" href="#排序的定义">排序的定义</a></h3>
<p>排序是重新排列列表中的元素，使表中的元素按关键字有序的过程。</p>
<ul>
<li>算法的稳定性：若待排序表中有两个元素$R_i$和$R_j$，二者对应的关键字相同，且i在j的前面，若使用某一排序算法后i仍然在j的前面，则称该算法是稳定的，否则不稳定。</li>
</ul>
<p>根据排序过程中数据元素是否完全在内存中，可以将排序算法分为：</p>
<ul>
<li>内部排序：排序期间元素全部存放在内存中。</li>
<li>外部排序：排序期间元素无法全部同时存放在内存中，必须在排序过程中不断按照要求在内、外存之间移动的排序。</li>
</ul>
<p>内部排序算法在执行过程中一般都要进行两种操作：比较和移动。通过比较关键字的大小，确定对应元素的前后关系，然后通过移动元素以达到有序。</p>
<h2 id="插入排序"><a class="header" href="#插入排序">插入排序</a></h2>
<p>每次将一个待排序的记录按其关键字大小插入前面已排好序的子序列，直到全部记录插入完成。</p>
<h3 id="直接插入排序"><a class="header" href="#直接插入排序">直接插入排序</a></h3>
<p>无序序列的第一个元素为有序，首先从第二个元素开始到无序序列的末尾，依次找出每个元素在前面已经排好序的序列中的位置；然后将该位置后的所有元素依次向后移动一位；最后将元素插入该位置。以此类推。</p>
<p>代码实现如下：</p>
<pre><code class="language-c">void InsertSort(ElemType A[], int n) {
	int i, j;
	for (i = 2; i &lt;= n; i++)
	{//从第二位元素开始，将无序序列的每个元素都插入有序序列中
		if (A[i] &lt; A[i-1]) {	//如果当前元素小于前一位元素，即小于有序序列的最后一位，则执行插入操作；否则直接放在有序序列的最后一位。
			A[0] = A[i];	//A[0]不存放元素，作为哨兵
			for (j = i-1; A[j] &gt; A[0]; j--)	//将当前位置后的所有元素依次向后移动一位
				A[j+1] = A[j];
			A[j+1] = A[0];
		}
	}
}
</code></pre>
<p><strong>性能分析</strong></p>
<ul>
<li>
<p>空闲复杂度：$O(1)$</p>
</li>
<li>
<p>时间复杂度：$O(n^2)$</p>
</li>
<li>
<p>稳定性：直接插入算法是一个<strong>稳定</strong>的排序算法</p>
</li>
<li>
<p>适用性：适用于顺序存储和链式存储的线性表</p>
<blockquote>
<p>大部分排序算法都只适用于顺序存储的线性表</p>
</blockquote>
</li>
</ul>
<h3 id="折半插入排序"><a class="header" href="#折半插入排序">折半插入排序</a></h3>
<p>该方法将比较和移动分离。先折半查找出元素的待插入位置，然后统一地移动待插入位置之后的所有元素。</p>
<p>代码实现如下：</p>
<pre><code class="language-c">void InsertSort(ElemType A[], int n) {
	int i, j, low, high, mid;
	for (i = 2; i&lt;= n; i++) {
		A[0] = A[i];
		low = 1; high = i - 1;	//折半查找的范围
		while (low &lt;= high) {	//折半查找
			mid = (low + high) / 2;
			if (A[mid] &gt; A[0])	high = mid - 1;
			else low = mid + 1;
		}
		for (j = i - 1; j &gt;= high + 1; --j)
			A[j + 1] = A[j];	//统一后移操作，空出插入位置
		A[high + 1] = A[0];
	}
}
</code></pre>
<p><strong>性能分析</strong></p>
<p>折半插入排序仅减少了比较元素次数，约为$O(n\log_2 n)$，该比较次数只与n有关；元素的移动次数并未改变，依赖于排序表的初始状态。因此，折半插入排序的时间复杂度仍$为O(n^2)$，但对于数据量不大的排序表，有着较好的性能。折半排序是一种稳定的排序方法。</p>
<h3 id="希尔排序"><a class="header" href="#希尔排序">希尔排序</a></h3>
<p>基本思想：将待排序表分割为<strong>若干个等长的子表</strong>，即把相隔某个增量的所有元素组成一个子表，对各个子表分别进行插入排序，当整个表中的元素已经基本有序时，在对全体记录进行依次直接插入排序。局部有序性。</p>
<p>增量即为划分的子序列的个数。</p>
<p>增量序列的常用方法有：$d_1=n/2,$，$d_{i+1}=d_i/2$.</p>
<p>代码实现如下：</p>
<pre><code class="language-c">void ShellSort(ElemType A[], int n) {
    for (dk = n/2; dk &gt;= 1; dk = dk/2)	//步长变化
        for (i = dk + 1; i &lt;= n; ++i)
            
        
}
</code></pre>
<p><strong>性能分析</strong></p>
<p>空间复杂度：$O(1)$</p>
<p>时间复杂度：依赖于增量序列的函数，当n在某个特定范围时，希尔排序的时间复杂度为$O(n^{1.3})$，最坏情况下的时间复杂度为$O(n^2)$</p>
<p>稳定性：希尔排序是一个<strong>不稳定</strong>的排序方法</p>
<p>适用性：适用于线性表为顺序存储的情况。</p>
<h2 id="交换排序"><a class="header" href="#交换排序">交换排序</a></h2>
<p>根据序列中两个元素关键字的比较结果来对换这两个记录在序列中的位置。</p>
<h3 id="冒泡排序"><a class="header" href="#冒泡排序">冒泡排序</a></h3>
<p>基本思想：从后往前后从前往后<strong>两两比较相邻元素</strong>，若为逆序（$A[i-1]&gt;A[i]$），则交换它们，直到序列比较完。称为第一趟冒泡，结果是将最小的元素交换到待排序列的第一个位置。下一趟冒泡时，前一趟最小的元素将不再参与，以此类推，最多做n-1趟冒泡就能把所有元素排好序。</p>
<p><strong>性能分析</strong></p>
<p>空间复杂度：$O(1)$</p>
<p>时间复杂度：最坏时为$O(n^2)$，平均也为$O(n^2)$</p>
<p>稳定性：<strong>稳定</strong>，即元素相等时不会发生交换。</p>
<h3 id="快速排序"><a class="header" href="#快速排序">快速排序</a></h3>
<p>是基于分治的思想，在待排序表中任取一个元素pivot作为轴枢元素，通过一趟排序将排序表划分为两个部分$L[1....k-1]$和$L[k+1....n]$，使得$L[1....k-1]$中的所有元素小于pivot，$L[k+1....n]$中的所有元素大于pivot，此时pivot放在了其最终位置L(k)上，然后分别对两个子表重复上述过程，直至每部分内只有一个元素或为空，所有元素就都放在了最终位置。</p>
<p>快速排序算法的关键在于<strong>划分操作</strong>，而考研数学考察的快速排序的划分操作为每次总以当前表中<strong>第一个元素</strong>作为枢轴对表进行划分。</p>
<pre><code class="language-c">void QuickSort(ElemType A[], int low, int high) {
	if (low &lt; high) {
		int pivotpos = Partition(A, low, high);	//划分
		QuickSort(A, low, pivotpos - 1);	//依次对两个子表进行递归排序
		QuickSort(A, pivotpos + 1, high);
	}
}
int Partition(ElemType A[], int low, int high) {
	ElemType pivot = A[low];	//将当前表的第一个元素设置为轴枢，对表进行划分
    while (low &lt; high) {
        while (low &lt; high &amp;&amp; A[high] &gt;= pivot)	--high;
        A[low] = A[high];	//比轴枢小的元素移动到左端
        while (low &lt; high &amp;&amp; A[low] &lt;= pivot)	++low;
        A[high] = A[low];	//比轴枢大的元素移动到右端
    }
    A[low] = pivot;	//轴枢元素移动到最终位置
    return low;	//f
}
</code></pre>
<p><strong>性能分析</strong></p>
<p>空间复杂度：递归过程需要借助一个递归工作栈，最好的情况为$O(\log_2 n)$；最坏情况下栈的深度为$O(n)$，平均情况下为$O(\log_2 n)$</p>
<p>时间复杂度：平均情况下为$O(n\log_2 n)$</p>
<p>快速排序是<strong>所有内部排序算法</strong>中<strong>平均性能最优</strong>的排序算法。</p>
<h2 id="选择排序"><a class="header" href="#选择排序">选择排序</a></h2>
<h3 id="简单选择排序"><a class="header" href="#简单选择排序">简单选择排序</a></h3>
<p>基本思想：每一趟（例如第i趟）在后面n-i+1个待排元素中选取关键字最小的元素，作为有序子序列的第i个元素，直到第n-1趟做完，待排序元素只剩下一个，就不用再选了。</p>
<p><strong>性能分析</strong></p>
<ul>
<li>空间复杂度：$O(1)$</li>
<li>时间复杂度：元素移动操作次数较少，但比较次数较多，时间复杂度为$O(n^2)$</li>
<li>稳定性：不稳定，可能导致相同关键字元素顺序变化</li>
</ul>
<h3 id="堆排序"><a class="header" href="#堆排序">堆排序</a></h3>
<p><strong>堆的定义</strong></p>
<p>n个关键字序列L[1...n]称为堆，满足：</p>
<ul>
<li>L(i)&gt;L(2i)且L(i)&gt;=L(2i+1)或</li>
<li>L(i)&lt;L(2i)且L(i)&lt;=L(2i+1)</li>
</ul>
<p>可以将该一维数组视为一颗完全二叉树，满足上面第一个条件的称为<strong>大根堆（大顶堆）</strong>，大根堆的最大元素存放在根结点，且任一非根结点的值小于等于其双亲结点值。满足第二个条件的称为<strong>小根堆</strong>，定义刚好相反，根结点为最小元素。</p>
<p><strong>堆排序</strong></p>
<p>算法思路：首先将存放在L[1...n]中的n个元素建成初始堆（大顶堆），堆顶元素就是最大值。输出堆顶元素后，将堆底元素送入堆顶，此时根结点已经不满足大顶堆的性质，堆被破坏，将堆顶元素向下调整使其继续保持大顶堆的性质，再输出堆顶元素。如此重复，直到堆中仅剩一个元素为止。</p>
<p>堆排序的两个主要问题：</p>
<ul>
<li>如何将无序序列构造为堆</li>
<li>输出栈顶元素后，如何将剩余元素调整为新的堆</li>
</ul>
<p>以上两个具体算法的分析见书上的例子。</p>
<p><strong>性能分析</strong></p>
<ul>
<li>空间复杂度：$O(1)$</li>
<li>时间复杂度：建堆时间为$O(n)$，进行一次堆调整的时间为$O(\log_2 n)$；堆排序的时间复杂度在最好、最坏和平均情况下都为$O(n\log_2 n)$。</li>
<li>稳定性：不稳定</li>
</ul>
<h2 id="归并排序和基数排序"><a class="header" href="#归并排序和基数排序">归并排序和基数排序</a></h2>
<h3 id="归并排序"><a class="header" href="#归并排序">归并排序</a></h3>
<p>归并是将两个或两个以上的有序表组合成一个新的有序表。假设待排序表含有n个记录，则可将其视为有n个有序的子表，每个子表的长度为1，然后两两归并，得到n/2个长度为2或1的有序表；继续两两归并，如此重复，直到合并成一个长度为n的有序表为止，这种排序方法称为2路归并排序。</p>
<p>Merge()的功能是将前后相邻的两个有序表归并为一个有序表。两段有序表A[low...mid]和A[mid+1...high]存放在同意顺序表的相邻位置，先将它们复制到辅助数组B中。每次从B中的两个段取出一个记录进行关键字比较，将较小者放入A中，当数组B中有一段的下标超出其对应表长时，将另一端的剩余部分直接复制到A中。算法实现如下：</p>
<pre><code>
</code></pre>
<p>递归形式的2路归并排序是基于分治的，过程如下：</p>
<ul>
<li>分解：将含有n个元素的待排序表分成各含n/2个元素的子表，采用2路归并排序算法对两个子表递归地进行排序。</li>
<li>合并：合并两个已经排序的子表得到排序结果。</li>
</ul>
<p><strong>性能分析</strong></p>
<ul>
<li>空间复杂度：辅助单元为n个单元，所以$O(n)$</li>
<li>时间复杂度：每趟归并的时间复杂度为$O(n)$，共需要进行$O(\log_2 n$)趟归并，所以算法的时间复杂度为$O(n\log_2 n)$</li>
<li>稳定性：稳定</li>
</ul>
<h3 id="基数排序"><a class="header" href="#基数排序">基数排序</a></h3>
<h2 id="各种排序算法的比较"><a class="header" href="#各种排序算法的比较">各种排序算法的比较</a></h2>
<h3 id="内部排序算法的比较"><a class="header" href="#内部排序算法的比较">内部排序算法的比较</a></h3>
<p>基于三个因素进行对比：时空复杂度、算法的稳定性、算法的过程特征</p>
<h3 id="内部排序算法的应用"><a class="header" href="#内部排序算法的应用">内部排序算法的应用</a></h3>
<p><strong>选取排序方法时需要考虑的因素</strong></p>
<p><strong>排序算法小结</strong></p>
<h2 id="外部排序"><a class="header" href="#外部排序">外部排序</a></h2>
<h3 id="基本概念-5"><a class="header" href="#基本概念-5">基本概念</a></h3>
<p>前面介绍的排序方法都是在内存中进行的（称为内部排序）。在许多应用中，需要对大文件进行排序，文件中的信息较为庞大，无法将整个文件复制进内存中进行排序。因此需要将待排序的记录存储在外存上，排序时再把数据一部分一部分地调入内存中进行排序，在排序过程中需要多次进行内存和外存之间的交换。</p>
<h3 id="外部排序的方法"><a class="header" href="#外部排序的方法">外部排序的方法</a></h3>
<h3 id="多路平衡归并与败者树"><a class="header" href="#多路平衡归并与败者树">多路平衡归并与败者树</a></h3>
<h3 id="置换-选择排序"><a class="header" href="#置换-选择排序">置换-选择排序</a></h3>
<div style="break-before: page; page-break-before: always;"></div><p>数据的表示和运算：内容复杂，考察重点。</p>
<p>存储系统：考察重点，Cache和虚拟存储器容易出综合体。难点是Cache映射规律、容量计算及替换特性；还有交叉存储器访问时间和访问效率。</p>
<p>指令系统：是表征一台计算机性能的重要因素，出选择题概率较大，单可以和指令流水线结合出大题</p>
<p>中央处理器：难点，容易出综合题。</p>
<p>总线：内容较少，通常出选择题，总线的带宽计算也可能与其他章节结合出综合题。</p>
<p>I/O系统：可能出综合题，特别是I/O方式效率相关计算，中断方式的各种原理，DMA方式的特点、与中断的区别等。</p>
<h2 id="组成原理大题"><a class="header" href="#组成原理大题">组成原理大题</a></h2>
<ul>
<li>定点数的表示与运算和指令系统结合的题目</li>
<li>Cache缓存系统相关题目</li>
<li>指令系统相关</li>
<li>CPU数据通路和前面相结合的题目</li>
<li>流水线结合指令执行过程题目</li>
<li>I/O方式大题</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h2 id="数制与编码"><a class="header" href="#数制与编码">数制与编码</a></h2>
<h3 id="进位计数制机器相互转换"><a class="header" href="#进位计数制机器相互转换">进位计数制机器相互转换</a></h3>
<p><strong>进位计数法</strong></p>
<p>二进制、八进制、十进制、十六进制</p>
<p><strong>不同进制之间的相互转换</strong></p>
<ul>
<li>二进制转换为八进制和十六进制：将一串二进制数分为<strong>3位一组或4位一组，补零</strong>，然后分别用八进制或十六进制数代替。</li>
<li>任意进制转换为十进制：各位数码与权值相乘，再把乘积相加</li>
<li>十进制转化为任意进制数：基数乘除法，对十进制数的整数和小数部分分别处理，整数部分采用<strong>除基取余法</strong>（最先取得的余数为最低位，最后取得的余数为最高位），小数部分采用<strong>乘基取整法</strong>（最先取得的整数位最高位，最后取得的整数位为最低位）。</li>
</ul>
<h3 id="真值和机器数"><a class="header" href="#真值和机器数">真值和机器数</a></h3>
<p>真值：正负数，是机器数代表的实际值</p>
<p>机器数：把真值数字化为寄存存储的数，常用的有原码、反码、补码</p>
<h3 id="bcd码"><a class="header" href="#bcd码">BCD码</a></h3>
<p>用二进制编码的十进制数，通常用4位二进制数表示一位十进制数字。</p>
<p>8421码：大于1010时要加6修正。</p>
<h3 id="字符与字符串"><a class="header" href="#字符与字符串">字符与字符串</a></h3>
<p>ASCII编码：使用7位二进制编码（每个字节的最高位保持为0，可用于传输时的奇偶校验），可以表示10个十进制数、52个大小写英文字母，以及一些专用符号。</p>
<ul>
<li>编码值0-31：控制字符</li>
<li>编码值127是DEL码；编码值32是空格SP</li>
<li>编码值32-126：可印刷字符</li>
</ul>
<p>0-9的ASCII值为48-57</p>
<p><strong>汉字的编码和表示</strong></p>
<p>汉字的编码包括汉字的<strong>输入编码、汉字内码、汉字字形码</strong>三种，是计算机用于输入、内部处理、输出的三种编码。</p>
<p>国标码、区位码、汉字内码。</p>
<h3 id="校验码"><a class="header" href="#校验码">校验码</a></h3>
<p>数据校验码的码距：任意两个合法码字之间最少变化的二进制位数</p>
<p>对于码距不小于2的数据校验码，开始具有检错能力。</p>
<p><strong>奇偶校验码</strong></p>
<p><strong>海明校验码</strong></p>
<p><strong>CRC码</strong></p>
<p>在K位信息码后再拼接R位校验码，整个编码长度为N位，所以又称(N,K)编码。</p>
<p>发送端首先将K位信息位左移R位，将其与多项式G(x)作模2除法，生成一个R位校验码，附在信息码后，得到N位编码。</p>
<p>生成多项式G(x)的最高幂次为R，转换成对应二进制码为R+1位。</p>
<p>接收端用生成多项式G(x)作模2除法，余数为0则没有错误。</p>
<h2 id="定点数的表示和运算"><a class="header" href="#定点数的表示和运算">定点数的表示和运算</a></h2>
<h3 id="定点数的表示"><a class="header" href="#定点数的表示">定点数的表示</a></h3>
<p><strong>无符号数和有符号数</strong></p>
<p>无符号数：整个机器字长的所有二进制位<strong>均为数值位，没有符号位</strong></p>
<p>有符号数：有符号数用0表示正号，用1表示负号，从而将符号数值化，通常约定二进制数的最高位为符号位。</p>
<p>有符号数的<strong>机器表示</strong>有<strong>原码、补码、反码和移码</strong>。</p>
<p><strong>机器数的定点表示</strong></p>
<p>根据<strong>小数点的位置是否固定</strong>，计算机中有两种数据格式：定点表示和浮点表示。</p>
<p>定点表示约定机器数中的小数点位置固定不变，计算机中通常采用两种简单的约定：将小数点固定在<strong>最高位之前(定点小数)</strong>，或固定在<strong>最低位之后(定点整数)</strong>。</p>
<ul>
<li>定点小数：是<strong>纯小数</strong>，约定小数点位置在符号位之后，有效数值部分最高位之前。表示范围为$1-2^{-n} \to -(1-2^{-n})$</li>
<li>定点整数：是<strong>纯整数</strong>，约定小数点位置在有效数值部分最低为之后。</li>
</ul>
<p><strong>原码、补码、反码、移码</strong></p>
<ul>
<li>原码：用机器数的<strong>最高位</strong>表示该数的<strong>符号</strong>，其余各位表示数的绝对值</li>
<li>补码：补码中的加减法同一采用加法操作实现</li>
<li>反码：由原码求补码或补码求原码的中间过渡</li>
<li>移码：用来表示浮点数的阶码，只能表示整数。
<ul>
<li>$[x]_{移}=2^n+x$（机器字长为n+1）</li>
</ul>
</li>
</ul>
<h3 id="定点数的运算"><a class="header" href="#定点数的运算">定点数的运算</a></h3>
<p><strong>移位运算</strong></p>
<p>分为算术移位和逻辑移位，有符号数的移位称为算术移位，逻辑移位的操作对象是逻辑代码，可视为无符号数。</p>
<ul>
<li>算术移位：正数的原码、补码和反码都相同，移位后添0即可；负数依据编码形式不同而不同。</li>
<li>逻辑移位：逻辑左移时高位移丢，低位添0；逻辑右移时，低位丢失，高位添0.</li>
<li>循环移位：适合将数据的低字节数据和高字节数据互换</li>
</ul>
<p><strong>原码定点数的加减法运算</strong></p>
<p><strong>补码定点数加减法运算</strong></p>
<p><strong>符号扩展</strong></p>
<p>把采用给定位数表示的数转换成具有不同位数的某种表示形式。</p>
<p><strong>溢出</strong></p>
<p>运算结果超出了数的表示范围。</p>
<p>上溢和下溢。</p>
<p>溢出的判断法：</p>
<ul>
<li>一位符号法：只要参加操作的两个数符号相同，结果又与原操作数符号不同，则表示结果溢出</li>
<li>双符号位法：模4补码</li>
</ul>
<p><strong>定点数的乘法运算</strong></p>
<p>累加和右移操作实现。</p>
<p><strong>定点数的除法运算</strong></p>
<p>累加和左移实现。</p>
<h3 id="c语言中的整数类型及类型转换"><a class="header" href="#c语言中的整数类型及类型转换">C语言中的整数类型及类型转换</a></h3>
<p>C语言变量之间的类型转换是常出现的题目。</p>
<p><strong>有符号数和无符号数的转换</strong></p>
<p>在不同数据类型之间作<strong>强制类型转换</strong>。强制类型转换的结果<strong>保持位值不变，仅改变了解释这些位值的方式</strong>。</p>
<p><strong>不同字长整数之间的转换</strong></p>
<ul>
<li>大字长变量向小字长变量转换：把多余高位字长部分直接截断，低位直接赋值。</li>
<li>短字长整数向长字长整数转换：不仅相应的位值相等，高位部分还会扩展为原数字的符号位。</li>
</ul>
<h3 id="数据的存储和排列"><a class="header" href="#数据的存储和排列">数据的存储和排列</a></h3>
<p><strong>存储方法：大端法和小端法</strong></p>
<p>大端法：按从最高有效字节到最低有效字节的顺序存储数据，即<strong>最高有效字节放在最前面，地址最小</strong>。</p>
<p>小端法：从最低有效字节到最高有效字节存储数据，<strong>最低有效字节放在最前面，地址最小</strong>。</p>
<p><strong>数据按边界对齐方式存储</strong></p>
<p>假设存储字长为32位（每次访存读取1个字，即4字节），可按字节、半字和字进行寻址。对于机器字长为32位的计算机，数据以边界对齐方式存放，半字地址一定是2的整数倍，字地址一定是4的整数倍，这样无论所取的数据是字节、半字还是字，均可一次访存取出。所存储的数据不满足以上要求时通过，通过填充空白字节使其符合要求。虽然浪费了一些空间，但能提高取指令和取数的速度。</p>
<h2 id="浮点数的表示和运算"><a class="header" href="#浮点数的表示和运算">浮点数的表示和运算</a></h2>
<h3 id="浮点数的表示"><a class="header" href="#浮点数的表示">浮点数的表示</a></h3>
<p>以适当的形式将比例因子表示在数据中，让小数点的位置根据需要而浮动。这样在位数有限的情况下既扩大了数的表示范围，又保持了数的有效精度。</p>
<h3 id="浮点数的加减运算"><a class="header" href="#浮点数的加减运算">浮点数的加减运算</a></h3>
<h2 id="算术逻辑运算alu"><a class="header" href="#算术逻辑运算alu">算术逻辑运算（ALU）</a></h2>
<p>计算机中，运算器执行各种算术和逻辑运算，运算器由算术逻辑单元（ALU）、累加器、状态寄存器、通用寄存器等组成。ALU的基本功能包括加减乘除四则运算，与或非异或等<strong>逻辑运算</strong>，以及<strong>移位、求补</strong>等操作。</p>
<p>计算机运行时，运算器的操作和操作种类由控制器决定，运算器处理的数据来自存储器，处理后的结果数据通常送回存储器或暂存在运算器中。</p>
<h3 id="串行加法器和并行加法器"><a class="header" href="#串行加法器和并行加法器">串行加法器和并行加法器</a></h3>
<p>ALU的核心部件为加法器，加法器由<strong>全加器</strong>再配以其他必要逻辑电路组成。根据组成加法器的<strong>全加器个数是单个或多个</strong>，将加法器分为<strong>串行和并行</strong>。</p>
<p><strong>一位全加器</strong></p>
<p><strong>串行加法器</strong></p>
<p>只有一个全加器，数据逐位串行送入加法器中进行运算。若操作数长n位，则加法就要分n次进行，每次产生一位和，并串行地送回寄存器。进位触发器用来寄存进位信号，一边参与下一次运算。</p>
<p><strong>并行加法器</strong></p>
<p>由多个全加器组成，其位数与机器字长相同，各位数据同时运算。存在最长运算时间问题，主要由进位信号的传递时间决定。</p>
<p>并行加法器的进位通常分为<strong>串行进位</strong>和<strong>并行进位</strong>。</p>
<h3 id="算术逻辑单元的功能和结构"><a class="header" href="#算术逻辑单元的功能和结构">算术逻辑单元的功能和结构</a></h3>
<div style="break-before: page; page-break-before: always;"></div><h2 id="存储器概述"><a class="header" href="#存储器概述">存储器概述</a></h2>
<h3 id="分类"><a class="header" href="#分类">分类</a></h3>
<p><strong>按层次分</strong></p>
<ul>
<li>主存储器：内存，CPU可直接随机对其访问</li>
<li>辅助存储器：外存，是主存储器的后援存储器，用来存放当前暂时不用的程序和数据，以及需要永久保存的数据</li>
<li>高速缓冲存储器：位于主存和CPU之间，用来存放正在执行的程序段和数据，存取速度可与CPU的速度匹配</li>
</ul>
<p><strong>按存取方式</strong></p>
<ul>
<li>随机存储器(RAM)：又分为SRAM和DRAM</li>
<li>只读存储器(ROM)：断电保留内容，随机读写特性，但写入比读取慢得多。</li>
<li>串行访问存储器：对存储单元进行读写操作时，需要按其物理位置的先后顺序寻址。(磁带)</li>
</ul>
<p><strong>按信息的可保存性分</strong></p>
<p>易失性：断电后存储信息消失。</p>
<p>非易失性：断电后信息仍然保持。</p>
<h3 id="性能指标"><a class="header" href="#性能指标">性能指标</a></h3>
<p><strong>存储容量</strong></p>
<p>=存储字数*字长；存储字数表示存储器<strong>地址空间的大小</strong>，字长表示<strong>一次存取操作的数据量</strong>。</p>
<p><strong>单位成本</strong></p>
<p>每位价格=总成本/总容量</p>
<p><strong>存储速度</strong></p>
<ul>
<li>存取时间：从启动一次存储器操作到完成该操作所经历的时间</li>
<li>存取周期：存储器进行一次完整的读写操作所需要的全部时间</li>
<li>主存带宽：又称数据传输率，每秒从主存进出信息的最大数量</li>
</ul>
<p>存取时间不等于存储周期，通常<strong>存取周期大于存取时间</strong>，因为对于任何一种存储器，读写操作后总要有一段<strong>恢复内部状态的复原时间</strong>。</p>
<h2 id="存储器的层次化结构"><a class="header" href="#存储器的层次化结构">存储器的层次化结构</a></h2>
<p>多级存储系统，用来解决存储器大容量、高速度和低成本3个相互制约的矛盾。</p>
<ul>
<li>
<p>Cache-主存：解决CPU和主存速度不匹配的问题</p>
</li>
<li>
<p>主存-辅存：解决存储系统的容量问题</p>
</li>
</ul>
<p>辅存要通过主存和CPU交换信息，主存与CPU、Cache、辅存都能交换信息。</p>
<p>主存和Cache之间的数据调动是由硬件自动完成的，对<strong>所有程序员</strong>都透明；主存和辅存之间（虚拟内存管理）的数据调动是由<strong>硬件和操作系统</strong>共同完成的，对<strong>应用程序员</strong>透明。</p>
<h2 id="半导体随机存储器"><a class="header" href="#半导体随机存储器">半导体随机存储器</a></h2>
<p>主存由DRAM实现，Cache由SRAM实现，都属于易失性存储器。</p>
<h3 id="sram和dram"><a class="header" href="#sram和dram">SRAM和DRAM</a></h3>
<p><strong>SRAM</strong></p>
<p>把存放一个二进制位的物理器件称为<strong>存储元</strong>，是存储器最基本的构件。地址码相同的多个存储元构成一个<strong>存储单元</strong>。若干存储单元的集合构成<strong>存储体</strong>。</p>
<p>SRAM用双稳态触发器（6个晶体管）来记忆信息，是非破坏性读取。</p>
<p>SRAM存储速度快，但集成度低，功耗较大，一般用来作高速缓存。</p>
<p><strong>DRAM</strong></p>
<p>利用存储元电路中栅极电容上的电荷来存储信息，只使用一个晶体管，比SRAM密度高很多。</p>
<p>DRAM采用<strong>地址复用技术</strong>，地址线是原来的1/2，地址信号分行、列两次传送。</p>
<p>DRAM相对于SRAM来说容易集成、价位低、容量大，但存取速度慢。</p>
<p>DRAM电容上的电荷一般只能维持1-2ms，即使电源不断电，信息也会自动消失。为此必须每隔一定时间刷新，时间一般设为<strong>2ms</strong>，称为<strong>刷新周期</strong>，常用刷新方式有：</p>
<ul>
<li><strong>集中</strong>刷新：在一个刷新周期内<strong>取一段固定时间</strong>依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为<strong>死时间</strong>，又称访存死区。优点是读写操作不受刷新影响，缺点是在集中刷新期间不能进行读写操作。</li>
<li><strong>分散</strong>刷新：把对每行的刷新<strong>分散到各个工作周期</strong>中；由此一个存储器的系统工作周期分为两部分：前半部分用于正常读写或保持；后半部分用于刷新。这种方式增加了系统的存取周期，降低了整机速度，优点是<strong>没有死区</strong>。</li>
<li><strong>异步</strong>刷新：是前两种方法的结合，既能缩短死时间，又能充分利用最大刷新间隔为2ms的特点。将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求，这样可以避免使CPU连续等待过长时间，并且减少刷新次数。</li>
</ul>
<p>刷新对CPU是透明的，不依赖于外部的访问；DRAM刷新的是行，由芯片内部自行生成行地址。刷新时不需要片选，即存储整个器中的所有芯片同时被刷新。</p>
<p><strong>存储芯片内部的结构</strong></p>
<ul>
<li>存储体（存储矩阵）：是存储单元的集合，由行选择线（X）和列选择线（Y） 来选择所访问单元。存储体相同行、列上的单元同时被读出或写入。</li>
<li>地址译码器</li>
<li>I/O控制电路</li>
<li>片选控制信号</li>
<li>读/写控制信号</li>
</ul>
<h3 id="只读存储器rom"><a class="header" href="#只读存储器rom">只读存储器ROM</a></h3>
<p>类型：掩膜式、一次可编程只读、可擦除可编程只读、闪存、固态硬盘。</p>
<h3 id="主存储器的基本组成"><a class="header" href="#主存储器的基本组成">主存储器的基本组成</a></h3>
<p>一个个存储0或1的记忆单元构成的存储矩阵是存储器的核心部分。为了存取存储体中的信息，必须对存储单元进行<strong>编址</strong>，现代计算机通常采用<strong>字节编址</strong>方式，此时存储体内的一个地址中有1个字节。</p>
<p>指令执行过程需要访问主存时，CPU首先把访问单元的<strong>地址</strong>送到MAR中，然后通过地址线将主存地址送到主存中的地址寄存器，以便地址译码器进行译码选中相应的单元，同时CPU将<strong>读写控制信号</strong>通过控制线送到主存的读写控制电路。如果是写操作，CPU同时将要写的信息送入MDR中，在读写控制电路的作用下，经数据线将信号写入写中的单元；如果是读操作，那么主存读出选中的单元的内容送到数据线，然后送到MDR中。</p>
<p>数据线的宽度与MDR的宽度相同，地址线的宽度与MAR的相同。64位数据线按照字节编址的方式下，最多可以存取8个单元（8字节，字节编址下每个单元1B）的内容。<strong>地址线的位数</strong>决定了主存地址空间的<strong>最大可寻址范围</strong>。</p>
<p>数据线数和地址线数共同反映了存储体容量的大小。</p>
<h2 id="主存储器与cpu的连接"><a class="header" href="#主存储器与cpu的连接">主存储器与CPU的连接</a></h2>
<h3 id="连接原理"><a class="header" href="#连接原理">连接原理</a></h3>
<ul>
<li>主存通过<strong>数据总线、地址总线和控制总线</strong>与CPU相连</li>
<li>数据总线的位数与工作频率的乘积正比于数据传输率</li>
<li>地址总线的位数取决于可寻址的最大内存空间</li>
<li>控制总线（读/写）指出本次总线周期的类型以及本次输入/输出操作完成的时刻</li>
</ul>
<h3 id="主存容量的扩展"><a class="header" href="#主存容量的扩展">主存容量的扩展</a></h3>
<p><strong>位扩展法</strong></p>
<p>对<strong>字长</strong>进行补充，即增加存储单元的字长，使得<strong>数据位数</strong>与CPU的数据线数相等。</p>
<p>仅仅采用位扩展时，各芯片连接地址线的方式相同，但<strong>连接数据线的方式不同</strong>，片选信号要连到所有芯片。</p>
<p>eg：利用8片8K*1位的RAM芯片组成8K*8位的存储器。</p>
<p><strong>字扩展法</strong></p>
<p>增加存储器中<strong>存储单元(字)<strong>的数量，位数不变。字扩展将芯片的地址线、数据线、读写控制线相并联，由片选信号区分各芯片的地址范围。相当于</strong>增加地址线的数量</strong>。</p>
<p>仅采用字扩展时，各芯片连接地址线的方式相同，连接数据线的方式也相同，但某个时刻只需要<strong>选中部分芯片</strong>，所以通过<strong>片选</strong>芯片或采用<strong>译码器</strong>设计连接到相应的芯片。</p>
<p>eg：用4片16K*8位的RAM芯片组成64K*8位的存储器。</p>
<p><strong>字位同时扩展</strong></p>
<p>既改变字长，又改变地址数。</p>
<h3 id="存储芯片的地址分配和片选"><a class="header" href="#存储芯片的地址分配和片选">存储芯片的地址分配和片选</a></h3>
<p>CPU实现<strong>对存储单元的访问</strong>，首先要选择存储芯片，即进行<strong>片选</strong>，然后为选中的芯片依地址码选择相应的存储单元，进行数据的存储，即进行<strong>字选</strong>。片内的字选通常由CPU送出的N条<strong>低地址线</strong>完成，地址线直接接到所有存储芯片的地址输入端。</p>
<p>片选和字选都相当于通过地址线进行选择。</p>
<p>片选信号的产生分为线选法和译码片选法。</p>
<p><strong>线选法</strong></p>
<p>用除了片内寻址外的<strong>高位地址</strong>线直接分别连接到各个存储芯片的<strong>片选端</strong>，当某地址线信息为0时，选中与之对应的存储芯片。片选地址线每次寻址时只能有一位有效，不允许同时多位有效。（例如0号芯片地址为1110，1号芯片地址为1101，2号芯片地址为1011，3号芯片地址为0111）</p>
<p>缺点：地址空间不连续，不能充分利用系统的存储器空间，造成地址资源的浪费。</p>
<p><strong>译码片选法</strong></p>
<p>用除片内寻址外的高位地址线通过<strong>地址译码器</strong>芯片产生片选信号。</p>
<h2 id="双端口ram和多模块存储器"><a class="header" href="#双端口ram和多模块存储器">双端口RAM和多模块存储器</a></h2>
<p>为了提高CPU访问存储器的速度，使用双端口存储器、多模块存储器等技术。</p>
<h3 id="双端口ram"><a class="header" href="#双端口ram">双端口RAM</a></h3>
<p>双通道内存。</p>
<p>一个存储器有左右两个独立的端口，分别具有<strong>两组相互独立的地址线、数据线和读写控制线</strong>。允许两个独立的控制器<strong>同时异步地</strong>访问存储单元。</p>
<p>当两个端口的<strong>地址不相同时</strong>，在两个端口上进行读写操作一定不会发生冲突。</p>
<p>两个端口同时存取存储器的<strong>同一地址单元</strong>时，会因数据冲突造成数据存储或读取错误。共有以下4中情况：</p>
<ul>
<li>两个端口<strong>不同时</strong>对同一地址单元<strong>读写</strong>数据</li>
<li>两个端口<strong>同时</strong>对同一地址单元<strong>读取</strong>数据</li>
<li>两个端口<strong>同时</strong>对同一地址单元<strong>写入</strong>数据</li>
<li>两个端口<strong>同时</strong>对同一地址单元操作，<strong>一个写入数据，一个读取数据</strong></li>
</ul>
<p>前两种不会出现错误，第三种出现写入错误，第四种出现读写错误。</p>
<p>解决方法：置忙信号BUSY位0，由判断逻辑决定<strong>暂时关闭一个端口</strong>，未被关闭的端口正常访问，被关闭的端口延长一个很短的时间后再访问。</p>
<h3 id="多模块存储器"><a class="header" href="#多模块存储器">多模块存储器</a></h3>
<p>常用的有单体多字存储器和多体低位交叉存储器。</p>
<p><strong>单体多字存储器</strong></p>
<p>只有一个存储器，每个存储单元存储m个字，总线宽度也为m个字。一次并行读出m个字，地址必须顺序排列并处于同一存储单元。</p>
<p>该系统在一个存取周期内，从同一地址取出m条指令，然后将指令逐条送至CPU执行，即每个1/m存取周期，CPU向主存取一条指令，这增大了存储器的带宽，提高了工作速度。</p>
<p>缺点：指令和数据必须在内存中连续存放，遇到转移指令，这种方法的效果就不明显了。</p>
<p><strong>多体并行存储器</strong></p>
<p>由多体模块组成，每个模块都有相同的容量和读取速度，每个模块都有相同的容量和读取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。它们既能并行工作，又能交叉工作。</p>
<p>多体并行存储器分为高位交叉编址（顺序方式）和低位交叉编址（交叉方式）两种：</p>
<ul>
<li>高位交叉编址：高位地址表示<strong>体号</strong>，低位地址为<strong>体内地址</strong>。该方式下总是把低位的体内地址送到由高位体号确定的模块内进行译码。CPU总是按顺序访问存储模块，存储模块不能被并行访问，不能提高存储器的吞吐率。</li>
<li>低位交叉编址：低位地址为<strong>体号</strong>，高位地址为<strong>体内地址</strong>。每个模块按照<strong>模m交叉编址</strong>，模块号=单元地址%m，假定有m个模块，每个模块有k个单元，则0,m,...,(k-1)m单元位于$M_0$；第1,m+1,...,(k-1)m+1单元位于$M_1$，以此类推。该编址方式下，总把高位的体内地址送到由低位体号确定的模块内进行译码，程序<strong>连续存放在相邻模块</strong>。采用这种编址方式，可以在不改变每个模块存取周期的前提下，采用流水线方式并行存取，提高存储器带宽。</li>
</ul>
<h2 id="高速缓冲存储器"><a class="header" href="#高速缓冲存储器">高速缓冲存储器</a></h2>
<p>采用存储体系，通常将存储系统分为“Cache-主存”层次和“主存-辅存”层次。</p>
<h3 id="程序访问的局部性原理"><a class="header" href="#程序访问的局部性原理">程序访问的局部性原理</a></h3>
<p>包括<strong>时间局部性</strong>和<strong>空间局部性</strong>。时间局部性指的是最近的未来要用到的信息，很可能是<strong>现在正在使用</strong>的信息，因为程序中存在<strong>循环</strong>。空间局部性是最近的未来要用到的信息，很可能与现在正在使用的信息<strong>在存储空间上是临近</strong>的，因为指令通常是<strong>顺序存放、顺序执行</strong>的，数据一般也以向量、数组等形式存储在一起。</p>
<p>高速缓冲技术利用程序访问的局部性原理，把程序中正在使用的部分存放在一个高速的、容量较小的Cache中，使CPU的访存操作大多针对Cache进行，从而大大提高程序的执行速度。</p>
<h3 id="cache的基本工作原理"><a class="header" href="#cache的基本工作原理">Cache的基本工作原理</a></h3>
<p>为了便于Cache和主存的信息交换，<strong>Cache和主存</strong>都被划分为<strong>相等的块</strong>，Cache块又称为<strong>Cache行</strong>，每块由若干字节组成，块的长度称为<strong>块长</strong>(<strong>Cache行长</strong>)。由于Cache的容量远小于主存容量，所以Cache中的块数要远少于主存中的块数，仅保留主存中最活的若干块的副本。</p>
<p>CPU与Cache（或主存）之间的数据交换以<strong>字</strong>为单位，而Cache与主存之间的数据交换以<strong>Cache块</strong>为单位。</p>
<p>CPU欲访问的信息已在Cache中的比率称为Cache的命中率。设一个程序执行期间，Cache的总命中次数为$N_c$，访问主存的总次数为$N_m$，则命中率$H$为：
$$
H=N_c/(N_c+N_m)
$$
命中率越接近于1越好。</p>
<h3 id="cache和主存的映射方式"><a class="header" href="#cache和主存的映射方式">Cache和主存的映射方式</a></h3>
<p>Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放的主存中的信息按照某种规则装入Cache。</p>
<p>Cache中的行数比主存块数少得多，主存中只有一部分块的信息可以放在Cache中，因此在Cache中要为每块加一个<strong>标记</strong>，指明其是主存中哪一个块的副本。该标记的内容相当于<strong>主存块的编号</strong>。另外为了说明Cahce行中的<strong>信息是否有效</strong>，每个Cache行需要一个<strong>有效位</strong>。</p>
<p><strong>直接映射</strong></p>
<p><strong>主存中的每一块</strong>只能装入Cache中的<strong>唯一位置</strong>。若该位置已有内容，则产生块冲突，原来的块将无条件地被替换出去。这种实现方式较为简单，但不够灵活，即使Cache中的其他许多地址空着也不能占用，这使得直接映射的块<strong>冲突概率最高，空间利用率低</strong>。</p>
<p>直接映射关系可以定义为（取余运算）：
$$
j=i \ \text{mod} \ 2^c
$$
$j$是Cache的行号，$i$是主存的块号，$2^c$是Cache的总块数；这种映射方式中，主存中的第$0$、$2^c$、$2^{c+1}$....块只能映射到Cache的第0行；主存的第$1$、$2^c+1$、$2^{c+1}+1$....块只能映射到Cache的第1行，以此类推。</p>
<p>从这个定义可以得出，主存块号的<strong>低c位</strong>，正好是其要装入的<strong>Cache行号</strong>。给每个Cache行设置一个长为$t=m-c$（m为地址长度）的<strong>标记</strong>，当主存某块调入Cache后，就将其<strong>块号的高t位</strong>设置在对应Cache行的标记中。</p>
<p>CPU访存过程：首先根据访存地址中的<strong>低c位</strong>找到对应的Cache行，将对应Cache行中的<strong>标记</strong>和主存地址的<strong>高t位进行比较</strong>，若相等且有效位为1，则<strong>命中</strong>，此时根据主存中<strong>低位的块内地址</strong>，在对应的Cache行中存取信息；若未命中或有效位为0，则CPU从主存中读取出该地址所在的一块信息送到对应的Cache行中，将有效位置1，并将标记设置为地址中的高t位，同时将内容送入CPU。</p>
<p><strong>全相联映射</strong></p>
<p>主存中的每一块可以装入Cache中的任何位置，<strong>每行的标记</strong>用于指出该行取自<strong>主存的哪一块</strong>，所以CPU访存时需要与所有Cache的行进行比较。</p>
<p>这种方式的优点是比较灵活，Cache块的冲突概率低，空间利用率高，命中率也高；缺点是<strong>标记的比较速度较慢，实现成本较高</strong>。</p>
<p><strong>组相联映射</strong></p>
<p>将Cache空间分为大小相同的组，主存的一个数据块可以装入组内任何一个位置，相当于在<strong>组间采用直接映射</strong>，而<strong>组内采用全相联映射</strong>。</p>
<p>假设<strong>每个组有r个Cache行</strong>，则称之为<strong>r路</strong>组相联。</p>
<p>组相联映射关系可以定义为：
$$
j= i \ \text{mod} \ Q
$$
$j$是Cache行的组号，$i$是主存的块号，$Q$是Cache的组数。</p>
<p>路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。选定适当的适量，可以使组相联映射的成本接近直接映射，而性能上接近全相联映射。</p>
<p>组相联映射的地址结构为：</p>
<p><strong>标记、组号、块内地址</strong></p>
<p>CPU访存过程：首先根据访存地址中的组号找到对应的Cache组；将Cache组中每个行的标记与主存地址的高位标记进行比较，若有一个相等且有效位为1，则访问Cache命中，此时根据主存地址中的块内地址，在对应Cache中存取信息；若都不相等或虽然相等但有效位为0，则不命中，此时CPU从主存中读出该地址所在的信息块并送到Cache对应组的任意一个空闲行，将有效位置1，并设置标记，同时将该地址中的内容送入CPU。</p>
<h3 id="cache中主存块的替换算法"><a class="header" href="#cache中主存块的替换算法">Cache中主存块的替换算法</a></h3>
<p>采用<strong>全相联和组相联</strong>映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的<strong>空间已被占满</strong>时，需要使用替换算法置换Cache行。采用直接映射时，一个给定主存块只能放到唯一的Cache行，当对应Cache行已经有一个主存块存在时，新的主存块会直接把存在的主存块替换掉，无须使用替换算法。</p>
<p><strong>随机算法(RAND)</strong></p>
<p>随机地确定替换的Cache块。实现比较简单，未依据程序访问的局部性原理，命中率较低。</p>
<p><strong>先进先出算法(FIFO)</strong></p>
<p>选择最早调入的行进行替换。比较容易实现，也未依据程序访问的局部性原理，因为最早进入的主存块可能也是目前经常要使用的。</p>
<p><strong>近期最少使用算法(LRU)</strong></p>
<p>依据程序访问的局部性原理，选择近期内长久未访问过的Cache行作为替换的行，平均命中率比FIFO高。</p>
<p>LRU算法为每个Cache行设置一个<strong>计数器</strong>，用计数值来记录主存块的使用情况，并根据计数值选择淘汰某个行，计数值的位数与Cache组大小有关，2路时有1位LRU位，4路时有2位LRU位。</p>
<p>计数器的变化规则：</p>
<ul>
<li>命中时，所命中行的计数器清零，比其低的计数器加1，其余不变；</li>
<li>未命中且有空闲行时，新装入的行的计数器置0，其余全加1；</li>
<li>未命中且无空闲行时，计数值为3的行的信息块被淘汰，新装入的行的计数器置0，其余全加1.</li>
</ul>
<p>当集中访问的存储区超过Cache组大小时，命中率可能变得很低。</p>
<p><strong>最不经常使用算法(LFU)</strong></p>
<p>将一段时间内被访问次数最少的存储行换出，也需要每行设置一个计数器。</p>
<h3 id="cache写策略"><a class="header" href="#cache写策略">Cache写策略</a></h3>
<p>当对Cache中的内容进行<strong>更新</strong>时，就需选用写操作策略使得<strong>Cache内容和主存内容保持一致</strong>。分两种情况：Cache写命中和Cache写不命中。</p>
<p><strong>Cache写命中</strong></p>
<p>写命中时有两种处理方法：</p>
<ul>
<li><strong>全写法</strong>：CPU对Cache写命中时，把数据<strong>同时写入Cache和主存</strong>。当某一块需要替换时，不必把这一块写回主存，用新调入的块直接覆盖即可。这种方法实现简单，能随时保存主存数据的正确性，缺点是增加了访问次数，降低了Cache效率。
<ul>
<li>写缓冲（Write Buffer）：为了减少全写法写入主存时的时间损耗，在Cache和主存之间添加的一个FIFO缓冲队列，可以解决速度不匹配的问题，但若频繁写时，会出现缓冲饱和溢出。</li>
</ul>
</li>
<li><strong>写回法</strong>：CPU对Cache写命中时，<strong>只修改Cache的内容，不立即写入主存</strong>，只有当此块<strong>被换出时</strong>才写回主存。这种方法减少了访存次数，但存在<strong>不一致的隐患</strong>。采用这种方法时每个Cache行要设置一个<strong>标志位（脏位）</strong>，反映此块是否被CPU修改过。</li>
</ul>
<p><strong>Cache写不命中</strong></p>
<p>也有两种处理方法：</p>
<ul>
<li><strong>写分配法</strong>：加载主存中的块到Cache中，然后更新这个Cache块，试图利用程序的空间局部性，但缺点是每次不命中都需要从主存中读取一块。</li>
<li><strong>非写分配法</strong>：<strong>只写入主存，不进行调块</strong>。
<ul>
<li>这种方法通常与全写法合用；写分配法通常与写回法合用。</li>
<li>现代计算机通常设立<strong>多级Cache</strong>，一般为L1、L2、L3三级，依次离CPU从近到远，访问速度越来越慢，容量越大。</li>
<li>指令Cache与数据Cache分离一般在L1 Cache，此时通常使用<strong>写分配法与写回法合用</strong>。</li>
<li>一个两级Cache系统中，L1 Cache对L2 Cache使用<strong>全写法</strong>，L2 Cache对主存使用<strong>写回法</strong>；L2 Cache的存在避免了频繁写造成的写缓冲饱和溢出。</li>
</ul>
</li>
</ul>
<h2 id="虚拟存储器"><a class="header" href="#虚拟存储器">虚拟存储器</a></h2>
<p>主存和辅存共同构成了虚拟存储器。对于应用程序员来说，虚拟存储器是透明的。虚拟存储器具有<strong>主存的速度和辅存的容量</strong>。</p>
<h3 id="基本概念-6"><a class="header" href="#基本概念-6">基本概念</a></h3>
<p>虚拟存储器将主存或辅存的地址空间同一编址，形成一个庞大的地址空间，在该空间内用户可以自由编程，不必在乎之际的主存容量和程序在主存中存放的位置。</p>
<p>用户编程允许设计的地址称为虚地址或<strong>逻辑地址</strong>，虚地址对应的空间称为虚拟空间；实际主存单元的地址称为实地址。虚地址比实地址大得多。</p>
<p>CPU使用虚地址时，由辅助硬件找出虚地址和实地址之间的对应关系，并判断这个虚地址对应的存储单元是否已经装入主存。若已在主存中，则通过地址变换，CPU可直接访问主存指示的实际单元；若不在主存中，则把包含这个字的一页或一段调入主存后再由CPU访问；若主存已满，则采用替换算法置换主存中的一页或一段。</p>
<p>虚拟存储器由软件（操作系统）和硬件共同实现。</p>
<h3 id="页式虚拟存储器"><a class="header" href="#页式虚拟存储器">页式虚拟存储器</a></h3>
<p>以页为基本单位的存储器。虚拟空间与主存空间都被划分为同样大小的页，主存的页称为<strong>实页</strong>，虚存的页称为<strong>虚页</strong>。</p>
<p>把虚拟地址分为两个字段：<strong>虚页号</strong>和<strong>页内地址</strong>。虚拟地址到物理地址的转换是由页表实现的。</p>
<p>页表是一张存放在主存中的虚页号和实页号（物理块号）的对照表，它记录程序的虚页调入主存时被安排在主存的位置。页表一般长久地保存在主存中。</p>
<p><strong>页表</strong></p>
<ul>
<li>
<p>有效位（装入位）：用来表示对应页面是否在主存，若为1，则表示该虚拟页已经从外存调入主存，此时页表项存放该页的<strong>物理页号</strong>；若为0，则表示没有调入主存，此时页表项可以存放该页的<strong>磁盘地址</strong>。</p>
</li>
<li>
<p>脏位（修改位）：用来表示页面是否被修改过，虚存机制中采用回写策略，利用脏位可以判断替换时是否需要写回磁盘。</p>
</li>
<li>
<p>引用位（使用位）：用来配合替换策略进行设置，例如FIFO、LRU。</p>
</li>
</ul>
<p>CPU执行指令时，需要先将虚拟地址转换为主存物理地址。<strong>每个进程</strong>都有一个页表基址寄存器，存放该进程的页表首地址，然后根据虚拟地址高位部分的虚拟页号找到对应的页表项。若装入位为1，则取出物理页号，和虚拟地址低位部分进行拼接，形成实际物理地址；若装入位为0，则说明缺页（未调入主存），需要操作系统进行缺页处理。</p>
<p>页式虚拟存储器的优点是页面长度固定、页表简单、调入方便。缺点是页不是逻辑上独立的实体，处理、保护和共享都不如段式虚拟存储器方便。</p>
<p><strong>快表(TLB)</strong></p>
<p>依据程序执行的局部性原理，在一段时间内总是经常访问某些页时，若把这些页对应的页表存放在<strong>高速缓冲器</strong>组成的快表（TLB）中，则可以明显地提高效率。相应地把放在主存中的页表称为慢表（Page）。</p>
<p>在地址转换时，首先查找快表，若命中，则无须访问主存中的页表，减少了一次访问主存的次数。</p>
<p><strong>具有TLB和Cache的多级存储系统</strong></p>
<p><img src="https://raw.githubusercontent.com/eternityqjl/blogGallery/master/%E5%B8%A6TLB%E7%9A%84CPU%E8%AE%BF%E5%AD%98%E8%BF%87%E7%A8%8B.jpg" alt="" /></p>
<h3 id="段式虚拟存储器"><a class="header" href="#段式虚拟存储器">段式虚拟存储器</a></h3>
<p>段是按照<strong>程序的逻辑结构</strong>划分的，各个段的长度因程序而异。把虚拟地址分为两部分：<strong>段号</strong>和<strong>段内地址</strong>。</p>
<p>虚拟地址到实地址之间的变换是由<strong>段表</strong>来实现的。段表是程序的<strong>逻辑段</strong>和在主存中<strong>存放位置</strong>的对照表。段表的每行记录与某个段对应的段号、装入位、段起点和段长等信息。由于段长度可变，所以段表中要给出各段的起始地址与段的长度。</p>
<p>CPU根据虚拟地址访问时，先根据<strong>段号</strong>和<strong>段表基地址</strong>拼接成对应的段表行，然后根据段表行的装入位判断该段是否已调入主存。已调入主存时，从段表读出该段的起始地址，与段内地址（偏移量）相加，得到对应主存实地址。</p>
<h3 id="段页式虚拟存储器"><a class="header" href="#段页式虚拟存储器">段页式虚拟存储器</a></h3>
<p>把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页，程序对主存的点入、调出仍以页为基本单位。这种虚拟存储器中，每个程序对应一个段表，每段对应一个页表，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。</p>
<p>虚地址分为段号、段内页号、页内地址三部分。</p>
<p>详细内容见操作系统相关部分。</p>
<h3 id="虚拟存储器与cache的比较"><a class="header" href="#虚拟存储器与cache的比较">虚拟存储器与Cache的比较</a></h3>
<p><strong>相同之处</strong></p>
<p>都为了提高系统性能；都把数据划分为小信息块，并作为基本的传递单位；都有地址的映射、替换算法、更新策略；都依据程序的局部性原理，应用快速缓存思想，将活跃的数据放在相对高速的部件上。</p>
<p><strong>不同之处</strong></p>
<ul>
<li>Cache主要解决<strong>系统速度</strong>问题，虚拟存储器为了解决<strong>容量问题</strong></li>
<li>Cache<strong>全由硬件实现</strong>，是硬件存储器，对所有程序员透明；虚拟存储器由<strong>OS和硬件共同实现</strong>，是逻辑上的存储器，对系统程序员不透明</li>
<li>虚拟存储器不命中时对系统性能的影响更大</li>
<li>辅存与CPU没有建立直接通路，需要经过主存访问</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="指令格式"><a class="header" href="#指令格式">指令格式</a></h2>
<h3 id="基本格式"><a class="header" href="#基本格式">基本格式</a></h3>
<p>一条指令就是机器语言的一个语句，是一组有意义的二进制代码。一条指令通常包括<strong>操作码</strong>字段和<strong>地址码</strong>字段两个部分。</p>
<p>操作码指出一条指令中该指令应该执行什么性质的操作以及具有何种功能。例如指出时算术加运算还是减运算。</p>
<p>地址码给出被操作信息的地址。</p>
<p>指令的长度指的是一条指令中所包含的<strong>二进制代码的位数</strong>。指令长度取决于操作码的长度、操作数地址码的长度以及操作数地址的个数。指令长度与机器字长没有固定关系，通常把指令长度等于机器字长的指令称为<strong>单字长指令</strong>，等于半个机器字长的指令称为<strong>半字长指令</strong>。</p>
<p>一个指令系统中，如果所有指令的长度都相等，则称为<strong>定长指令字结构</strong>，定字长指令的执行速度快、控制简单。各指令长度随功能而异，称为<strong>变长指令字结构</strong>。</p>
<p>根据指令中<strong>操作数地址数量</strong>的不同，可以将指令分为：</p>
<p><strong>零地址指令</strong></p>
<p>只给出操作码OP，没有显式地址。</p>
<p><strong>一地址指令</strong></p>
<p><strong>二地址指令</strong></p>
<p><strong>三地址指令</strong></p>
<p><strong>四地址指令</strong></p>
<h3 id="定长操作码指令格式"><a class="header" href="#定长操作码指令格式">定长操作码指令格式</a></h3>
<p>在指令字的最高位部分分配固定的若干位（定长）表示操作码。一般n位操作码字段的指令系统最大能表示$2^n$条指令。</p>
<h3 id="扩展操作码指令格式"><a class="header" href="#扩展操作码指令格式">扩展操作码指令格式</a></h3>
<p>为了在指令字长有限的前提下保持比较丰富的指令种类，可采取<strong>可变长操作码</strong>，即全部指令的操作码字段<strong>位数不固定</strong>，且分散地放在指令字的不同位置上。</p>
<p>最常见的变长操作码方法是扩展操作码，它使操作码的长度随地址码的减少而增加，不同地址数的指令有不同长度的操作码。</p>
<p>注意：</p>
<ul>
<li>不允许短码是长码的前缀</li>
<li>各指令的操作码不能重复</li>
</ul>
<p>通常对使用频率较高的指令分配较短的操作码，对使用频率较低的指令分配较长的操作码。</p>
<h3 id="指令的操作类型"><a class="header" href="#指令的操作类型">指令的操作类型</a></h3>
<ul>
<li>数据传送</li>
<li>算术和逻辑运算</li>
<li>移位操作</li>
<li>转移操作</li>
<li>输入输出操作</li>
</ul>
<h2 id="指令的寻址方式"><a class="header" href="#指令的寻址方式">指令的寻址方式</a></h2>
<p>寻找指令或操作数的有效地址的方式，即确定本条指令的数据地址以及下一条待执行指令的地址的方式。</p>
<p>寻址方式分为：指令寻址和数据寻址两大类。</p>
<h3 id="指令寻址和数据寻址"><a class="header" href="#指令寻址和数据寻址">指令寻址和数据寻址</a></h3>
<h3 id="常见寻址方式"><a class="header" href="#常见寻址方式">常见寻址方式</a></h3>
<p><strong>隐含寻址</strong></p>
<p><strong>不明显地给出</strong>操作数的地址，而在指令中隐含操作数的地址。例如单地址的指令格式规定累加器（ACC）作为第二操作数的地址。</p>
<p>优点：有利于<strong>缩短指令字长</strong>；缺点：需要增加存储器操作数或隐含地址的硬件。</p>
<p><strong>立即数寻址</strong></p>
<p>地址字段为<strong>操作数本身</strong>而不是地址，又称为立即数。数据采用补码存放。</p>
<p>优点：不用访问主存，指令执行时间段；缺点：<strong>A的位数</strong>限制了立即数的<strong>范围</strong>。</p>
<p><strong>直接寻址</strong></p>
<p>指令字中的形式地址A为操作数的<strong>真实地址EA</strong>，即EA=A</p>
<p>优点：简单，指令执行阶段<strong>仅访问一次主存</strong>，不需要专门计算操作数的地址；缺点：<strong>A的位数</strong>决定了该操作数的<strong>寻址范围</strong>。</p>
<p><strong>间接寻址</strong></p>
<p>指令地址字段给出的地址不是操作数的真正地址，而是操作数有效地址所在的存储单元的地址，即<strong>操作数地址的地址</strong>。</p>
<p>间接寻址可以是一次间接寻址，也可以是多次。</p>
<p>优点：可以<strong>扩大寻址范围</strong>，便于编程（可方便地完成子程序的返回）；缺点：指令在执行阶段要<strong>多次访存</strong>。</p>
<p><strong>寄存器寻址</strong></p>
<p>直接给出操作数所在的<strong>寄存器的编号</strong>。</p>
<p>该寻址方式在指令执行期间<strong>不访问主存</strong>，只访问寄存器，速度较快，但寄存器价格昂贵，计算机中的寄存器个数有限。</p>
<p><strong>寄存器间接寻址</strong></p>
<p>寄存器中给出操作数<strong>所在主存单元的地址</strong>。</p>
<p>与一般间接寻址相比速度更快，但是指令执行阶段需要访问主存。</p>
<p><strong>相对寻址</strong></p>
<p>把<strong>程序计数器PC的内容</strong>加上指令格式中的<strong>形式地址A</strong>形成操作数的有效地址。即EA=(PC)+A</p>
<p>优点：操作数的地址不是固定的，随PC值的变化而变化，且与指令地址之间总相差一个固定值，便于<strong>程序浮动</strong>。广泛用于转移指令。</p>
<p><strong>基址寻址</strong></p>
<p>将CPU中<strong>基址寄存器中的内容</strong>加上指令格式中的<strong>形式地址A</strong>形成的操作数的有效地址。即EA=(BR)+A</p>
<p>基址寄存器是面向<strong>操作系统</strong>的，主要用于为多道程序或数据分配存储空间。基址寄存器的值由操作系统确定，程序执行过程中其值不可以改变，而指令字中的<strong>A可以改变</strong>。</p>
<p>优点是可以<strong>扩大寻址范围</strong>（基址寄存器的位数大于形式地址A的位数）；用户不必考虑自己的程序存于主存的哪个空间区域，有利于<strong>多道程序设计</strong>。并可用于编制浮动程序，但偏移量的位数较短。</p>
<p><strong>变址寻址</strong></p>
<p>有效地址为指令字中的<strong>形式地址A</strong>与<strong>变址寄存器IX中的内容</strong>的和。</p>
<p>变址寄存器是面向<strong>用户</strong>的。变址寄存器中的内容可以由用户改变，并且程序执行过程中其值可以改变，而指令字中的<strong>A不可以该变</strong>。</p>
<p>变址寻址的优点是可扩大寻址范围；在<strong>数组</strong>处理过程中可以设定A为数组首地址，不断改变变址寄存器IX的内容，可以容易地形成数据中任意数据的地址，适合编制循环程序。偏移量的位数足以表示整个存储空间。</p>
<p><strong>堆栈寻址</strong></p>
<p>堆栈是存储器中一块特定的、按LIFO后进先出原则管理的存储区，该存储区中读写地址是使用<strong>堆栈指针SP</strong>寄存器给出的。</p>
<p>堆栈可分为硬堆栈和软堆栈。</p>
<p>栈指针指向栈顶的空单元。</p>
<h3 id="x86汇编指令入门"><a class="header" href="#x86汇编指令入门">X86汇编指令入门</a></h3>
<p><strong>相关寄存器</strong></p>
<p>8个32位通用寄存器，除了堆栈基指针EBP和堆栈顶指针ESP外其他几个寄存器的用途是比较任意的。</p>
<p><strong>寻址模式和内存分配</strong></p>
<p><strong>常用指令</strong></p>
<p>汇编指令可分为数据传送指令、逻辑计算指令和控制流指令。</p>
<ul>
<li>数据传送指令
<ul>
<li>mov</li>
<li>push</li>
<li>pop</li>
</ul>
</li>
<li>算术和逻辑运算指令
<ul>
<li>add/sub</li>
<li>inc/dec</li>
<li>imul</li>
<li>idiv</li>
<li>and/or/xor</li>
<li>not</li>
<li>neg</li>
<li>shl/shr</li>
</ul>
</li>
<li>控制流指令
<ul>
<li>jmp</li>
<li>j(condition)
<ul>
<li>je</li>
<li>jne</li>
<li>jz</li>
<li>...</li>
</ul>
</li>
<li>cmp</li>
<li>call/ret：分别实现了子程序（过程、函数等）的调用以及返回。</li>
</ul>
</li>
</ul>
<h2 id="cisc和risc"><a class="header" href="#cisc和risc">CISC和RISC</a></h2>
<p>复杂指令系统计算机(CISC)：增强原有指令功能，设置更为复杂的新指令，实现软件功能的硬件化。例如X86架构计算机。</p>
<p>精简指令系统计算机(RISC)：减少指令种类，简化指令功能，提高指令的执行速度。例如ARM、MIPS架构的计算机。</p>
<h3 id="cisc"><a class="header" href="#cisc">CISC</a></h3>
<p>VLSI技术。</p>
<h3 id="risc"><a class="header" href="#risc">RISC</a></h3>
<p>精简指令系统计算机。要求指令系统简化，尽量使用寄存器-寄存器操作指令，指令格式力求一致。</p>
<p>主要特点：</p>
<p>见书。</p>
<h3 id="二者的比较"><a class="header" href="#二者的比较">二者的比较</a></h3>
<div style="break-before: page; page-break-before: always;"></div><p>数据通路容易考大题。</p>
<h2 id="cpu的功能和基本结构"><a class="header" href="#cpu的功能和基本结构">CPU的功能和基本结构</a></h2>
<h3 id="功能"><a class="header" href="#功能">功能</a></h3>
<p>CPU由<strong>运算器和控制器</strong>组成。控制器负责协调并控制计算机各部件执行程序的指令序列，包括取指令、分析指令、执行指令；运算器是对数据进行加工。</p>
<p>CPU的具体功能：</p>
<ul>
<li>指令控制：程序的顺序控制</li>
<li>操作控制：一条指令功能由若干操作信号的组合来实现。CPU管理并产生由内存取出的每条指令的操作信号，把操作信号送往相应部件</li>
<li>时间控制：为每条指令按时间顺序提供应用的控制信号</li>
<li>数据加工：对数据进行算术或逻辑运算</li>
<li>中断处理：对异常情况和特殊请求进行处理</li>
</ul>
<h3 id="基本结构"><a class="header" href="#基本结构">基本结构</a></h3>
<p><strong>运算器</strong></p>
<ul>
<li>算术逻辑单元ALU</li>
<li>暂存寄存器</li>
<li>累加寄存器ACC</li>
<li>通用寄存器组</li>
<li>程序状态字寄存器PSW</li>
<li>移位器</li>
<li>计数器</li>
</ul>
<p><strong>控制器</strong></p>
<ul>
<li>程序计数器PC：指出下一条指令在主存中的存放地址。PC有自增功能。</li>
<li>指令寄存器IR：用于保存当前正在执行的那条指令</li>
<li>指令译码器：仅对操作码字段进行译码，向控制器提供特定操作信号</li>
<li>存储器地址寄存器MAR</li>
<li>存储器数据寄存器MDR</li>
<li>时序系统：用于产生各种时序信号。由统一时钟CLOCK分频得到。</li>
<li>微操作信号发生器：根据IR和PSW的内容及时序信号，产生控制整个计算机系统所需的各种控制信号，结构有组合逻辑型和存储逻辑型。</li>
</ul>
<h2 id="指令执行过程"><a class="header" href="#指令执行过程">指令执行过程</a></h2>
<h3 id="指令周期"><a class="header" href="#指令周期">指令周期</a></h3>
<ul>
<li>指令周期：CPU从主存中取出并执行一条指令的时间</li>
<li>机器周期：不同的工作周期，例如取指、间址、执行、中断周期</li>
<li>时钟周期（节拍）：CPU操作的最基本单位</li>
</ul>
<p>每个指令周期内的机器周期数可以不相等；例如无条件转移指令JMP X在执行时不需要访问主存，只包含取址和执行阶段，所以其指令周期只包含取指和执行周期。</p>
<p>间址指令为了取操作数需要先访问一次主存，取出有效地址，然后访问主存，取出操作数，所以还需要包括间址周期。</p>
<p>当CPU采用中断方式实现主机和I/O设备的信息交换时，CPU在每条指令执行结束前都要发中断查询信号，若有中断请求则CPU进入中断响应阶段，又称中断周期。</p>
<h3 id="指令周期的数据流"><a class="header" href="#指令周期的数据流">指令周期的数据流</a></h3>
<p>（各周期的详细步骤见书上的图）</p>
<p>根据指令要求依次访问的数据序列。</p>
<p><strong>取指周期</strong></p>
<p>根据PC中的内容从主存中取出指令代码并存放在IR中。取指的同时，PC加1</p>
<p>数据流如下：</p>
<ul>
<li>PC$\to$MAR$\to$地址总线$\to$主存</li>
<li>CU发出读命令$\to$控制总线$\to$主存</li>
<li>主存$\to$数据总线$\to$MDR$\to$IR</li>
<li>CU发出控制指令$\to$PC内容加1</li>
</ul>
<p><strong>间址周期</strong></p>
<p>取操作数的有效地址。</p>
<p>数据流如下：</p>
<ul>
<li>Ad(IR)（或MDR）$\to$MAR$\to$地址总线$\to$主存</li>
<li>CU发出读命令$\to$控制总线$\to$主存</li>
<li>主存$\to$数据总线$\to$MDR（存放操作数有效地址）</li>
</ul>
<p>（Ad(IR)指的是存放在IR中的指令字的地址段）</p>
<p><strong>执行周期</strong></p>
<p>取操作数，并根据IR中指令字的操作码通过ALU操作产生执行结果。</p>
<p>不同指令的执行周期操作不同，没有统一的数据流向。</p>
<p><strong>中断周期</strong></p>
<p>处理中断请求。假设程序断点存入堆栈，并用SP指示栈顶指针，且进栈操作是先修改栈顶指针后存入数据，则数据流如下：</p>
<ul>
<li>CU控制将SP减1，SP$\to$MAR$\to$地址总线$\to$主存</li>
<li>CU发出写命令$\to$控制总线$\to$主存</li>
<li>PC$\to$MDR$\to$数据总线$\to$主存（程序断点存入主存）</li>
<li>CU（中断服务程序的入口地址）$\to$PC</li>
</ul>
<h3 id="指令执行方案"><a class="header" href="#指令执行方案">指令执行方案</a></h3>
<p><strong>单指令周期</strong></p>
<p>对所有指令选用<strong>相同的执行时间</strong>来完成，即每条指令都在固定的时间周期内完成，指令之间串行执行。</p>
<p>对于本可以在更短时间内完成的指令，要使用这个较长的周期来完成，会<strong>降低整个系统的运行速度</strong>。</p>
<p><strong>多指令周期</strong></p>
<p>对不同类型的指令选用不同的执行步骤来完成。指令之间串行执行。但可以选用<strong>不同个数的时钟周期</strong>来完成不同指令的执行过程，指令需要几个周期就分配几个周期。</p>
<p><strong>流水线方案</strong></p>
<p>指令之间可以并行执行，目标是力求在<strong>每个时钟脉冲</strong>周期完成一条指令的执行过程。这种方案通过在每个时钟周期启动一条指令，尽量让多条指令同时运行，但各自处于不同的执行步骤中。</p>
<h2 id="数据通路"><a class="header" href="#数据通路">数据通路</a></h2>
<h3 id="功能-1"><a class="header" href="#功能-1">功能</a></h3>
<p>数据在功能部件之间传输的路径称为数据通路。路径上的部件称为<strong>数据通路部件</strong>。数据通路描述了信息从什么地方开始，中间经过哪个寄存器或多路开关，最后传送到哪个寄存器，这些都需要加以控制。</p>
<p>数据通路由控制部件控制，控制部件根据每条指令功能的不同生成对数据通路的控制信号，并正确控制指令的执行流程。</p>
<h3 id="基本结构-1"><a class="header" href="#基本结构-1">基本结构</a></h3>
<ul>
<li>CPU内部单总线方式</li>
</ul>
<p>将所有寄存器的输入和输出端都连接到一条公共通路上，结构简单，但数据传输存在较多冲突，性能较低。</p>
<ul>
<li>CPU内部三总线方式</li>
</ul>
<p>将所有寄存器的输入和输出端都连接到多条公共通路上，能同时在多个总线上传输不同数据，提高效率。</p>
<ul>
<li>专用数据通路方式</li>
</ul>
<p>根据指令执行过程中的数据和地址的流动方向安排连接线路，避免使用共享的总线，性能较高但硬件量大。</p>
<p><strong>寄存器间的数据传送</strong></p>
<p>寄存器之间的数据传送可以通过CPU内部总线完成。</p>
<p>这里以PC寄存器为例：</p>
<p>PC$\rightarrow$Bus</p>
<p>Bus$\rightarrow$MAR</p>
<p><strong>主存与CPU之间的数据传送</strong></p>
<p>二者之间的数据传送同样也要借助CPU内部总线完成。</p>
<p>PC$\rightarrow$Bus$\rightarrow$MAR</p>
<p>1$\rightarrow$R（CU发出读命令）</p>
<p>MEM(MAR)$\rightarrow$MDR</p>
<p>MDR$\rightarrow$Bus$\rightarrow$IR</p>
<p><strong>执行算术或逻辑运算</strong></p>
<p>ALU内部本身没有存储功能，如果要执行加法运算，相加的两个数必须在ALU的两个输入端同时有效。</p>
<h2 id="控制器"><a class="header" href="#控制器">控制器</a></h2>
<h3 id="结构和功能"><a class="header" href="#结构和功能">结构和功能</a></h3>
<p>计算机硬件的主要连接关系：</p>
<ul>
<li>运算器通过数据总线与内存、输入设备、输出设备传送数据</li>
<li>输入输出设备与总线相连</li>
<li>内存、输入设备、输出设备通过地址总线接收地址信息，从控制总线得到控制信号，通过数据总线与其他部件传送数据。</li>
</ul>
<p>控制器的主要功能：</p>
<ul>
<li>从主存中取出一条指令，并指出下一条指令在内存中的位置</li>
<li>对指令进行译码或测试，并产生相应控制信号</li>
<li>指挥并控制CPU、主存、输入输出设备之间的数据流动</li>
</ul>
<p>根据控制器产生<strong>微操作控制信号</strong>的方式不同，控制器可以分为<strong>硬布线</strong>控制器和<strong>微程序</strong>控制器，两类控制器的PC和IR是相同的，但是确定和表示执行步骤的方法以及给出控制信号的方案不同。</p>
<h3 id="硬布线控制器"><a class="header" href="#硬布线控制器">硬布线控制器</a></h3>
<p>根据指令的要求、当前的时序以及外部和内部的状态，按时间的顺序发送一系列微操作控制信号。由复杂的组合逻辑门电路和一些触发器构成，又称为组合逻辑控制器。</p>
<p><strong>硬布线控制单元</strong></p>
<p>指令的操作码时决定控制单元发出不同操作命令（控制信号）的关键。为了简化控制单元CU的逻辑，将指令的操作码译码和节拍发生器从CU分离出来，得到简化的控制单元图。</p>
<p>CU的输入信号来源：</p>
<ul>
<li>经指令译码器译码产生的指令信息。</li>
<li>时序系统产生的机器周期信号和节拍信号。</li>
<li>来自执行单元的反馈信息，即标志。控制单元有时需要依赖CPU当前所处的状态产生控制信号。</li>
</ul>
<p>CU输出到CPU内部或外部控制总线上。</p>
<p><strong>时序系统及微操作</strong></p>
<ul>
<li>时钟周期：用时钟信号控制节拍发生器，产生节拍。每个节拍的宽度正好对应一个时钟周期。</li>
<li>机器周期：所有指令执行过程中过的一个基准时间。不同指令的操作不同，指令周期也不同。访问一次存储器的时间是固定的，因此童话参观以存取周期为基准时间，即内存中读取一个指令字的最短时间作为机器时间。在存储字长等于指令字长的前提下，取指周期也可视为机器周期。</li>
<li>指令周期。</li>
<li>微操作命令分析：</li>
</ul>
<p>执行程序过程中，对于不同指令，控制单元需要发出各种不同的微操作命令。一条指令分为3个工作周期：取指、间址、执行周期。下面分析各个子周期的微操作指令：</p>
<ol>
<li>
<p>取指周期</p>
</li>
<li>
<p>间址周期</p>
</li>
<li>
<p>执行周期</p>
<p>a. 非访存指令</p>
<p>b. 访存指令</p>
<p>c. 转移指令</p>
</li>
</ol>
<p><strong>CPU的控制方式</strong></p>
<p>控制单元控制一条指令执行的过程，实质上是依次执行一个确定的微操作序列的过程。主要有以下三种控制方式：</p>
<ul>
<li>同步控制：系统有一个统一的时钟，所有控制信号来自这个统一的时钟信号。采取完全统一的、具有相同时间间隔和相同数目的节拍作为机器周期来运行不同指令。控制电路简单但运行速度慢。</li>
<li>异步控制：不存在基准时标信号，各部件按照自身固有速度工作，通过应答方式联络。运行速度块但控制电路较为复杂。</li>
<li>联合控制：介于同步、异步之间的一种折中。对不同指令大部分采用同步控制，小部分采用异步控制。</li>
</ul>
<p><strong>硬布线控制单元涉及步骤</strong></p>
<ul>
<li>列出微操作命令的操作时间表</li>
<li>进行微操作信号综合，得到逻辑表达式</li>
<li>根据逻辑表达式画出微操作命令的逻辑图，并用逻辑门电路实现。</li>
</ul>
<h3 id="微程序控制器"><a class="header" href="#微程序控制器">微程序控制器</a></h3>
<p>微程序控制器采用存储逻辑实现，即把微操作信号<strong>代码化</strong>，使每条<strong>机器指令</strong>转化成一段<strong>微程序</strong>并存入一个<strong>专门的存储器（控制存储器CM）<strong>中。微操作控制信号由</strong>微指令</strong>（每个微程序包括若干微指令）产生。</p>
<p><strong>基本概念</strong></p>
<ul>
<li>
<p>微命令和微操作：一个微操作是计算机中最基本的、不可再分解的操作。一条微命令和微操作一一对应。微命令是构成控制序列的最小单位。</p>
</li>
<li>
<p>微指令和微周期：微指令是由若干微命令的集合。存放微指令的控制存储器的单元地址称为微地址。一条微指令包括两大部分信息：</p>
<ul>
<li>操作控制（微操作码）字段：产生某一步操作所需的各种操作控制信号</li>
<li>顺序控制（微地址码）字段：用于控制产生下一条要执行的微指令地址</li>
</ul>
<p>微周期指从控制存储器读取一条微指令并执行相应微操作所需的时间。</p>
</li>
<li>
<p>主存储器与控制存储器：主存在CPU外部，用于存放程序和数据，用RAM实现；控制存储器CM用于存放微程序，在CPU内部，由ROM实现</p>
</li>
<li>
<p>程序与微程序：微程序由微指令组成，用于描述机器指令，微程序实际上是机器指令的实时解释器，对用户透明。</p>
</li>
</ul>
<p><strong>组成和工作过程</strong></p>
<p>（1）微程序控制器的基本组成</p>
<ul>
<li>控制存储器：核心部件，用于存放微程序，由ROM构成</li>
<li>微指令寄存器CMDR：用于存放从CM中取出的微指令，位数同微指令字长相等</li>
<li>微地址形成部件：用于产生初始微地址和后继微地址，保证微指令的连续执行</li>
<li>微地址寄存器CMAR：接收微地址形成部件送来的微地址，为在CM中读取微指令做准备。</li>
</ul>
<p>（2）微程序的工作过程</p>
<ul>
<li>执行<strong>取微指令公共操作</strong>。在机器开始运行时，自动将取指微程序的入口地址送入CMAR，并从CM取出相应微指令送入CMDR</li>
<li>由机器指令的操作码字段通过微地址形成部件产生<strong>该机器指令对应的微程序的入口地址</strong>，送入CMAR</li>
<li>从CM中<strong>逐条取出对应微指令并执行</strong></li>
<li>执行完对应于一条机器指令的一个微程序后，又回到<strong>取指微程序</strong>的入口地址，继续第一步，完成下一条机器指令的公共操作</li>
</ul>
<p>（3）微程序和机器指令</p>
<p><strong>微指令的编码方式</strong></p>
<p>又称微指令的控制方式，指如何对微指令的控制字段进行编码，以形成控制信号。编码是为了在保证速度的情况下，尽量缩短指令字长。</p>
<ul>
<li>直接编码</li>
</ul>
<p>直接编码无须进行译码，微指令的微命令字段对应的每一位都代表一个微命令。每个微命令对应并控制数据通路中的一个微操作。</p>
<p>这种方式简单、直观、执行速度快，操作并行性好；缺点是微指令字长过长。</p>
<ul>
<li>字段直接编码</li>
</ul>
<p>将微指令的微命令字段分成若干小字段，把互斥性微命令组合在同一字段，相容性微命令组合在不同字段，每个字段独立编码。</p>
<ul>
<li>字段间接编码</li>
</ul>
<p>一个字段某些微命令需要另一个字段中的某些微命令来解释，不是直接靠字段直接译码发出的微命令，称为字段间接编码。这种方式可以进一步缩短微指令字长，但削弱了微指令的并行控制能力，通常作为一种辅助手段。</p>
<p><strong>微指令的地址形成方式</strong></p>
<p><strong>微指令的格式</strong></p>
<ul>
<li>水平型微指令</li>
<li>垂直型微指令</li>
<li>混合型微指令</li>
</ul>
<p><strong>微程序控制单元的设计步骤</strong></p>
<p>主要任务是编写各条机器指令对应的微程序。具体步骤如下：</p>
<ul>
<li>写出对应机器指令的微操作命令及节拍安排</li>
<li>确定微指令格式</li>
<li>编写微指令码点</li>
</ul>
<p><strong>动态微程序涉及和毫微程序设计</strong></p>
<p><strong>硬布线和微程序控制器的特点</strong></p>
<h2 id="指令流水线"><a class="header" href="#指令流水线">指令流水线</a></h2>
<h3 id="基本概念-7"><a class="header" href="#基本概念-7">基本概念</a></h3>
<p>一种并行处理技术。一条指令的执行过程可分解为若干阶段，每个阶段由相应功能部件完成。如果将各个阶段视为相应流水段，则指令的执行过程就构成了一条指令流水线。采用流水线技术只需要增加少量硬件就能把计算机的运算速度提高几倍。</p>
<p>流水线执行方式</p>
<p>多级流水线</p>
<p><strong>指令流水的定义</strong></p>
<p>把一条指令的执行分为取指、分析、执行三个截断。当多条指令在处理器中执行时，可以采用以下两种方式：</p>
<ul>
<li>顺序执行方式：前一条指令执行完后才启动下一条指令，又称串行执行方式，控制简单但各部件利用率低。</li>
<li>流水线执行方式：为提高指令执行速度，把取k+1条执行提前到分析第k条指令的期间完成，将分析第k+1条指令与执行第k条指令同时进行。这种方式能将指令的执行时间缩短2/3，各功能部件利用率明显提高。但要付出硬件上较大的开销。理想状态下每个时钟周期都有一条指令进入流水线，处理机中同时有3条指令在执行，每条指令的时钟周期数CPI都为1。</li>
</ul>
<p>为了进一步获得更高的执行速度还可以将流水线进一步细分。划分为4级或者5级流水线。</p>
<p>流水线的设计原则：</p>
<ul>
<li>指令流水段个数以最复杂指令所用的功能段个数为准；</li>
<li>流水段的长度以最复杂操作所需的时间为准。</li>
</ul>
<p>流水线方式不一定能缩短一条指令的执行时间，但对于整个程序来说，可以大大增加指令执行的吞吐率。</p>
<p>为了利于实现指令流水线，指令集应具有以下特征：</p>
<ul>
<li>指令长度尽量一致，有利于简化取指令和指令译码操作</li>
<li>指令格式应尽量规整，尽量保证源寄存器的位置相同，有利于在指令未知时就可以取寄存器操作数。</li>
<li>采用Load/Store质量你个，其他指令都不能访问存储器，有利于减少操作步骤。</li>
<li>数据和指令在存储器中对其存放。有利于减少访存次数。</li>
</ul>
<p><strong>流水线的表示方法</strong></p>
<p>通常用时空图来直观描述流水线的工作过程。见书上的图所示。</p>
<p><strong>流水线方式的特点</strong></p>
<ul>
<li>把一个任务分解为几个有联系的子任务，每个子任务由一个专门的功能部件来执行，并依靠多个功能部件并行工作来缩短程序执行时间。</li>
<li>流水线的每个功能段后面都要有一个缓冲寄存器，用来保存本流水段的执行结果，供给下一流水段使用。</li>
<li>流水线中各功能段的时间应尽量相等，否则将引起堵塞、断流</li>
<li>只有连续不断提供同一种任务时才能发挥流水线的效率，所以流水线中处理的必须是连续任务。</li>
<li>流水线需要有装入时间和排空时间。</li>
</ul>
<h3 id="分类-1"><a class="header" href="#分类-1">分类</a></h3>
<p>按照不同的分类标准进行分：</p>
<p><strong>部件功能级、处理机级、处理机间级流水线</strong></p>
<ul>
<li>部件功能级：将复杂的算术逻辑运算组成流水线工作方式。</li>
<li>处理机级：把一条指令解释过程分成多个子过程，如前面提到的取值、译码、执行、访存和写回5个子过程</li>
<li>处理机间流水：一种宏流水，每个处理机完成某一专门任务。</li>
</ul>
<p><strong>单功能和多功能流水线</strong></p>
<p><strong>动态和静态流水线</strong></p>
<p>按同一时间段内各段之间的连接方式分。</p>
<p><strong>线性和非线性流水线</strong></p>
<p>按各个功能段之间是否有反馈信号。非线性流水线输入输出过程中多次通过某一段流水线，适合于线性递归运算。</p>
<h3 id="影响因素"><a class="header" href="#影响因素">影响因素</a></h3>
<p><strong>资源冲突</strong></p>
<p>多条指令在同一时刻争用同一资源形成的冲突。数据Cache和指令Cache分离的方式避免了资源冲突的发生。</p>
<p><strong>数据冲突</strong></p>
<p>下一条指令会用到当前指令计算出的结果。</p>
<ul>
<li>写后读</li>
<li>读后写</li>
<li>写后写</li>
</ul>
<p>解决方法：</p>
<ul>
<li>遇到数据相关的指令及其后序指令暂定一至几个时钟周期，知道相关问题消失后再执行。</li>
<li>设置相关专用通路，不等前一条指令把计算结果写入寄存器组，下一条指令也不再读寄存器组。</li>
<li>通过编译器对数据相关的指令编译优化的方法，调整指令顺序来解决数据相关。</li>
</ul>
<p><strong>控制冲突</strong></p>
<p>在执行转移、调用或返回等指令时会改变PC值，而造成断流，引起控制冒险。</p>
<p>解决方式：</p>
<ul>
<li>对指令进行分支预测，今早生成转移目标地址</li>
<li>预取转移成功和不成功两个控制流方向上的目标指令</li>
<li>加快和提前形成条件码</li>
<li>提高转移方向的猜准率</li>
</ul>
<h3 id="性能指标-1"><a class="header" href="#性能指标-1">性能指标</a></h3>
<p><strong>流水线的吞吐率</strong></p>
<p>单位时间内流水线所完成的任务数量，或输出结果的数量。</p>
<p><strong>流水线的加速比</strong></p>
<p>完成同一批任务，不使用流水线所用时间和使用流水线所用时间之比。</p>
<p><strong>流水线的效率</strong></p>
<p>流水线的设备利用率称为流水线的效率。</p>
<h3 id="超标量流水线"><a class="header" href="#超标量流水线">超标量流水线</a></h3>
<p><strong>超标量流水线技术</strong></p>
<p>每个时钟周期内可以并发多条独立指令，即以并行操作方式将两条或多条指令编译并执行，为此需要配置多个功能部件。</p>
<p>不能调整指令的执行顺序。</p>
<p><strong>超流水线技术</strong></p>
<p>一个时钟周期内再分段，在一个时钟周期内一个功能部件使用多次。</p>
<p><strong>超长指令字</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="总线概述"><a class="header" href="#总线概述">总线概述</a></h2>
<p>总线型连接是为了解决I/O设备和主机之间连接的灵活性问题。</p>
<h3 id="基本概念-8"><a class="header" href="#基本概念-8">基本概念</a></h3>
<p><strong>定义</strong></p>
<p>能为多个部件分时共享的公共信息传送线路。分时和共享是总线的两个特点。</p>
<p>共享指总线上可以挂接多个部件。</p>
<p><strong>总线设备</strong></p>
<p>分为主设备和从设备。</p>
<p><strong>特性</strong></p>
<p>指机械特性、电气特性、功能特性、时间特性。</p>
<h3 id="总线分类"><a class="header" href="#总线分类">总线分类</a></h3>
<p><strong>片内总线</strong></p>
<p>CPU内部寄存器之间、寄存器与ALU之间的公共连接线。</p>
<p><strong>系统总线</strong></p>
<p>计算机各功能部件（CPU、主存、I/O接口）之间相互连接的总线。</p>
<p>又分为数据、地址和控制总线。</p>
<p><strong>通信总线</strong></p>
<p>在计算机系统之间或计算机与其他系统之间传送信息的总线，有时也称外部总线。</p>
<p>另外按时序还分为同步和异步总线，按数据传输格式分为串行和并行总线。</p>
<h3 id="系统总线的结构"><a class="header" href="#系统总线的结构">系统总线的结构</a></h3>
<p><strong>单总线结构</strong></p>
<p>将CPU、主存、I/O设备都挂在一组总线上。</p>
<p><strong>双总线结构</strong></p>
<p>一条是主存总线，用于CPU、主存和通道之间传送数据；另一条是I/O总线，用于在多个外部设备和通道之间传送数据。</p>
<p><strong>三总线结构</strong></p>
<p>主存总线、I/O总线、直接内存访问(DMA)总线。</p>
<p>DMA总线用于内存和高速外设之间直接传送数据，提高了I/O设备的性能。</p>
<h3 id="总线的性能指标"><a class="header" href="#总线的性能指标">总线的性能指标</a></h3>
<ul>
<li>总线传输周期：一次总线操作所需的时间</li>
<li>总线时钟周期：即机器的时钟周期</li>
<li>总线的工作频率：总线上各种操作的频率，为总线周期的倒数。实际上指1s内传输几次数据。</li>
<li>总线的时钟频率</li>
<li>总线宽度</li>
<li>总线带宽：总线的最大数据传输率</li>
<li>总线复用：一种信号线在不同时间传输不同的信息</li>
<li>信号线数：地址总线、数据总线和控制总线3种总线数的总和。</li>
</ul>
<h2 id="总线仲裁"><a class="header" href="#总线仲裁">*总线仲裁</a></h2>
<p>为了解决多个主设备同时竞争总线控制权的问题。</p>
<h3 id="集中仲裁方式"><a class="header" href="#集中仲裁方式">集中仲裁方式</a></h3>
<p>总线控制逻辑集中于一个设备（例如CPU）中。将所有总线请求集中起来，利用特定的裁决算法进行裁决。集中仲裁方式有以下几种：</p>
<p><strong>链式查询方式</strong></p>
<p>BG总线允许线、BR总线请求线、BS总线忙线</p>
<p><strong>计数器定时查询方式</strong></p>
<p>BR总线请求线、BS总线忙线、地址设备线</p>
<p>优先次序可以改变，这种方式对电路故障没那么敏感。</p>
<p><strong>独立请求方式</strong></p>
<p>每个设备都有自己的BG总线允许线、BR总线请求线。</p>
<p>总线控制器按照一定的优先次序批准某个部件的请求。</p>
<p>响应速度快但控制线数量多，总线控制逻辑更复杂。</p>
<h3 id="分布仲裁方式"><a class="header" href="#分布仲裁方式">分布仲裁方式</a></h3>
<p>没有中央仲裁器，每个主模块都有自己的仲裁号和仲裁器。</p>
<h2 id="总线操作和定时"><a class="header" href="#总线操作和定时">总线操作和定时</a></h2>
<p>总线定时指总线在双方交换数据的过程中需要时间上配合关系的控制，实质上是一种协议。主要有<strong>同步和异步</strong>两种基本定时方式。</p>
<h3 id="总线传输的4个阶段"><a class="header" href="#总线传输的4个阶段">总线传输的4个阶段</a></h3>
<ul>
<li>申请分配阶段</li>
<li>寻址阶段</li>
<li>传输阶段</li>
<li>结束阶段</li>
</ul>
<h3 id="同步定时方式"><a class="header" href="#同步定时方式">同步定时方式</a></h3>
<p>系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。时钟产生相等的时间间隔，每个间隔构成一个总线周期。一个总线周期发送方和接收方可以进行一次数据传送。</p>
<p>传输速度较快。主从设备强制同步。适用于纵线长度较短及总线所接部件的存取时间较接近的系统。</p>
<h3 id="异步定时方式"><a class="header" href="#异步定时方式">异步定时方式</a></h3>
<p>依靠传送双方相互制约的握手信号来实现定时控制。</p>
<p>总线周期长度可变，控制方式稍复杂，速度较慢。</p>
<ul>
<li>不互锁方式</li>
<li>半互锁方式</li>
<li>全互锁方式</li>
</ul>
<h2 id="总线标准"><a class="header" href="#总线标准">总线标准</a></h2>
<ul>
<li>ISA：最早输出现的系统总线</li>
<li>EISA</li>
<li>VESA：32位，应用于多媒体</li>
<li>PCI：外部设备互联</li>
<li>PCIe</li>
<li>AGP：加速图形接口</li>
<li>RS-232：串行通信总线</li>
<li>USB</li>
<li>PCMCIA</li>
<li>IDE</li>
<li>SCSI</li>
<li>SATA</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="io系统基本概念"><a class="header" href="#io系统基本概念">I/O系统基本概念</a></h2>
<h3 id="输入输出系统"><a class="header" href="#输入输出系统">输入/输出系统</a></h3>
<p>I/O系统中的几个基本概念：</p>
<ul>
<li>外部设备</li>
<li>接口</li>
<li>输入设备</li>
<li>输出设备</li>
<li>外存设备</li>
</ul>
<h3 id="io控制方式"><a class="header" href="#io控制方式">I/O控制方式</a></h3>
<ul>
<li>程序查询方式</li>
<li>程序中断方式</li>
<li>DMA方式</li>
<li>通道方式</li>
</ul>
<h2 id="外部设备"><a class="header" href="#外部设备">外部设备</a></h2>
<h3 id="输入设备"><a class="header" href="#输入设备">输入设备</a></h3>
<p>键盘、鼠标</p>
<h3 id="输出设备"><a class="header" href="#输出设备">输出设备</a></h3>
<p><strong>显示器</strong></p>
<p>显示器的主要参数：屏幕大小、分辨率、灰度级、刷新、刷新频率、显示存储器（VRAN）</p>
<p>显示器的分类：</p>
<ul>
<li>阴极射线管CRt显示器</li>
<li>液晶显示器LCD</li>
<li>LED发光二极管显示器</li>
</ul>
<p><strong>打印机</strong></p>
<p>针式打印机、喷墨式打印机、激光打印机</p>
<h3 id="外存储器"><a class="header" href="#外存储器">外存储器</a></h3>
<p><strong>磁盘存储器</strong></p>
<p><strong>磁盘阵列RAID</strong></p>
<p><strong>光盘存储器</strong></p>
<h2 id="io接口"><a class="header" href="#io接口">I/O接口</a></h2>
<p>主机和外设之间的交接界面。</p>
<h3 id="功能-2"><a class="header" href="#功能-2">功能</a></h3>
<ul>
<li>实现主机和外设的通信联络控制</li>
<li>进行地址译码和设备选择</li>
<li>实现数据缓冲</li>
<li>信号格式的转换</li>
<li>传送控制命令和状态信息</li>
</ul>
<h3 id="结构"><a class="header" href="#结构">结构</a></h3>
<h3 id="类型"><a class="header" href="#类型">类型</a></h3>
<p>从不同角度看，I/O接口可以分为不同的类型：</p>
<ul>
<li>按数据传送方式可分为并行和串行接口</li>
<li>按主机访问I/O设备的控制方式可分为程序查询接口、中断接口、DMA接口</li>
<li>按功能选择的灵活性可分为可编程接口和不可编程接口</li>
</ul>
<h3 id="io端口及其编址"><a class="header" href="#io端口及其编址">I/O端口及其编址</a></h3>
<p>I/O端口指的是接口电路中可以被CPU直接访问的寄存器，主要有数据端口、状态端口和控制端口。通常CPU能对<strong>数据端口</strong>执行<strong>读写</strong>操作，对<strong>状态端口</strong>只执行<strong>读</strong>操作，对<strong>控制端口</strong>只能执行<strong>写</strong>操作。</p>
<p>I/O端口的编址方式有：</p>
<ul>
<li>统一编址：把I/O端口当作存储器的单元进行地址分配。</li>
<li>独立编址：设置专门的I/O指令来访问I/O端口。</li>
</ul>
<h2 id="io方式"><a class="header" href="#io方式">I/O方式</a></h2>
<p>主机与I/O设备之间的<strong>数据传输</strong>可以采用不同的<strong>控制方式</strong>。常用的有以下三种方式，其中前两种更依赖于CPU中程序指令的执行。</p>
<h3 id="程序查询方式"><a class="header" href="#程序查询方式">程序查询方式</a></h3>
<p>信息交换的控制完全由主机执行程序实现，该种方式接口中设置一个数据缓冲寄存器（数据端口）和一个设备状态寄存器（状态端口）。主机进行I/O操作时，先发出询问信号，读取设备状态并根据设备状态决定下一步的操作。</p>
<p>这种方式下，CPU一旦启动I/O，就必须停止现行程序的运行，并在现行程序中插入一段程序。这种方式下CPU有踏步等待现象。CPU在信息传送过程中要花费很多时间查询和等待，在一段时间内只能和一台外设交换信息，效率大大降低。</p>
<h3 id="程序中断方式"><a class="header" href="#程序中断方式">程序中断方式</a></h3>
<p>现代计算机系统有完善的异常和中断处理系统，CPU的数据通路有相应的异常和中断的检测和响应逻辑。外设接口中有中断请求和逻辑控制，操作系统中有响应的中断服务程序。这些硬件和中断服务程序有机结合，共同完成异常和中断的处理过程。</p>
<p><strong>异常和中断</strong></p>
<ul>
<li>异常</li>
</ul>
<p>由CPU内部引起的意外事件，分为<strong>硬故障中断</strong>和<strong>程序性异常</strong>。硬故障中断指的是硬连线出现异常引起的，例如电源掉电等；程序性异常指CPU内部因执行异常指令而引起的异常事件。</p>
<p>按照发生异常的报告和返回方式的不同，内部异常可分为：故障、自陷、终止。</p>
<p>故障指在引起故障的指令启动后、执行结束前被检测到的异常事件。</p>
<p>自陷是预先安排的一种异常事件。用于程序调试的断点设置功能就是通过自陷方式实现的。</p>
<p>终止指的是指令执行过程中发生了使计算机无法继续运行的硬件故障，程序无法继续执行，只能终止，此时调用中断服务程序来重启系统。</p>
<ul>
<li>外部中断</li>
</ul>
<p>外部中断指的是来自CPU外部、与CPU执行指令无关的时间引起的中断，包括I/O设备发出的I/O中断、外部信号中断，以及各种定时器引起的时钟中断等。外中断在狭义上一般称为中断。</p>
<p>外部中断和内部异常的不同点：缺页或溢出等异常事件由特定指令在执行过程中产生，而中断不与任何指令相关联，也不阻止任何指令的完成；异常的检测由CPU自身完成，不必通过外部的某个信号通知CPU。对于中断，CPU必须通过总线获取中断源的标志信息，才能知道哪个外部设备发生了何种中断。</p>
<p><strong>中断的基本概念</strong></p>
<p>计算机执行现行程序过程中，出现某些急需处理的异常概况，CPU暂时中止先行程序，转去对这些异常进行处理。</p>
<p><strong>程序中断方式工作流程</strong></p>
<ul>
<li>
<p>中断请求</p>
</li>
<li>
<p>中断判优</p>
</li>
<li>
<p>CPU响应中断的条件</p>
</li>
<li>
<p>中断响应：关中断、保存断点、引出中断服务子程序</p>
</li>
<li>
<p>中断向量</p>
</li>
<li>
<p>中断处理过程</p>
<ul>
<li>中断隐指令（硬件自动完成）
<ul>
<li>关中断</li>
<li>保存断点</li>
<li>引出中断服务程序</li>
</ul>
</li>
<li>中断服务程序
<ul>
<li>保存现场和屏蔽字</li>
<li>开中断（允许更高级中断请求得到响应）</li>
<li>执行中断服务程序</li>
<li>关中断（保证在恢复现场和屏蔽字时不被中断）</li>
<li>恢复现场和屏蔽字</li>
<li>开中断、中断返回</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>多重中断和中断屏蔽技术</strong></p>
<p>CPU在执行中断服务程序的过程中，又出现了新的更高优先级的中断请求，CPU暂停现行，转而去处理新的中断请求，称为多重中断。</p>
<h3 id="dma方式"><a class="header" href="#dma方式">DMA方式</a></h3>
<p>DMA方式在外设与内存直接开辟了一条直接数据通道，信息传送不再经过CPU，降低了CPU再传送数据时的开销。</p>
<p>这种方式适用于高速设备大批量数据的传送，硬件开销较大。DMA方式中，中断仅限于故障和正常传送结束时的处理。</p>
<p><strong>DMA方式的特点</strong></p>
<p><strong>I/O与主机并行</strong>工作，<strong>程序和传送并行</strong>工作。（中断方式中，I/O与主机并行工作，程序和传送串行工作）</p>
<p><strong>DMA控制器的组成</strong></p>
<p>DMA控制器的主要功能：</p>
<ul>
<li>接收外设发出的DMA请求，并向CPU发送总线请求</li>
<li>CPU响应此总线请求，发送总线响应信号，接管总线控制权，进入DMA操作周期</li>
<li>确定传送数据的主存单元以及长度，并自动修改主存地址计数和传送长度计数</li>
<li>规定数据在主存和外设间的传送方向，发送读写等控制信号，执行数据传送操作</li>
<li>向CPU报告DMA操作的结束</li>
</ul>
<p><strong>DMA的传送方式</strong></p>
<p>当I/O设备和CPU同时访问主存时，可能发生冲突，为了有效使用主存，DMA控制器与CPU通常采用以下方式使用主存：</p>
<ul>
<li>停止CPU访存</li>
<li>周期挪用</li>
<li>DMA与CPU交替访存</li>
</ul>
<p><strong>DMA的传送过程</strong></p>
<ul>
<li>预处理</li>
<li>数据传送</li>
<li>后处理</li>
</ul>
<p><strong>DMA方式与中断方式的区别</strong></p>
<ul>
<li></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>进程管理：操作系统的核心。概念、进程调度、信号量机制实现同步和互斥、进程死锁是重点。另外容易出综合题。</p>
<p>内存管理：也是核心内容，围绕分页机制展开。</p>
<p>文件管理：注意对概念的理解</p>
<p>I/O管理：很多内容直接与硬件相关，要结合组成原理复习。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="基本概念-9"><a class="header" href="#基本概念-9">基本概念</a></h2>
<h3 id="操作系统概念"><a class="header" href="#操作系统概念">操作系统概念</a></h3>
<p>计算机系统自下而上分为4部分：硬件、操作系统、应用程序和用户</p>
<p>硬件提供基本的计算资源；应用程序规定用何种方式使用这些资源来解决用户的计算问题；操作系统<strong>控制和协调</strong>各用户的应用程序对硬件的分配和使用。</p>
<h3 id="特征"><a class="header" href="#特征">特征</a></h3>
<p>并发</p>
<p>共享：互斥共享方式、同时访问共享方式</p>
<p>虚拟：虚拟CPU、虚拟存储器、虚拟I/O设备</p>
<p>异步：多道程序环境允许多个程序并发执行，进程的执行不是一贯到底，而是走走停停，以不可预测的速度向前推进。</p>
<h3 id="目标和功能"><a class="header" href="#目标和功能">目标和功能</a></h3>
<p><strong>作为计算机系统资源的管理者</strong></p>
<p>处理机、存储器、文件、设备管理</p>
<p><strong>作为用户与计算机硬件系统之间的接口</strong></p>
<ul>
<li>命令接口：使用命令接口进行作业控制的主要方式有两种：联机控制和脱机控制
<ul>
<li>联机命令接口：交互式命令接口，适用于分时或实时操作系统，由一组键盘操作命令组成。</li>
<li>脱机命令接口：批处理命令接口，适用于批处理系统，由一组作业控制命令组成，脱机用户不能直接干预作业的运行。</li>
</ul>
</li>
<li>程序接口：由一组系统调用(广义指令)组成，用户通过在程序中使用这些系统调用来请求操作系统为其提供服务，如使用各种外部设备、申请分配和回收内存等；</li>
</ul>
<p><strong>操作系统作为扩充机器</strong></p>
<h2 id="操作系统的发展和分类"><a class="header" href="#操作系统的发展和分类">操作系统的发展和分类</a></h2>
<h3 id="手工操作阶段"><a class="header" href="#手工操作阶段">手工操作阶段</a></h3>
<p>计算机上的所有工作都要人工干预，如程序的装入、运行、结果的输出。</p>
<p>缺点：用户独占全机，资源利用率低；CPU利用不充分</p>
<h3 id="批处理阶段"><a class="header" href="#批处理阶段">批处理阶段</a></h3>
<p><strong>单道批处理系统</strong></p>
<p>系统对作业的处理是成批进行的但内存中始终保持一道作业。</p>
<ul>
<li>自动性：磁带上的一批作业能自动逐个运行，无须人工干预</li>
<li>顺序性：磁带上的各道作业顺序地进入内存，各道作业地完成顺序与它们进入内存的顺序在正常状态下完全相同</li>
<li>单道性：内存中只有一道程序运行</li>
</ul>
<p>问题：内存中仅放入一道作业，每当它在运行期间发出I/O请求后，高速CPU便处于等待低速I/O完成的状态。</p>
<p><strong>多道批处理系统</strong></p>
<p>允许多个程序同时进入内存并允许它们在CPU中交替地运行，这些程序共享系统中的各种软硬件资源。</p>
<p>当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。</p>
<p>多道程序设计的特点：</p>
<ul>
<li>多道：计算机内存中同时存放多道相互独立的程序</li>
<li>宏观上并行</li>
<li>微观上串行</li>
</ul>
<p>多道批处理系统把用户提交的作业成批地送进计算机内存，然后由作业调度程序自动地选择作业运行</p>
<p>优点：资源利用率高，系统吞吐量大。</p>
<p>缺点：用户相应时间较长，不能提供人机交互能力，用户既不能了解自己的程序的运行情况，又不能控制计算机。</p>
<h3 id="分时操作系统"><a class="header" href="#分时操作系统">分时操作系统</a></h3>
<p>分时是指把处理器的运行时间分成很短的时间片，按时间片把处理器分配给各联机作业使用。多个用户通过终端共享一台主机，用户可以与主机进行交互操作而互不干扰。</p>
<p>分时系统相比于多道批处理系统能够人机交互功能。</p>
<p>分时系统主要有以下特征：</p>
<ul>
<li>同时性：允许多个终端同时使用一台计算机</li>
<li>交互性：用户能够方便地与系统进行人机对话</li>
<li>独立性：系统中多个用户可以彼此独立地进行操作</li>
<li>及时性：用户请求能在很短时间内获得响应</li>
</ul>
<h3 id="实时操作系统"><a class="header" href="#实时操作系统">实时操作系统</a></h3>
<p>为了能够在某个时间限制内完成某些紧急任务而不需要时间片排队。</p>
<ul>
<li>
<p>硬实时系统：某个动作必须绝对地在规定的时刻发生</p>
</li>
<li>
<p>软实时系统：能够接受偶尔违反时间规定且不会引起任何永久性的损害，例如飞机订票系统等</p>
</li>
</ul>
<h2 id="操作系统的运行环境"><a class="header" href="#操作系统的运行环境">操作系统的运行环境</a></h2>
<h3 id="运行机制"><a class="header" href="#运行机制">运行机制</a></h3>
<p>CPU的状态划分为<strong>用户态</strong>和<strong>核心态</strong>。用户自编程序运行在用户态，操作系统内核程序运行在核心态。</p>
<p>现代操作系统都是层次式的结构；一些与硬件关联较为紧密的模块，例如时钟管理、中断处理、设备驱动等处于最底层；其次是运行频率较高的程序，如进程管理、存储器管理和设备管理。这两部分内容构成了操作系统的内核，这部分内容的指令操作工作在核心态。</p>
<p><strong>时钟管理</strong></p>
<p>时钟的第一个功能是计时，操作系统需要通过时钟管理，向用户提供标准的系统时间。另外通过时钟中断的管理，可以实现进程的切换。</p>
<p><strong>中断机制</strong></p>
<p>中断最初是为了提供多道程序运行环境中CPU的利用率，主要针对外部设备。后来逐步发展形成多种类型，成为操作系统各项操作的基础；例如键盘鼠标的输入、进程管理调度等等。</p>
<p>中断机制中只有一小部分功能属于内核，负责保护和恢复中断线程的信息，转移控制权到相关处理程序。这样可以减少中断的处理时间，提高系统并行处理能力。</p>
<p><strong>原语</strong></p>
<p>操作系统底层有一些可被调用的公用小程序，各自完成一个对丁操作，特点如下：</p>
<ul>
<li>处于操作系统最底层，接近于硬件</li>
<li>这些程序具有原子性，其操作能一气呵成</li>
<li>这些程序的运行时间较短，且调用频繁</li>
</ul>
<p>把具有这些特点的程序称为原语。定义原语的直接方法是关闭中断，让所有动作完成后再打开中断。</p>
<p><strong>系统控制的数据结构及处理</strong></p>
<p>系统中用于登记状态信息的数据结构很多，如作业控制块、设备控制块、消息队列、缓冲区等。为了实现有效管理，系统需要以下一些基本操作：</p>
<ul>
<li>进程管理</li>
<li>存储器管理</li>
<li>设备管理</li>
</ul>
<h3 id="中断和异常"><a class="header" href="#中断和异常">中断和异常</a></h3>
<p>发生中断或异常时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的。中断用来提高系统资源利用率，在程序未使用某种资源时，把它对那种资源的占有权释放。</p>
<p><strong>中断和异常的定义</strong></p>
<p>中断也称为<strong>外中断</strong>，指来自CPU执行指令以外的时间的发生，如设备发出的I/O结束中断，表示设备输入输出已经完成。这一类中断通常是与当前指令执行无关的事件，即它们与当前处理机运行的程序无关。</p>
<p>异常也称为<strong>内中断</strong>，指源自CPU执行指令内部的事件，如程序的非法操作码、地址越界等等。对于异常的处理一般依赖于当前程序的运行线程，异常不能被屏蔽，一旦出现应该立即处理。</p>
<p><strong>中断(外中断)处理的过程</strong></p>
<ul>
<li>关中断：CPU响应中断后，首先要保护程序的现场状态；若现场保存不完整，当中断服务程序结束后就不能正确恢复并继续执行现行程序。</li>
<li>保存断点：将原来的程序的断点（程序计数器PC）保存起来，使得中断结束后能正确返回到原来程序。</li>
<li>中断服务程序寻址：取出中断服务程序地址送入程序计数器PC。</li>
<li>保存现场和屏蔽字：进入中断服务程序后，首先要保存现场信息，一般指程序状态字寄存器PSWR和某些通用寄存器的内容。</li>
<li>开中断：允许更高级中断请求得到响应</li>
<li>执行中断服务程序</li>
<li>关中断</li>
<li>恢复现场和屏蔽字</li>
<li>开中断，中断返回：中断服务程序的最后一条指令一般是中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。</li>
</ul>
<h3 id="系统调用"><a class="header" href="#系统调用">系统调用</a></h3>
<p>用户在程序中调用一些操作系统提供的子功能，系统调用可视为特殊的公共子程序。</p>
<p>一个操作系统提供的系统调用命令可以分为以下几类：</p>
<ul>
<li>设备管理：完成设备的请求或释放</li>
<li>文件管理：完成文件的读、写、创建及删除</li>
<li>进程控制：完成进程创建、撤销、阻塞等</li>
<li>进程通信：完成进程之间的消息传递或信号传递</li>
<li>内存管理：完成内存的分配、回收等</li>
</ul>
<p>系统调用的处理需要由操作系统内核程序负责完成，运行在<strong>内核态</strong>。</p>
<p>用户程序可以执行**陷入指令(又称访管指令)**来发起系统调用，请求操作系统提供服务。相当于用户程序把CPU的主动权交给操作系统内核程序，之后操作系统内核对系统调用请求作出响应，处理完成后内核又把CPU使用权交给用户程序。这么设计是为了让用户程序不能直接执行对系统影响非常大的操作，必须通过系统调用的方式请求操作系统代为操作。</p>
<p>操作系统层面关心的是系统核心态和用户态的软件实现与切换。</p>
<h2 id="操作系统的体系结构"><a class="header" href="#操作系统的体系结构">操作系统的体系结构</a></h2>
<h3 id="大内核和微内核"><a class="header" href="#大内核和微内核">大内核和微内核</a></h3>
<p>大内核将操作系统的主要功能模块都作为一个紧密联系的整体运行在核心态，从而为应用提供高性能的系统服务。因为各管理模块之间共享信息，能够有效利用相互之间的有效特性，具有无可比拟的性能优势。</p>
<p>微内核是为了解决操作系统的内核代码难以维护的问题，将内核中最基本的功能保留在内核，将那些不需要再核心态执行的功能移到用户态执行，降低了内核的设计复杂性。微内核有效分离了内核与服务、服务与服务，使得它们之间的接口更加清晰，降低了维护代价。</p>
<p>微内核最大的问题是性能，需要频繁地在用户态和核心态之间切换，系统的执行开销偏大。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="进程与线程"><a class="header" href="#进程与线程">进程与线程</a></h2>
<h3 id="进程的概念和特征"><a class="header" href="#进程的概念和特征">进程的概念和特征</a></h3>
<p><strong>概念</strong></p>
<p>多道程序环境下，引入进程的概念，以便更好地描述和控制程序的并发执行，实现操作系统的<strong>并发性和共享性</strong>。</p>
<p>为了使得参与并发执行的程序(包含数据)能够独立地运行，必须为之配置一个专门的数据结构，称为<strong>进程控制块(PCB)</strong>。系统利用PCB来描述进程的基本情况和运行状态，进而控制和管理进程。相应地，由<strong>程序段、相关数据段和PCB</strong>三部分构成了<strong>进程映像</strong>（实体）。创建进程实质上是创建<strong>进程映像中的PCB</strong>，撤销进程实际上是撤销进程的PCB。</p>
<p>PCB是<strong>进程存在</strong>的唯一标志。</p>
<p><strong>特征</strong></p>
<ul>
<li>动态性：进程是程序的依次执行，它有着创建、活动、暂停、终止等过程，具有一定的<strong>生命周期</strong>。</li>
<li>并发性：多个进程实体同时存在于<strong>内存</strong>中。</li>
<li>独立性：进程实体是一个能独立运行、独立获得资源、独立接受调度的基本单位</li>
<li>异步性：进程之间相互制约，按照各自独立的、不可预知的速度向前推进；异步性会导致执行结果不可再现，因此在操作系统中必须配置相应的同步机制。</li>
<li>结构性：进程实体由程序段、数据段、PCB三部分组成。</li>
</ul>
<h3 id="进程的状态与转换"><a class="header" href="#进程的状态与转换">进程的状态与转换</a></h3>
<ul>
<li><strong>运行态</strong>：进程正在处理机上运行。单处理机环境下每个时刻最多只有一个进程处于运行态。</li>
<li><strong>就绪态</strong>：进程获得除了处理机外的一切资源，一旦获得处理机资源，就可以立即运行。系统中可能有多个处于就绪态的进程，它们排成一个队列，称为就绪队列。</li>
<li><strong>阻塞态</strong>（等待态）：进程正在等待某一时间而暂停，可能是I/O完成或等待某资源成为可用。</li>
<li>创建态：进程正在被创建，尚未转到就绪态。创建过程：首先申请一个PCB，并向PCB中写入一些控制和管理进程的信息，然后系统为进程分配所需的资源，最后把进程转入就绪态。</li>
<li>结束态：进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。</li>
</ul>
<p>整个系统的3种基本状态之间的转换：</p>
<ul>
<li>就绪态$\rightarrow$运行态</li>
<li>运行态$\rightarrow$就绪态：处于运行态的程序在<strong>时间片用完后</strong>不得不让出处理机，从而从运行态转为就绪态</li>
<li>运行态$\rightarrow$阻塞态：进程请求某一资源的使用和分配或等待某一事件的发生时，就从运行态转换为阻塞态</li>
<li>阻塞态$\rightarrow$就绪态：进程等待的事件到来时，如I/O操作结束或中断结束时，中断处理程序必须把相应的进程的状态转换为就绪态</li>
</ul>
<h3 id="进程控制"><a class="header" href="#进程控制">进程控制</a></h3>
<p>对系统中所有进程实施有效的管理，具有<strong>创建新进程、撤销已有进程、实现进程状态转换</strong>等功能。操作系统中一般把<strong>进程控制用的程序段</strong>称为<strong>原语</strong>。原语执行期间不允许中断，是一个不可分割的单位。</p>
<p><strong>进程的创建</strong></p>
<p>允许一个进程创建另一个进程，创建者称为父进程，被创建的进程称为子进程，子进程可以继承父进程拥有的资源。</p>
<p>操作系统创建一个新进程（原语）的过程如下：</p>
<ul>
<li>为新进程分配一个唯一的进程标识号（<strong>PID</strong>），并申请一个<strong>空白的PCB</strong>。</li>
<li>为进程分配资源，即必要的<strong>内存空间</strong>；若资源不足，并不是创建失败，而是处于阻塞态</li>
<li><strong>初始化PCB</strong>，主要包括初始化标志信息、处理机状态信息和控制信息、进程的优先级</li>
<li>若就绪队列能够接纳新进程，则将新进程<strong>插入就绪队列</strong></li>
</ul>
<p><strong>进程的终止</strong></p>
<p>引起进程终止的事件有：</p>
<ul>
<li>正常结束，任务已经完成准备退出运行</li>
<li>异常结束，进程运行时发生了异常事件，如存储区越界、非法指令等。</li>
<li>外界干预：进程应外界的请求而终止运行，如操作系统干预、父进程终止等。</li>
</ul>
<p>操作系统终止进程的过程；</p>
<ul>
<li>根据终止进程的PID，检索PCB，从中读出进程状态</li>
<li>若处于执行状态，则立即终止该进程，将处理机资源释放</li>
<li>若该进程有子孙进程，则将所有子孙进程终止</li>
<li>将该进程的所有资源归还</li>
<li>将该PCB从所在队列（链表）中删除</li>
</ul>
<p><strong>进程的阻塞和唤醒</strong></p>
<p>正在执行的进程，由于期待某些事情发生，如等待某种操作的完成、新数据尚未到达等，由系统自动执行<strong>阻塞原语Block</strong>，使自己由运行态变为阻塞态；阻塞是进程自身的一种行为，只有<strong>处于运行态</strong>的进程才能转换为阻塞态。阻塞原语的执行过程如下：</p>
<ul>
<li>找到要被阻塞进程的PID对应的PCB</li>
<li>保护现场，将其状态转为阻塞态，停止运行。</li>
<li>将该PCB插入<strong>相应事件的等待队列</strong>，将处理机资源调度给其他就绪进程。</li>
</ul>
<p>当被阻塞进程所期待的事件出现时，调用<strong>唤醒原语Wakeup</strong>将其唤醒：</p>
<ul>
<li>在该事件的等待队列中找到相应进程的PCB</li>
<li>将其从等待队列中移除，置为就序列</li>
<li>将其插入就绪队列，等待调度</li>
</ul>
<p><strong>进程切换</strong></p>
<p>进程切换在内核的支持下实现。进程切换指的是处理机从一个进程的运行转到另一个进程的运行，过程如下：</p>
<ul>
<li>保存处理机上下文，包括程序计数器和其他寄存器</li>
<li>更新PCB信息</li>
<li>将进程的PCB移入相应队列，如就绪、在某事件阻塞等队列</li>
<li>选择另一个进程执行，更新其PCB</li>
<li>更新内存管理的数据结构</li>
<li>恢复处理机的上下文</li>
</ul>
<blockquote>
<p>注：<strong>进程调度</strong>是决定资源分配给哪个进程的行为，是一种<strong>决策行为</strong>；<strong>进程切换</strong>是指实际分配的行为，是<strong>执行行为</strong>。一般先有调度后有执行。</p>
</blockquote>
<h3 id="进程的组成"><a class="header" href="#进程的组成">进程的组成</a></h3>
<p>进程是操作系统进行资源分配和调度的基本单位。由以下三部分组成，其中最核心的时进程控制块（PCB）。</p>
<p><strong>进程控制块</strong></p>
<p>进程创建时，操作系统为其分配一个新的PCB，PCB常驻内存，任何时刻都可以存取，在进程结束时删除。PCB是进程实体的一部分，是进程存在的唯一标志。</p>
<p>进程运行过程中PCB的使用：</p>
<ul>
<li>
<p>系统要调度进程运行时，要从进程的PCB中查出其<strong>现行状态和优先级</strong>。</p>
</li>
<li>
<p>调度到某进程后，要根据PCB中的处理机状态信息设置进程的<strong>恢复运行的现场</strong>，根据程序和数据的内存地址，找到<strong>程序和数据</strong>。</p>
</li>
<li>
<p>进程运行过程中，需要<strong>和其他进程实现同步、通信或访问文件</strong>时，也需要访问PCB</p>
</li>
<li>
<p>当进程由于一些原因<strong>暂停运行</strong>时，需要将其断点的处理机环境保存到PCB中。</p>
</li>
</ul>
<p>PCB包含的各个部分：</p>
<ul>
<li>进程描述信息：进程标识符PID和用户标识符UID</li>
<li>进程控制和管理信息：当前状态、优先级</li>
<li>资源分配清单：用于说明有关内存地址空间和虚拟地址空间的状况</li>
<li>处理机相关信息：处理机中各寄存器的值，便于在该进程被重新执行时能从断电继续运行</li>
</ul>
<p>系统组织各进程的所有PID的方式：</p>
<ul>
<li>链接方式：将同一状态的PCB链接成一个<strong>队列</strong>，不同状态对应不同队列</li>
<li>索引方式：将同一状态的PCB组织在一个索引表中，索引表的表项指向相应的PCB</li>
</ul>
<p><strong>程序段</strong></p>
<p>能被进程调度程序调度道CPU执行的代码；程序可以被多个进程共享。</p>
<p><strong>数据段</strong></p>
<p>可以是进程对应的程序加工处理的原始数据，或者程序执行时产生的中间或最终结果。</p>
<h3 id="进程的通信"><a class="header" href="#进程的通信">进程的通信</a></h3>
<p>指<strong>进程之间的信息交换</strong>。</p>
<p><strong>共享存储</strong></p>
<p>通信进程之间存在一块可以直接访问的共享空间，通过对这块共享空间进行读/写操作实现进程之间交换信息。</p>
<p>对共享空间进行读写时，需要使用<strong>同步互斥工具</strong>（P操作、V操作）。</p>
<p>共享存储分为：</p>
<ul>
<li>低级方式：基于数据结构的共享</li>
<li>高级方式：基于存储区的共享</li>
</ul>
<p>操作系统只提供可共享使用的存储空间和同步互斥工具，数据交换用户自行安排读写指令完成。</p>
<p><strong>消息传递</strong></p>
<p>该系统中，进程间的数据交换以<strong>格式化的消息</strong>为单位。这种方法用于进程之间不存在可以直接访问的共享空间。</p>
<p>进程通过系统提供的发送消息和接收消息两个原语进行数据交换。</p>
<ul>
<li>直接通信方式：发送进程把消息发送给接收进程，并将其挂在接收进程的缓冲队列上</li>
<li>间接通信方式：发送进程把消息发送给某个中间实体，接收进程从实体中获得消息</li>
</ul>
<p><strong>管道通信</strong></p>
<p>管道（pipe文件）是用于链接一个读进程和一个写进程以实现它们之间通信的一个共享文件夹，采用半双工通信。</p>
<p>写进程以字符流的形式将大量数据写入管道；接收进程从管道中读数据。管道机制提供三个方面的协调能力：互斥、同步、确定管道存在。队列形式。</p>
<p>管道和一般文件有所不同，能克服使用文件进行通信时的两个问题：</p>
<ul>
<li>限制管道的大小。管道是一个固定大小的缓冲区。</li>
<li>读进程可能比写进程快，当管道中所有数据已经被读取完后，这时管道中read()调用将被默认阻塞</li>
</ul>
<h3 id="线程概念和多线程模型"><a class="header" href="#线程概念和多线程模型">线程概念和多线程模型</a></h3>
<p><strong>线程基本概念</strong>
引入线程的目的是减小程序在<strong>并发执行</strong>时所付出的开销，提高操作系统的并发性能。</p>
<p>线程的直接理解就是轻量级进程，它是一个<strong>基本的CPU执行单元</strong>，也是程序执行流的<strong>最小单元</strong>，由线程ID、程序计数器、寄存器集合和堆栈组成。</p>
<p>线程是进程中的一个实体，是被系统独立调度和分配的基本单元，线程自己不拥有系统资源，而是与其他属于同一进程的多个线程共享进程的所有资源。</p>
<p>一个线程可以创建和撤销另一个线程，同一进程中的多个线程可以并发执行。线程之间相互制约，运行中存在间断性，拥有运行态、就绪态和阻塞态三种状态。</p>
<p>引入线程后，进程的内涵发生了变化，只作为除了CPU外系统资源的分配单元，线程则作为处理机的分配单元。线程之间的切换只需要花费很少的时空空间。</p>
<p>线程切换时只需要保存和设置少量寄存器，开销很小。另外多个线程共享进程的地址空间，同步和通信很容易实现，无需系统干预。</p>
<p><strong>线程的实现方式</strong></p>
<ul>
<li>
<p>用户级线程：有关线程管理的所有工作都由应用程序完成，内核和意识不到线程的存在，应用程序通过线程库来实现。</p>
</li>
<li>
<p>内核级线程：线程管理的所有工作由内核完成，线程管理对应用程序透明，只有一个到内核级线程的编程接口。</p>
</li>
<li>
<p>另外有些系统使用组合方式的多线程实现。一个应用程序中的多个用户级线程被映射到一些内核级线程上。</p>
</li>
</ul>
<p><strong>多线程模型</strong></p>
<ul>
<li>多对一：多个用户级线程对应一个内核级线程，线程管理在用户空间中完成。</li>
<li>一对一：将一个用户级线程映射到一个内核级线程上。</li>
<li>多对多：将n个用户级线程映射到m个内核级线程上，$m\leq n$。</li>
</ul>
<h2 id="处理机调度"><a class="header" href="#处理机调度">处理机调度</a></h2>
<h3 id="调度的概念"><a class="header" href="#调度的概念">调度的概念</a></h3>
<p><strong>概念</strong></p>
<p>进程数量往往多于处理机的个数，因此<strong>进程竞争</strong>处理机在所难免。处理机调度是按照一定的算法（<strong>公平、高效</strong>），选择一个进程并将处理机分配给它运行，实现进程并发地执行。</p>
<p>处理机调度机制是多道程序操作系统的基础，是操作系统设计的核心问题。</p>
<p><strong>调度的层次</strong></p>
<ul>
<li><strong>作业调度</strong>：又称高级调度，按照一定的原则从<strong>外存上</strong>处于后备状态的作业中挑选一个或多个，给它们分配内存、输入/输出设备等必要资源，并建立相应的进程，使它们获得竞争处理机的权利。简而言之就是内存与辅存之间的调度。执行频率较低，几分钟一次。</li>
<li>中级调度：又称内存调度，作用是提高内存利用率和系统吞吐量。将那些暂时不能运行的进程调至外存等待，此时进程的状态称为<strong>挂起态</strong>。当已具备运行条件且内存又有空闲时，重新调入内存，将其修改为就绪态，挂在就绪队列等待。</li>
<li><strong>进程调度</strong>：又称低级调度，按照某种方法和策略从<strong>就绪队列</strong>中选取一个进程将其交给处理机。进程调度的频率很高，一般几十毫秒一次。</li>
</ul>
<h3 id="调度的时机切换与过程"><a class="header" href="#调度的时机切换与过程">调度的时机、切换与过程</a></h3>
<p>进程调度和切换是操作系统内核程序。<strong>请求调度</strong>的事件发生后，才可能运行<strong>进程调度</strong>程序，调度了新的就绪程序后，才会进行<strong>进程的切换</strong>。这三件事在理论上是按顺序进行的，但实际中，操作系统内核程序运行时若发生了引起进程调度的因素，不一定能马上进行调度和切换：</p>
<ul>
<li>在中断处理过程中。</li>
<li>进程在操作系统内核程序的临界区中。</li>
<li>其他需要完全屏蔽中断的原子操作过程中。</li>
</ul>
<h3 id="进程调度方式"><a class="header" href="#进程调度方式">进程调度方式</a></h3>
<p>调度方式指的是当某个进程正在处理机上执行时，有某个<strong>优先权更高</strong>的进程进入就绪队列，此时应该如何分配处理机的问题。通常由以下两种方式：</p>
<ul>
<li><strong>非剥</strong>夺调度方式：当一个进程正在处理机上执行时，即使有优先权更高的进程进入就绪队列，也要等到正在执行的进程完成或发生某种事件而进入阻塞状态，才把处理机分给优先权更高的进程。这种方式适用于大多数批处理操作系统。</li>
<li><strong>剥夺</strong>调度方式：立即暂停正在执行的进程，将处理机分配给这个优先级更高的进程。这种方式对提供系统吞吐率和响应效率都有明显好处，但这不是一种任意行为，要遵循一定原则。</li>
</ul>
<h3 id="调度的基本准则"><a class="header" href="#调度的基本准则">调度的基本准则</a></h3>
<p>为了比较处理机调度算法的性能，提出了以下一些评价准则：</p>
<ul>
<li>CPU利用率</li>
<li>系统吞吐量：单位时间内CPU完成作业的数量</li>
<li>周转时间：从作业提交到作业完成所经历的事件</li>
<li>等待时间：进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低</li>
<li>响应时间：用户提交请求到系统首次产生响应的时间。</li>
</ul>
<h3 id="典型的调度算法"><a class="header" href="#典型的调度算法">典型的调度算法</a></h3>
<p><strong>先来先服务(FCFS)调度算法</strong></p>
<p>是最简单的调度算法，既可用于作业调度，又可用于进程调度。该算法每次从后备作业队列中选择最先进入该队列的一个或多个作业，调入内存，分配必要资源，创建进程并放入就绪队列。</p>
<p>该算法属于不可剥夺算法。算法简单，但效率低。对长作业有利，对短作业不利。</p>
<p><strong>短作业优先(SJF)调度算法</strong></p>
<p>对短作业优先调度。从后备队列中选择一个运行时间最短的作业，调入内存中。</p>
<p>缺点：</p>
<ul>
<li>对长作业不利，可能导致长作业长期不被调度。</li>
<li>未完全考虑作业的紧迫程度，不能保证紧迫性任务被及时处理。</li>
<li>作业长短是根据用户提供的预估时间而定的，用户可能有意或无意地缩短其作业预估时间，不一定能真正做到短作业优先。</li>
</ul>
<p><strong>优先级调度算法</strong></p>
<p>既可以用于作业调度，又可以用于进程调度。</p>
<p>根据新的更高优先级进程能否抢占正在执行的进程，可将调度算法分为：</p>
<ul>
<li>非剥夺式优先级调度</li>
<li>剥夺式优先级调度</li>
</ul>
<p>根据进程创建后其优先级是否可以改变，将进程优先级分为：</p>
<ul>
<li>静态优先级：优先级在进程创建时决定，且在进程的整个运行时期内不变。</li>
<li>动态优先级：进程运行过程中，根据进程情况的变化动态地调整优先级，主要依据有进程占有CPU时间长短、就绪进程等待CPU时间长短等。</li>
</ul>
<p>进程优先级设置可参照以下原则：</p>
<ul>
<li>系统进程&gt;用户进程</li>
<li>交互式进程&gt;非交互式进程</li>
<li>I/O进程&gt;计算型进程</li>
</ul>
<p><strong>高响应比优先调度算法</strong></p>
<p>是对先来先服务和短作业优先两种调度算法的综合。同时考虑了每个作业的等待时间和估计的运行时间。</p>
<p>每次进行作业调度时，先计算后备作业队列中每个作业的响应比，选择相应比最高的作业投入运行：
$$
响应比R_P=\frac{等待时间+要求服务时间}{要求服务时间}
$$</p>
<ul>
<li>作业等待时间相同时，要求服务时间越短，响应比越高，有利于短作业</li>
<li>要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，响应比越高，是先来先服务</li>
<li>对于长作业，作业的响应比随着等待时间的增加而提高，等待时间足够长，响应比便可以升到很高。</li>
</ul>
<p><strong>时间片轮转调度算法</strong></p>
<p>主要适用于<strong>分时系统</strong>。该种算法中，系统将所有就绪进程按照到达时间的先后次序排成一个队列，进程调度程序总选择队列的第一个进程执行，但仅能运行<strong>一个时间片</strong>，例如100ms，使用完一个时间片后必须立即释放（被剥夺）处理机给下一个就绪的进程，被剥夺的进程返回就绪队列的末尾重新排队，等待再次运行。</p>
<p>时间片的大小对系统性能的影响很大，若时间片过大，就相当于先来先服务算法；若时间片过小，处理机将在进程间频繁切换，使其开销增大，真正用于服务进程的时间变少。需要进行适当选择，需要考虑系统响应时间、系统处理能力等。</p>
<p><strong>多组反馈队列调度算法</strong></p>
<p>是<strong>时间片轮转</strong>调度算法和<strong>优先级</strong>调度算法的综合与发展。通过<strong>动态调整</strong>进程<strong>优先级和时间片大小</strong>，可以兼顾多方面的系统目标。</p>
<p>实现思想如下：</p>
<ul>
<li>设置多个就绪队列，每个队列设置不同的优先级，第1级队列优先级最高，逐次递减。</li>
<li>赋予各个队列中进程执行时间片的大小各不相同。优先级越高的队列中，每个进程的运行时间片越小。</li>
<li>一个新进程进入内存后，首先将其放入第一级队列的末尾，按照FCFS原则排队调度。当轮到该进程执行时，如果能在时间片内执行完，便可撤离系统；若尚未执行完，调度程序便将其转入第2级队列的末尾，再按同样的FCFS原则等待调度，以此类推直到一个进程从第1级依次降到第n级队列后，在第n级队列中按照时间片轮转的方式运行。</li>
<li>仅当第1级队列为空时，调度程序才会调度第2级队列的进程；仅当第1~(i-1)级队列都为空时才会调度第i级队列进程运行，若此时有新进程进入第1~(i-1)级队列，则进入的新进程将抢占处理机，处理机会被分配给更高优先级的进程。</li>
</ul>
<p>优势如下：</p>
<ul>
<li>终端型作业用户：短作业优先</li>
<li>短批处理作业用户：周转时间短</li>
<li>长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理</li>
</ul>
<h2 id="进程同步"><a class="header" href="#进程同步">进程同步</a></h2>
<h3 id="基本概念-10"><a class="header" href="#基本概念-10">基本概念</a></h3>
<p>用来协调不同进程之间的<strong>相互制约关系</strong>。</p>
<p><strong>临界资源</strong></p>
<p>系统中的许多资源只能为一个进程所用，我们将依次<strong>仅允许一个进程使用的资源</strong>称为临界资源。许多物理设备都属于临界资源。</p>
<p>对于临界资源的访问，必须<strong>互斥</strong>地进行，在每个进程中，<strong>访问临界资源的那段代码</strong>被称为<strong>临界区</strong>。我们可以把临界资源的访问过程分为4个部分：</p>
<ul>
<li>进入区：在进入区要检查是否可以进入临界区，若能进入则设置正在访问临界区的标志，阻值其他进程同时进入临界区</li>
<li>临界区：进程访问临界资源的那段代码</li>
<li>退出区：将正在访问临界区的标志清除</li>
<li>剩余区：代码中的其余部分</li>
</ul>
<p>这四类区是对于一个进程而言的，即每个进程都有这4个区；但临界资源是对所有要访问它的进程而言的。</p>
<p><strong>同步</strong></p>
<p>同步也称直接制约关系，指为了完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的<strong>工作次序</strong>而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的<strong>合作</strong>。</p>
<p><strong>互斥</strong></p>
<p>互斥也称<strong>间接制约</strong>关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用资源的进程退出临界后，另一个进程才允许访问此临界资源。</p>
<p>为禁止两个进程同时进入临界区，同步机制应遵循以下准则：</p>
<ul>
<li>空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程<strong>立即进入</strong>临界区</li>
<li>忙则等待：当已有进程进入临界区时，其他试图进入临界区的进程必须<strong>等待</strong></li>
<li>有限等待：对于请求访问的进程，应保证其能在<strong>有限时间内</strong>进入临界区</li>
<li>让权等待：当进程<strong>不能进入</strong>临界区时，应<strong>立即释放进程</strong>，防止进程忙等待</li>
</ul>
<h3 id="实现临界区互斥的基本方法"><a class="header" href="#实现临界区互斥的基本方法">实现临界区互斥的基本方法</a></h3>
<p><strong>软件实现方法</strong></p>
<p>在进入去设置并检查一些<strong>标志</strong>来表明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。</p>
<ul>
<li>单标志法：设置一个公用整型变量turn，用于指示被允许进入临界区的进程标号，即若turn=0，则允许$P_0$进程进入临界区。该算法可以确保每次只允许一个进程进入临界区。两个进程必须交替进入临界区，若某个进程不再进入临界区，另一个进程也无法进入临界区（因为turn没有改变），这样容易造成资源浪费。</li>
</ul>
<pre><code class="language-c">//P_0进程
while(turn != 0);
critical section;
turn = 1;
remainder section;
</code></pre>
<ul>
<li>双标志法先检查：在每个进程访问临界区资源之前，先检查临界资源是否正在被访问，若正被访问，则进程需要等待；邹泽进程才能进入自己的临界区。为此设置一个数据$flag[i]$，如第i个元素值为FALSE，表示$P_i$进程未进入临界区，值为TRUE，表示该进程进入临界区。优点：不用交替进入，可连续使用。缺点：两个进程可能同时进入临界区。</li>
<li>双标志法后检查：上一个算法线检测对方进程状态再置自己的标志，由于再检测和防止中可插入另一个进程到达时的检测操作，会造成两个进程再分别检测后同时进入临界区。为了该算法先将自己的标志置为TRUE，再检测对方状态标志，若对方状态标志为TRUE，则等待，否则进入临界区。两个进程几乎同时都想进入临界区，都将自己的标志置为TRUE，同时检测对方的状态，都想进入，双方相互谦让，谁也进不去，导致饥饿现象。</li>
<li>Peterson's Algorithm：防止两个进程进行无限等待，又设置了一个变量turn，每个变量在先设置自己的标志后再置turn标志。这时再同时检测另一个进程状态标志和允许进入标志，保证两个进程同时要求进入临界时只允许一个进程进入。该算法解决了饥饿现象。</li>
</ul>
<p><strong>硬件实现方法</strong></p>
<p>计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换。</p>
<ul>
<li>
<p>中断屏蔽法：一个进程正在使用处理机执行其临界代码时，防止其他进程进入其临界区进行访问的方式是：禁止一切中断发生。但这样会降低执行效率，限制了处理机交替执行程序的能力。</p>
</li>
<li>
<p>硬件指令方法：</p>
<ul>
<li>TestAndSet指令：该指令是原子操作，执行时不允许被中断。功能是读出指定标志后把该标志置为真。</li>
</ul>
<pre><code class="language-c">boolean TestAndSet (boolean *lock) {
	boolean old;
	old = *lock;
	*lock = true;
	return old;
}
</code></pre>
<p>为每个临界资源设置一个共享布尔变量lock，当lock为true时表示资源正在被占用，否则空闲。在进程访问临界资源之前，使用TestAndSet指令检查和修改lock标志；若有进程在临界区，则重复检查，直到进程退出。</p>
<pre><code class="language-c">while TestAndSet (&amp;lock);	//等待进入临界区
进程的临界区代码;
lock = false;	//使用完临界资源后，置lock为false
进程的其他代码;
</code></pre>
<ul>
<li>Swap指令：该指令的功能是交换两个字（字节）的内容：</li>
</ul>
<pre><code class="language-c">Swap (boolean *a, boolean *b) {
	boolean temp;
	Temp = *a;
	*a = *b;
	*b = temp;
}
</code></pre>
<p>Swap实现互斥详细过程见书。</p>
</li>
</ul>
<p>硬件实现的优点：适用于任意数目的进程；简单且容易验证其正确性。</p>
<p>缺点：进程等待进入临界区时需要耗费处理机时间，不能实现让权等待。</p>
<h3 id="信号量"><a class="header" href="#信号量">信号量</a></h3>
<p>信号量机制是一种功能较强的机制，可以解决互斥与同步的问题，它只能被两个标准原语<code>wait(S)</code>和<code>signal(s)</code>访问，可记为：<strong>P操作和V操作</strong>。</p>
<p>原语指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件实现。</p>
<p><strong>整型信号量</strong></p>
<p>整型信号量被定义为一个用于表示<strong>资源数目</strong>的整型量S，wait和signal操作可描述为：</p>
<pre><code class="language-c">wait(S) {
	while(S&lt;=0);
	S = S - 1;
}
signal(S) {
	S = S + 1;
}
</code></pre>
<p>wait操作中，只要信号量$S\leq 0$，就会不断测试。因此该机制并未遵循让权等待的准则，而是使进程处于忙等状态。</p>
<p><strong>记录型信号量</strong></p>
<p>该信号量是不存在忙等现象的进程同步机制。除了需要用一个用于代表<strong>资源数目</strong>的整型变量value外，再增加一个<strong>进程链表</strong>，用于链接所有等待该资源的进程。记录型信号量可以描述为：</p>
<pre><code class="language-c">typedef struct {
	int value;
	struct process *L;
} semaphore;
</code></pre>
<p>相应的wait(S)和signal(S)操作如下：</p>
<pre><code class="language-c">void wait(semaphore S) {
	S.value--;
	if(S.value &lt; 0) {
		add this process to S.L;
		block(S.L);
	}
}
</code></pre>
<p>S.value--表示进程请求一个该类资源，如果S.value&lt;0，表示该资源已经分配完毕，因此进程调用原语block，进行自我阻塞，放弃处理机，并插入该类资源的等待队列S.L。可见该机制遵循了让权等待原则。</p>
<pre><code class="language-c">void signal (semaphore S) {
	S.value++;
	if (S.value &lt;= 0) {
		remove a process P from S.L;
		wakeup(P);
	}
}
</code></pre>
<p>signal操作表示进程释放一个资源，使系统中可供分配的该类资源数增加1，因此有S.value++。若加1后仍然是$S.value\leq 0$，则表示S.L中仍有进程被阻塞，因此调用wakeup原语，将S.L中第一个等待的进程唤醒。</p>
<p><strong>利用信号量实现同步</strong></p>
<p><strong>利用信号量实现互斥</strong></p>
<p><strong>利用信号量实现前驱关系</strong></p>
<p>前驱图的例子如书上例题所示。</p>
<h3 id="管程"><a class="header" href="#管程">管程</a></h3>
<p>信号量机制中，每个要访问临界资源的进程都要自备PV操作，大量分散的同步操作给系统带来了麻烦，且容易因为同步操作不当而导致系统死锁。产生了一种新的同步工具——管程。管程的特性保证了<strong>进程互斥</strong>，降<strong>低了死锁</strong>发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。</p>
<p><strong>定义</strong></p>
<p>系统中的软硬件资源可以通过一个数据结构抽象地描述，即用少量信息和对资源所执行的操作来表征该资源。忽略其内部结构和实现细节。</p>
<p>管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据。</p>
<p>管程由4部分组成：</p>
<ul>
<li>管程的名称</li>
<li>局部于管程内部的共享数据结构说明</li>
<li>对该数据结构进程操作的一组过程（函数）</li>
<li>对局部于管程内部的共享数据设置初始值的语句</li>
</ul>
<p>管程的定义描述：</p>
<pre><code class="language-c">monitor Demo {
	共享数据结构S;
	init_code() {	//对共享数据结构初始化
		S = 5;	//初始资源数
	}
	
	take_away() {	//申请一个资源
		对共享数据结构x进行一系列处理;
		S--;	//可用资源数-1
		...
	}
	
	give_back() {	//归还一个资源
		对共享数据结构x的一系列处理;
		S++;	//可用资源数+1
		...
	}
}
</code></pre>
<p>管程类似于面向对象程序设计中的一个类。</p>
<p>每次仅允许一个进程进入管程，从而实现进程互斥。</p>
<p><strong>条件变量</strong></p>
<p>将<strong>阻塞原因</strong>定义为条件变量condition。通常一个进程被阻塞的原因有很多，因此在管程中设置了多个条件变量。每个条件变量保存一个<strong>等待队列</strong>，用于记录因该条件变量而阻塞的所有进程，对条件变量只能进行wait和signal两种操作。</p>
<p><code>x.wait</code>：当x对应的条件不满足时，正在调用管程的进程调用x.wait将自己插入x条件的等待队列，并释放管程。</p>
<p><code>x.signal</code>：x对应的条件发生了变化，则调用x.signal，唤醒一个因x条件而阻塞的进程。</p>
<h3 id="经典同步问题"><a class="header" href="#经典同步问题">经典同步问题</a></h3>
<p>大部分练习题和真题可以用消费者-生产者模型或读者-写者问题就能解决。</p>
<h2 id="死锁"><a class="header" href="#死锁">死锁</a></h2>
<h3 id="概念"><a class="header" href="#概念">概念</a></h3>
<p><strong>定义</strong></p>
<p>死锁是多个进程因竞争资源而造成的一种僵局（<strong>互相等待</strong>），若无外力作用，这些进程都将无法向前推进。</p>
<p><strong>产生的原因</strong></p>
<ul>
<li>系统资源的竞争：通常系统中拥有的<strong>不可剥夺资源</strong>数量不足以满足多个进程运行的需要，使得进程在运行过程中因为资源争夺而陷入僵局。</li>
<li>进程推进顺序非法：进程运行过程中，请求和释放资源的顺序不当</li>
<li>死锁产生的必要条件（以下4个要同时满足才能产生死锁）
<ul>
<li>互斥条件：进程对所分配的资源进行排他性地控制</li>
<li>不剥夺条件：进程所获得的资源未使用完之前，不能被其他进程强行夺走，即只能自己释放。</li>
<li>请求并保持条件：进程已经保持了一个或多个资源，但又提出了新的资源请求，而该资源已经被其他进程占有，此时请求进程被阻塞，但对自己已经有的资源保持不放。</li>
<li>循环等待条件：存在一种进程资源的循环等待链，链中每个进程已经拥有的资源被链中下一个进程所请求。（注意：同类的资源可能不止一个）</li>
</ul>
</li>
</ul>
<p>死锁与循环等待条件的区别：死锁的顶一下系统中每类资源都只有一个。</p>
<h3 id="处理策略"><a class="header" href="#处理策略">处理策略</a></h3>
<p><strong>死锁预防</strong></p>
<p>设置条件，破坏产生死锁的4个必要条件之一。</p>
<p><strong>避免死锁</strong></p>
<p>在资源动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。</p>
<p><strong>死锁的检测及解除</strong></p>
<p>不采取任何措施，允许进程运行过程中发生死锁。通过系统检测机构及时检测出死锁并采取措施将其清除。</p>
<h3 id="死锁预防"><a class="header" href="#死锁预防">死锁预防</a></h3>
<p><strong>破坏互斥条件</strong></p>
<p>有些资源是临界资源，只能互斥使用，所以破坏互斥条件不太可行。</p>
<p><strong>破坏不剥夺条件</strong></p>
<p>当一个进程已经保持了某些不可剥夺资源并请求新的资源的得不到满足时，必须释放已经持有的资源，以后需要时再重新申请。</p>
<p>这种策略实现起来较为复杂，并且可能造成进程前一阶段的工作失效，反复申请和释放资源会增加系统开销，降低吞吐量。这种方法适用于状态易于保存和恢复的资源，比如CPU的寄存器和内存资源，不适合于打印机。</p>
<p><strong>破坏请求并保持条件</strong></p>
<p>采用预先静态分配方法，在进程运行前一次申请完它所需的全部资源，资源不满足时，不投入运行。</p>
<p>这种方法实现简单，但系统资源被严重浪费，例如某些资源可能只需要在进程结束的时候使用，还可能导致饥饿现象。</p>
<p><strong>破坏循环等待条件</strong></p>
<p>可以采用顺序资源分配法。给系统中的资源编号，规定每个进程只能按照递增的顺序请求资源，同类资源一次申请完。</p>
<p>这种方法的问题是编号必须相对稳定，这就限制了新类型资源的增加；另外还可能造成资源浪费。</p>
<h3 id="死锁避免"><a class="header" href="#死锁避免">死锁避免</a></h3>
<p>避免死锁同样属于事先预防策略；这种方法施加的限制较弱，可以获得较好的系统性能。</p>
<p><strong>系统安全状态</strong></p>
<p>避免死锁的方法中，允许进程动态地申请资源，但在系统进行资源分配前，应先计算此次分配的安全性，若该次分配不会导致系统进入不安全状态，则允许分配；否则放进程等待。</p>
<p>安全状态：系统能够按照某种进程推进顺序$(P_1,P_2,...,P_n)$为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，使得每个进程都可以顺序完成。此时称整个序列为安全序列。</p>
<p>并非所有不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态。</p>
<p><strong>银行家算法</strong></p>
<p>该算法基于安全状态的判断。将操作系统视为银行家。操作系统按照银行家指定的规则为进程分配资源。进程运行前先声明对于各种资源的最大需求，当进程在执行中继续申请资源时，先测试已占用资源和本次申请资源数之和是否超过该进程声明的最大需求量。若超过则拒绝分配资源，若未超过则测试系统是否能满足，若能满足则分配，不满足则推迟分配。</p>
<ul>
<li>
<p>数据结构描述</p>
<ul>
<li>可利用资源向量Available：含有m个元素的数组</li>
<li>最大需求矩阵Max：n*m矩阵，定义系统中n个进程对m类资源的最大需求</li>
<li>分配矩阵Allocation：n*m矩阵，每个进程已获得的每类资源的数量</li>
<li>需求矩阵Need：n*m矩阵，每个进程接下来最多还需要多少资源</li>
</ul>
<p>$$
Need = Max - Allocation
$$</p>
</li>
<li>
<p>银行家算法描述</p>
</li>
<li>
<p>安全性算法</p>
</li>
</ul>
<h3 id="死锁检测和解除"><a class="header" href="#死锁检测和解除">死锁检测和解除</a></h3>
<p><strong>资源分配图</strong></p>
<p><strong>死锁定理</strong></p>
<p>系统状态S为死锁的条件是当且仅当S状态的资源分配图是不可简化的。</p>
<div style="break-before: page; page-break-before: always;"></div><p>本章围绕<strong>分页机制</strong>展开，通过分页管理方式在物理内存大小的基础上提高内存的利用率，再进一步引入请求分页管理方式，实现虚拟内存，使内存脱离物理大小的限制，从而提高处理器的利用率。</p>
<h2 id="内存管理概念"><a class="header" href="#内存管理概念">内存管理概念</a></h2>
<h3 id="基本原理和要求"><a class="header" href="#基本原理和要求">基本原理和要求</a></h3>
<p>内存管理的功能有：</p>
<ul>
<li>内存空间的分配与回收</li>
<li>地址转换</li>
<li>内存的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存</li>
<li>存储保护</li>
</ul>
<p><strong>程序装入和链接</strong></p>
<p>创建进程首先要将程序和数据装入内存。将源程序变为可在内存中运行的程序，需要以下步骤：</p>
<ul>
<li>编译：将源代码编译成若干目标模块</li>
<li>链接：将编译后形成的目标模块和所需的库函数链接在一起，形成完整的装入模块</li>
<li>装入：由装入程序将装入模块装入内存</li>
</ul>
<p>程序的链接有以下三种方式：</p>
<ul>
<li>静态链接：程序运行前，链接为一个完成的可执行程序，以后不再拆开</li>
<li>装入时动态链接：目标模块装入内存时边装入边链接</li>
<li>运行时动态链接：对某些目标模块，在程序执行过程中需要该目标模块时才进行链接，便于修改和更新。</li>
</ul>
<p>内存的装入模块在装入内存时同样有三种方式：</p>
<ul>
<li>绝对装入：程序将驻留在内存中的某个位置，则编译将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。无需对程序和数据的地址进行修改。只适用于单道程序环境。</li>
<li>可重定位装入：多道程序环境下，多个目标模块的起始地址通常都从0开始，程序中的其他地址都是相对于始址的，此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入内存的适当位置。装入时对目标程序中的指令和数据的修改过程称为重定位。特点是一个作业装入内存时必须分配要求的全部内存空间，若内存不够则无法装入。</li>
<li>动态运行时装入：装入程序把装入模块装入内存后，不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。装入后的所有地址为相对地址。</li>
</ul>
<p><strong>逻辑地址空间与物理地址空间</strong></p>
<p>地址重定位。</p>
<p><strong>内存保护</strong></p>
<p>内存分配前需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。内存保护的两种方式：</p>
<ul>
<li>在CPU中设置一对<strong>上下限寄存器</strong>，存放用户作业在主存中的上限和下限地址，当CPU要访问一个地址时进行比较，判断是否越界。</li>
<li>采用<strong>重定位寄存器</strong>和<strong>界地址寄存器</strong>实现。</li>
</ul>
<h3 id="覆盖与交换"><a class="header" href="#覆盖与交换">*覆盖与交换</a></h3>
<p>在多道程序环境下用来扩充内存。</p>
<p><strong>覆盖</strong></p>
<p>把用户空间分成<strong>一个固定区和若干覆盖区</strong>。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前再调入覆盖区。</p>
<p>覆盖区打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍然不能运行。</p>
<p><strong>交换</strong></p>
<p>把处于等待状态的程序从内存移到辅存，把内存腾出来，称为换出。把准备好竞争CPU运行的程序从辅存移入内存，称为换入。第2章中的中级调度采用的就是交换技术。</p>
<p>需要注意的问题：</p>
<ul>
<li>交换需要备份存储</li>
<li></li>
</ul>
<h3 id="连续分配管理方式"><a class="header" href="#连续分配管理方式">连续分配管理方式</a></h3>
<p>指为一个用户程序分配一个连续的内存空间。</p>
<p><strong>单一连续分配</strong></p>
<p>内存在此方式下分为用户区和系统区，系统区仅供操作系统使用，在低地址部分；用户区是为用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。内存中永远只有一道程序。</p>
<p>这种方式只能用于单用户、单任务的操作系统中，有内部碎片，存储器的利用率低。</p>
<p><strong>固定分区分配</strong></p>
<p>将用户空间划分为<strong>若干固定大小的区域</strong>，每个分区只装入<strong>一道作业</strong>。当有空闲分区时便可从外存的后备作业队列中选择适当大小的作业装入该分区。</p>
<p>固定分区分配在划分时有两种不同方法：</p>
<ul>
<li>分区大小相等</li>
<li>分区大小不相等</li>
</ul>
<p>为了便于内存分配通常将分区按照大小排队，并为之建立一张<strong>分区说明表</strong>，其中包括每个分区的始址、大小及状态（是否已分配）。</p>
<p>这种方式的问题：</p>
<ul>
<li>程序可能太大而放不进任何一个分区中</li>
<li>主存利用率低，当程序小于固定分区大小时，一部分内存空间就浪费了，称为内部碎片</li>
</ul>
<p><strong>动态分区分配</strong></p>
<p>这种方法不预先划分内存，而是在进程装入内存时，<strong>根据进程的大小</strong>动态地建立分区，并使分区的大小整合适合进程的需要。</p>
<p>动态分区在开始分配时是很好的，但之后会导致内存中出现许多小的内存块，随着时间的推移产生越来越多的碎片，内存利用率随之下降。这些小内存块称为外部碎片。</p>
<p>在进程装入或换入主存时，若内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，考虑以下几种算法：</p>
<ul>
<li>首次适应算法：空闲分区以<strong>地址递增</strong>的次序链接。分配时顺序查找，找到大小能满足的第一个分区。</li>
<li>最佳适应算法：空闲分区以<strong>容量递增</strong>的方式形成分区链，找到第一个能满足要求的空闲分区</li>
<li>最坏适应（最大适应）算法：空闲分区以<strong>容量递减</strong>的次序链接。</li>
<li>邻近适应算法：又称循环首次适应算法。由首次适应演变而来。不同之处时分配内存时从上次查找结束的位置开始继续查找。</li>
</ul>
<h3 id="非连续管理分配方式"><a class="header" href="#非连续管理分配方式">非连续管理分配方式</a></h3>
<p>允许一个程序分散地装入不相邻的内存分区。</p>
<p>非连续分配管理方式根据<strong>分区的大小是否固定</strong>，分为<strong>分页</strong>存储管理方式和<strong>分段</strong>存储管理方式。</p>
<p>分页存储管理方式中，又根据运行时是否要把作业的所有页面都装入内存中才能运行，分为<strong>基本</strong>分页存储管理方式和<strong>请求</strong>分页存储管理方式。</p>
<p><strong>基本分页存储管理方式</strong></p>
<p>分页的思想：把<strong>主存空间</strong>划分为大小相等且固定的块，块相对较小，作为主存的基本单位。<strong>每个进程</strong>也以块为单位进行划分，进程执行时以块为单位逐个申请内存中的块空间。</p>
<p><strong>（1）几个概念</strong></p>
<ul>
<li>
<p>页面和页面大小：进程中的块称为<strong>页</strong>，内存中的块称为<strong>页框</strong>。外存也以同样的单位进行划分，直接称为<strong>块</strong>。进程执行时需要申请主存空间，即要为每个页面分配主存中可用的页框。（每页大小一般为4KB）</p>
</li>
<li>
<p>地址结构：（地址长度为32位）</p>
<ul>
<li>页号P：12-31位为页号，地址空间最多允许$2^{20}$页</li>
<li>页内偏移量W：0-11位为页内地址，即每页大小为4KB</li>
</ul>
<p>地址结构决定了虚拟内存的寻址空间有多大。</p>
</li>
<li>
<p>页表：由页表项构成：</p>
<ul>
<li>页号：</li>
<li>物理内存中的块号</li>
</ul>
</li>
</ul>
<p>配置页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。</p>
<p><strong>（2）基本地址变换机构</strong></p>
<p>从逻辑地址到物理地址的转换。</p>
<p><strong>（3）具有快表的地址变换机构</strong></p>
<p><strong>快表</strong>为地址变换机构中的一个具有并行查找能力的高速缓冲器，又称相联存储器TLB。与此对应，内存中的页表通常称为<strong>慢表</strong>。</p>
<p>慢表存取一条数据或指令需要进行两次访存，而使用快表仅需一次。</p>
<p>具有快表的分页机制中，地址变换过程如下：</p>
<ul>
<li>CPU给出逻辑地址后由硬件进行地址转换，将页号送入高速缓冲存储器，并将此页号与快表中所有页号进行比较</li>
<li>若找到匹配的页号，说明所要访问的页表项在快表中，直接从中取出该页对应的页框号（物理块号），与页内偏移地址拼接形成物理地址。如此便可实现一次访问存取数据。</li>
<li>若未找到匹配的页号，则要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能的再次访问。</li>
</ul>
<p>快表命中率可以达到90%以上，快表的有效性基于局部性原理。</p>
<p><strong>（3）两级页表</strong></p>
<p>建立页表的页表，详情见书上的例子。</p>
<p><strong>基本分段存储管理方式</strong></p>
<p>分区大小不固定</p>
<p>分段考虑了用户和程序员，以满足方便编程、信息保护和共享、动态增长以及动态链接等多方面的需求。</p>
<ul>
<li>
<p>分段：逻辑地址由<strong>段号S</strong>与<strong>段内偏移量W</strong>组合而成。</p>
<p>页式系统中逻辑地址的页号和页内偏移量<strong>对用户是透明</strong>的，而段式系统中，段号和段内偏移量必须<strong>由用户显示提供</strong>。高级程序设计语言中，这个工作由<strong>编译器</strong>完成。</p>
</li>
<li>
<p>段表：逻辑空间与内存空间的映射表。每个段表项对应进程的一段，段表项记录该段在内存中的<strong>始址</strong>和<strong>长度</strong>。配置段表后，执行中的进程可以通过查找段表，找到每段对应的内存区。</p>
</li>
<li>
<p>地址变换机构：</p>
<ul>
<li>从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W。</li>
<li><strong>比较段号S和段表长度M</strong>，如果S大于等于M，则产生<strong>越界中断</strong>，否则继续执行。</li>
<li>段表中段号S对应的段表项地址=段表始地址F+段号S*段表项长度，取出段表项的前几位得到段长C，如果<strong>段内偏移量大于等于段长C</strong>，则产生<strong>越界中断</strong>。</li>
<li>取出段表项中该段的始址b，计算得到物理地址E=b+W，用E去访问内存。</li>
</ul>
</li>
<li>
<p>段的共享与保护</p>
<ul>
<li>段的共享：通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现。</li>
<li>段的保护：
<ul>
<li>存取控制保护</li>
<li>地址越界保护：将段表寄存器中的段表长度与逻辑地址中的段号S进行比较，若段号大于段表长度则产生越界中断；再将段表项中的段长与逻辑地址中的段内偏移量进行比较，若段内偏移大于段长，也会产生越界中断。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>段页式管理方式</strong></p>
<p>页式存储管理能有效提高内存利用率，分段存储管理能反映程序的逻辑结构并有利于段的共享。段页式存储将这两种方法结合起来。</p>
<p>该系统中，作业的地址空间首先被分成<strong>若干逻辑段</strong>，每段都有自己的<strong>段号</strong>，然后将每个段分为若干<strong>大小固定的页</strong>。对物理内存的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的<strong>存储块</strong>。</p>
<p>段页式系统中，作业的<strong>逻辑地址</strong>分为三部分：<strong>段号、页号和页内偏移量</strong>。</p>
<p>为了实现地址变换，系统为每个进程建立一个<strong>段表</strong>，每个分段有一张<strong>页表</strong>。段表中包括<strong>段号、页表长度和页表始址</strong>，页表表项中至少包括<strong>页号和块号</strong>。此外系统还有一个<strong>段表寄存器</strong>，指出作业的段表始址和段表长度。</p>
<p>一个进程中，段表只有一个，页表可能有多个。每个<strong>进程</strong>对应<strong>一个段表</strong>，<strong>每段</strong>对应<strong>一个页表</strong>，<strong>段的长度</strong>必须是<strong>页长的整数倍</strong>，段的起点必须是某一页的起点。</p>
<p>地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。进行一次访问实际需要三次访问主存，这里同样可以使用<strong>快表</strong>来加快查找速度，其关键字由<strong>段号、页号</strong>组成。</p>
<p>段页式管理的地址空间是二维的。</p>
<h2 id="虚拟内存管理"><a class="header" href="#虚拟内存管理">虚拟内存管理</a></h2>
<h3 id="基本概念-11"><a class="header" href="#基本概念-11">基本概念</a></h3>
<p><strong>传统存储管理方式的特征</strong></p>
<p>上一节的内存策略都是为了同时将多个进程保存在内存中，以便允许多道程序设计。它们有以下共同特征：</p>
<ul>
<li><strong>一次性</strong>：作业必须一次性全部装入内存后才能开始运行</li>
<li><strong>驻留性</strong>：作业装入内存后，就一直驻留在内存中，任何部分都不会被换出，直到作业结束。</li>
</ul>
<p>许多在程序运行中不用或暂时不用的程序（数据）占据了大量内存空间，而一些需要运行的作业又无法装入，浪费了宝贵的内存资源。</p>
<p><strong>局部性原理</strong></p>
<p>高速缓存。</p>
<ul>
<li>时间局部性：程序中某条指令一旦执行，不久后可能再次执行。典型原因是程序中存在大量循环操作</li>
<li>空间局部性：一旦程序访问了某个存储单元，不久后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，因为指令通常是顺序存放、顺序执行的。</li>
</ul>
<p>内存-外存两级存储结构，利用局部原理实现了高速缓存。</p>
<p><strong>虚拟存储器的定义和特征</strong></p>
<p>程序装入时，将程序的一部分装入内存，而将其余部分留在外存，就可启动程序。程序执行过程中当所访问的信息不在内存中时，由操作系统将所需的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存，从而腾出空间存放将要调入内存的信息。</p>
<p>这种虚拟存储器实际上不存在，只是由系统提供了部分装入、请求调入和置换功能。虚拟存储器的大小由计算机的地址结构决定。</p>
<p>虚拟存储器有以下特征：</p>
<ul>
<li>多次性：无须在作业时一次性地全部装入内存，允许被分成多次调入内存运行</li>
<li>对换性：无需在作业运行时一直常驻内存，允许在作业的运行过程中，进行换进和换出。</li>
<li>虚拟性：从逻辑上扩充内存容量</li>
</ul>
<p><strong>虚拟内存技术的实现</strong></p>
<p>虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。</p>
<p>虚拟内存的实现有以下方式：</p>
<ul>
<li>请求分页存储管理</li>
<li>请求分段存储管理</li>
<li>请求段页式存储管理</li>
</ul>
<p>不管是以上哪种方式，都需要硬件支持：</p>
<ul>
<li>一定容量的内存和外存</li>
<li>页表机制，作为主要的数据结构</li>
<li>中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断</li>
<li>地址变换机构，逻辑地址到物理地址的变换</li>
</ul>
<h3 id="请求分页管理方式"><a class="header" href="#请求分页管理方式">请求分页管理方式</a></h3>
<p>建立在基本分页系统基础之上。为了支持虚拟存储器功能增加了<strong>请求调页</strong>功能和<strong>页面置换</strong>功能。</p>
<p>该系统中，只要求将当前需要的一部分页面装入内存，便可启动作业。作业执行过程中，当所要访问的页面不在内存中时，通过调页功能将其调入，同时还可以通过页面置换将暂时不用的页面换出到外存上，以便腾出内存空间。</p>
<p><strong>页表机制</strong></p>
<p>发现和处理需要访问的页面不在内存中的情况。</p>
<p>请求页表项中增加了4个字段：</p>
<table><thead><tr><th>页号</th><th>物理块号</th><th>状态位P</th><th>访问字段A</th><th>修改位M</th><th>外存地址</th></tr></thead><tbody>
</tbody></table>
<ul>
<li>状态位P：用于指示该页是否已经调入内存</li>
<li>访问字段A：用于记录本页在一段时间内被访问的次数，为置换算法提供参考</li>
<li>修改位M：标识该页在调入内存后是否被修改过</li>
<li>外存地址：指出该页在外存上的地址，通常是物理块号</li>
</ul>
<p><strong>缺页中断机制</strong></p>
<p>每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页调入内存。</p>
<p>与一般中断相比，具有以下两个明显区别：</p>
<ul>
<li>在指令执行期间而非一条指令执行完成后产生和处理中断信号，属于内部中断</li>
<li>一条指令在执行期间可能产生多次缺页中断</li>
</ul>
<p><strong>地址变换机构</strong></p>
<ul>
<li>首先检索快表</li>
<li>若找到要访问的页，则修改页表项中的访问位（写指令还需重置修改位），然后利用页表中给出的物理块号和页内地址偏移形成物理地址</li>
<li>若未找到该页的页表项，则到内存中去查找页表，再对比页表项中的状态位，看该页是否调入内存，未调入则产生缺页中断，请求将该页从外存调入内存。</li>
</ul>
<h3 id="页面置换算法"><a class="header" href="#页面置换算法">页面置换算法</a></h3>
<p>进程运行时，若其访问的页面不在内存中而需将其调入，但内存中已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区。</p>
<p><strong>选择调出页面</strong>的算法就称为页面置换算法。好的页面置换算法应有较低的页面更换频率，即以后不会再访问或以后较长时间不访问的页面先调出。</p>
<p><strong>最佳（OPT）置换算法</strong></p>
<p>该算法选择的被淘汰页面是<strong>以后永不使用</strong>的页面，或是在<strong>最长时间内不再被访问</strong>的页面，以保证最低的缺页率。</p>
<p>由于人们无法预知哪个是未来最长时间不再被访问的，因此该算法无法实现。但该算法可以用来评价其他算法。</p>
<p><strong>先进先出（FIFO）置换算法</strong></p>
<p>优先淘汰最早进入内存的页面，只需把调入内存的页面根据先后次序链接成队列，设置一个指针指向最早的页面即可。但该算法与进程实际运行时的规律不符，在进程中有些页面经常被访问。</p>
<p>FIFO算法还会产生所分配的物理块数增大而页故障数不减反增的异常现象，称为<strong>Belady现象</strong>。</p>
<p><strong>最近最久未使用（LRU）置换算法</strong></p>
<p>该算法为每个页面设置一个访问字段，来记录页面<strong>上次被访问以来所经历的时间</strong>，淘汰页面时选择现有页面中值最大的予以淘汰。</p>
<p>LRU算法是向前看的，而最佳置换算法是向后看的。</p>
<p>LRU算法性能较好，但需要寄存器和栈的硬件支持。该算法是堆栈类算法，不会发生Belady异常；FIFO是队列算法。</p>
<p><strong>时钟（CLOCK）置换算法</strong></p>
<p>算法要扫描缓冲区，像时钟的指针一样转动，所以称为CLOCK算法。</p>
<p>（1）简单CLOCK算法</p>
<p>为每个帧关联一个附加位，称为<strong>使用位</strong>，当某页首次装入主存时，将该帧的使用位置为1；当该页随后再被访问到时，其使用位也被置为1。页替换算法的候选帧集合可视为一个循环缓冲区，并有一个指针与之相关联。</p>
<p>当某一页被替换时，该指针被设置成指向缓冲区的下一帧；当需要替换一页时，操作系统扫描缓冲区，查找使用位被置为1的一帧；每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；若在这个过程开始时缓冲区所有使用位都为0，则选择遇到的第一个帧；若所有帧的使用位都为1，则指针在缓冲区完整地循环一周，把所有使用位置为0，然后选择最初停留的帧。</p>
<p>（2）改进型COLCK算法</p>
<p>在<strong>使用位</strong>的基础上，增加一个<strong>修改位</strong>。每帧都处于以下4中情况：</p>
<ul>
<li>最近未被访问，也未被修改（u=0，m=0）</li>
<li>最近被访问，但未被修改（u=1，m=0）</li>
<li>最近未被访问，但被修改（u=0，m=1）</li>
<li>最近被访问，被修改（u=1，m=1）</li>
</ul>
<p>首先置换出未使用过的页面，如果所有页面都被使用过，则首先置换未修改过的页面，最后再置换使用过且修改过的页面。</p>
<h3 id="页面分配策略"><a class="header" href="#页面分配策略">页面分配策略</a></h3>
<p><strong>驻留集大小</strong></p>
<p>进程准备执行时，不需要也不可能把一个进程的所有页都读入内存。操作系统要决定给特定进程分配几个页框。给一个进程分配的<strong>物理页框的集合</strong>就是这个进程的<strong>驻留集</strong>。需要考虑以下因素：</p>
<ul>
<li>分配给一个进程的存储量越小，驻留在主存中的进程数就越多，时间利用率越高。</li>
<li>一个进程在主存中的页数过少，尽管有局部性原理，页错误率仍然较高。</li>
<li>若页数过多，则由于局部性原理，分配更多内存空间也不会影响错误率。</li>
</ul>
<p>因此，常采用以下策略：</p>
<ul>
<li>
<p><strong>固定分配局部置换</strong>：为每个进程分配一定数目的物理块，在整个运行期间都不变。若进程发生缺页，则只能从该进程在内存的页面中选择一页换出，然后调入需要的页面。这种策略难以确定为每个进程分配的物理块数；太少会频繁缺页，太多会使其他资源使用率下降。</p>
</li>
<li>
<p><strong>可变分配全局置换</strong>：为每个进程分配一定数目的物理块，操作系统也保持一个空闲的物理块队列。当进程发生缺页时，系统从空闲物理块队列取出一个物理块分配给该进程。这种方法会盲目给进程增加物理块，导致多道程序并发能力下降。</p>
</li>
<li>
<p><strong>可变分配局部置换</strong>：为每个进程分配一定数目的物理块，发生缺页时，只允许从该进程在内存的页面中选择一页换出，不会影响其他进程运行；当进程在运行中频繁缺页，则系统再为该进程分配一定数据物理块，直到进程的缺页率趋于适当；若进程运行的缺页率特别低，则可适当减少分配给该进程的物理块。这种方法既能动态增加物理块数量，还能动态减少进程物理块数量，既保证不会过多调页，又能保证系统的多道程序并发性能。</p>
</li>
</ul>
<p><strong>调入页面的时机</strong></p>
<p>用来确定进程将运行时所缺的页面调入内存的时机，可采取以下策略：</p>
<ul>
<li>
<p>预调页策略：采取以预测为基础的预调页策略，将预计在不久后便会访问的页面预先调入内存。但目前成功率为50%左右。这种策略主要用于进程的首次调入。</p>
</li>
<li>
<p>请求调页策略：缺页时系统提出调用请求，每次只调入一页，调入调出页面时会花费过多的I/O开销。</p>
</li>
</ul>
<p><strong>从何处调入页面</strong></p>
<p>请求分页系统的外存分为两部分：用于存放文件的<strong>文件区</strong>和用于存放对换页面的<strong>对换区</strong>。文件区采用<strong>离散</strong>分配方式，对换区采用<strong>连续</strong>分配方式，对换区的<strong>I/O速度更快</strong>。</p>
<ul>
<li>系统拥有足够的对换区空间时：全部从对换区调入页面。</li>
<li>系统缺少足够的对换区空间时：凡是不会修改的文件都直接从文件去调入；换出这些页面时，由于他们未被修改而不必将其换出。对于那些可能被修改的部分，在其换出时调到对换区，以后需要时再从对换区调入。</li>
<li>UNIX方式：与进程有关的文件都放在文件去，因此从未运行过的页面都从文件区调入；曾经运行过又被换出的页面，由于存放在对换区，下次调入是应从对换区调入。</li>
</ul>
<h3 id="抖动"><a class="header" href="#抖动">抖动</a></h3>
<p>页面置换过程中，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为称为抖动或颠簸。若一个进程<strong>在换页上用的时间多于执行时间</strong>，则这个进程就在颠簸。</p>
<h3 id="工作集"><a class="header" href="#工作集">工作集</a></h3>
<p>工作集指在某段<strong>时间间隔内</strong>进程<strong>要访问的页面集合</strong>。工作集反映了再接下来的一段时间内很可能频繁访问的页面集合。</p>
<p>工作集由时间t和窗口大小$\Delta$来确定。一般分配给进程的物理块数要大于工作集的大小。</p>
<p>落在工作集中的页面需要调入驻留集，落在工作集外的页面可以从驻留集中换出。</p>
<h3 id="地址翻译"><a class="header" href="#地址翻译">地址翻译</a></h3>
<p>结合高速缓存分析从虚拟内存访问的过程。</p>
<p>查找顺序从TLB表到页表（TLB不命中），再到Cache和主存，最后到外存。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="文件系统基础"><a class="header" href="#文件系统基础">文件系统基础</a></h2>
<h3 id="文件的概念"><a class="header" href="#文件的概念">文件的概念</a></h3>
<p><strong>文件的定义</strong></p>
<p>系统运行时，计算机以进程为单位进行资源的调度和分配。用户进行的输入、输出中，以文件为基本单位。</p>
<p>操作系统的文件系统用来管理和维护文件。</p>
<p>文件的结构化表述：</p>
<ul>
<li>数据项：文件系统中给最低级的数据组织形式，分为：
<ul>
<li>基本数据项：用于描述一个对象的某种属性的一个值</li>
<li>组合数据项：多个基本数据项的集合</li>
</ul>
</li>
<li>记录：一组相关的数据项的集合，用于描述一个对象在某方面的属性</li>
<li>文件：创作者定义的一组相关信息的集合，分为：
<ul>
<li>有结构文件（记录式文件）</li>
<li>无结构文件（流式文件）</li>
</ul>
</li>
</ul>
<p>文件可以是数字、字母或二进制代码，基本访问单元可以是字节、行或记录。</p>
<p><strong>文件的属性</strong></p>
<ul>
<li>名称：文件名称唯一</li>
<li>标识符：标识文件系统内文件的唯一标签，通常为数字</li>
<li>类型</li>
<li>位置</li>
<li>大小</li>
<li>保护</li>
<li>时间、日期和用户标识</li>
</ul>
<p>所有文件信息都保存在<strong>目录结构</strong>中，而目录结构保存在<strong>外存</strong>中。</p>
<p><strong>文件的基本操作</strong></p>
<p>文件属于抽象数据类型，操作系统提供系统调用，对文件进行以下操作：</p>
<ul>
<li>创建文件：创建空间+创建条目</li>
<li>写文件</li>
<li>读文件</li>
<li>文件重定位（文件寻址）</li>
<li>删除文件</li>
<li>截断文件</li>
</ul>
<p><strong>文件的打开与关闭</strong></p>
<p>许多系统要求在首次使用文件时，使用系统调用open将指明文件属性（包括文件在外存上的物理位置）从外存复制到<strong>内存</strong>打开文件表的一个表目中，并将该标目的编号（索引）返回给用户。系统维护一个包含所有打开文件信息的表——<strong>打开文件表</strong>。当用户需要一个文件操作时，可通过该表的一个<strong>索引</strong>指定文件，省略了搜索环节。文件不再使用时，进程可以关闭它，操作系统从打开文件表中删除这个条目。</p>
<p>大部分操作系统要求在文件使用前就被显示地打开。操作open会<strong>根据文件名搜索目录</strong>，并将该<strong>目录条目</strong>复制到打开文件表。若调用open的请求（创建、只读、读写、添加等）得到允许，则进程可以打开文件。open通常返回一个指向打开文件表中的一个条目的<strong>指针</strong>，通过使用该指针进行I/O操作，来简化步骤并节省资源。</p>
<p>每个打开文件都有如下关联信息：</p>
<ul>
<li>文件指针</li>
<li>文件打开计数：多个进程可能打开同一个文件，系统在删除打开文件前，必须等待最后一个进程关闭文件。计数为0时，系统关闭文件，删除该条目。</li>
<li>文件磁盘位置</li>
<li>访问权限</li>
</ul>
<h3 id="文件的逻辑结构"><a class="header" href="#文件的逻辑结构">文件的逻辑结构</a></h3>
<p>文件的逻辑结构是从<strong>用户角度</strong>看文件的组织形式，<strong>与存储介质的特性无关</strong>，实际上是指在文件的内部，数据逻辑上是如何组织起来的。文件的物理结构是从实现观点出发看到的文件在外存上的存储组织形式。</p>
<p>按逻辑结构，文件可划分为有结构和无结构文件两种。</p>
<p><strong>无结构文件（流式文件）</strong></p>
<p>将数据按顺序组织成记录并积累、保存，它是有序相关信息项的集合，以字节为单位。无结构文件没有结构，因而对记录的访问只能通过<strong>穷举搜索</strong>的方式，这种文件形式对大多数应用不适用。对基本信息单位操作不多的文件较适于采用字符流的无结构方式，如源程序文件、目标代码文件。</p>
<p><strong>有结构文件（记录式文件）</strong></p>
<ul>
<li>
<p><strong>顺序文件</strong>：文件中的<strong>记录一个接一个地顺序排列</strong>，记录通常是定长的，可以顺序存储或以链表的形式存储，在方式时要顺序搜索文件。顺序文件有以下两种结构：</p>
<ul>
<li>串排列：记录之间的顺序与关键字无关。通常由时间决定顺序。</li>
<li>顺序结构：文件中的所有记录按关键字排序。</li>
</ul>
<p>大批量读写时，顺序文件的效率最高；但顺序文件对查找、修改、增加删除等操作较为困难。</p>
</li>
<li>
<p><strong>索引文件</strong>：按照定长和变长文件分。通过公式计算<strong>每条记录</strong>的地址。可以为变长记录文件建立一张索引表，来加快检索速度。索引表本身是定长记录的顺序文件。</p>
</li>
<li>
<p><strong>索引顺序文件</strong>：顺序和索引两种组织形式的结合。将顺序文件的<strong>所有记录分为若干组</strong>，为顺序文件建立一个索引表，在索引表中为<strong>每组的第一条记录</strong>建立一个索引项，其中含有该记录的<strong>关键字值</strong>和指向该记录的<strong>指针</strong>。<strong>组与组之间的关键字有序</strong>，但同一组中的关键字可以无序。查找一条记录时，首先通过索引表找到其所在的组，然后在该组中使用顺序查找。</p>
<p>采用这种方式能够加快查找速率。</p>
</li>
<li>
<p><strong>直接文件或散列文件（Hash File）</strong>：由给定记录的键值或散列函数转换的键值直接决定记录的物理地址。这种方式有很高的读取速度，但存在冲突。</p>
</li>
</ul>
<h3 id="目录结构"><a class="header" href="#目录结构">目录结构</a></h3>
<p>文件目录包含有关文件的信息如属性、位置和所有权等，由操作系统进行管理。目录提供<strong>文件名和文件之间的一种映射</strong>。这实际上是解决多个文件之间在逻辑上如何组织的问题，是文件的外部逻辑问题。</p>
<p><strong>文件控制块FCB和索引节点</strong></p>
<p>与进程一样，为了方便管理，操作系统引入文件控制块FCB的数据结构。</p>
<ul>
<li>文件控制块：存放控制文件所需的各种信息，以实现按名存取。<strong>FCB的有序集合</strong>称为<strong>文件目录</strong>，一个FCB就是一个文件目录项。FCB主要包括以下信息：
<ul>
<li>基本信息：文件名、物理位置、逻辑结构等</li>
<li>存取控制信息：文件存取权限等</li>
<li>使用信息：文件建立时间、修改时间等</li>
</ul>
</li>
<li>索引结点：检索目录时，只用到了文件名，其他描述信息用不到。因此有的系统采用文件名和文件描述信息分开的方法，文件描述信息单独形成一个称为索引结点的数据结构，简称i结点。</li>
</ul>
<p>存放在磁盘上的索引结点称为<strong>磁盘索引结点</strong>，UNIX中的每个文件都有一个唯一的磁盘索引结点，主要包括：</p>
<ul>
<li>文件主标识符</li>
<li>文件类型</li>
<li>文件存取权限</li>
<li>文件物理地址</li>
<li>文件长度</li>
<li>文件链接计数</li>
<li>文件存取时间</li>
</ul>
<p>文件被打开时，磁盘索引结点复制到内存的索引结点中，便于使用。内存索引结点增加了以下内容：</p>
<ul>
<li>索引结点编号</li>
<li>状态</li>
<li>访问计数</li>
<li>逻辑设备号</li>
<li>链接指针</li>
</ul>
<p><strong>目录结构</strong></p>
<p>目录这个层次上所要执行的操作：</p>
<ul>
<li>搜索</li>
<li>创建文件</li>
<li>删除文件</li>
<li>显示目录</li>
<li>修改目录</li>
</ul>
<p>考虑以下几种目录结构：</p>
<ul>
<li>
<p>单级目录结构：整个文件系统只建立一张目录表，每个文件占一个目录项。实现了按名存取，但查找速度慢、文件不允许重名、不便于文件共享，对于多用户操作不适用。</p>
</li>
<li>
<p>两级目录结构：将文件目录分为<strong>主文件目录</strong>和<strong>用户文件目录</strong>两级。能解决多用户之间的文件重名问题，文件系统可以在目录上实现访问限制。但缺乏灵活性，不能对文件分类。</p>
</li>
<li>
<p>多级目录结构（树形结构）：将两级目录结构的层次关系加以推广即可。</p>
</li>
<li>
<p>无环图目录结构：在树形目录结构的基础上增加了一些指向同一结点的有向边，使整个目录成为一个有向无环图。引入无环图目录结构是为了实现<strong>文件共享</strong>。</p>
</li>
</ul>
<h3 id="文件共享"><a class="header" href="#文件共享">文件共享</a></h3>
<p>文件共享使多个用户（进程）共享同一个文件，系统中只需要保留该文件的一个副本。</p>
<p>现代常用的两种文件共享方法：</p>
<p><strong>基于索引结点的共享方式（硬链接）</strong></p>
<p><strong>利用符号链实现文件共享（软链接）</strong></p>
<p>硬链接就是多个指针指向一个索引结点，保证只要还有一个指针指向索引结点，索引结点就不能被删除；软链接就是把到达共享文件的路径记录下来，当要访问文件时，根据路径寻找文件。</p>
<h3 id="文件保护"><a class="header" href="#文件保护">文件保护</a></h3>
<p>为了防止文件共享可能会导致文件被破坏或未经核准的用户修改文件，文件系统要控制用户对文件的存取。即解决对文件的读、写、执行的许可问题。</p>
<p>文件保护通过口令保护、加密保护和访问控制等方式实现。前两者是为了防止用户文件被他人存取或窃取，后一个是用于控制用户对文件的访问方式。</p>
<p><strong>访问类型</strong></p>
<ul>
<li>读</li>
<li>写</li>
<li>执行</li>
<li>添加</li>
<li>删除</li>
<li>列标清单</li>
</ul>
<p>保护可以只在低层提供。</p>
<p><strong>访问控制</strong></p>
<p>根据用户身份进行控制。为每个文件和目录增加一个访问控制列表ACL，规定每个用户名及其所允许的访问类型。</p>
<p>精简的访问列表：</p>
<ul>
<li>拥有者</li>
<li>组</li>
<li>其他</li>
</ul>
<h2 id="文件系统实现"><a class="header" href="#文件系统实现">文件系统实现</a></h2>
<p>文件物理结构和目录的实现。</p>
<h3 id="文件系统层次结构"><a class="header" href="#文件系统层次结构">文件系统层次结构</a></h3>
<p>现代操作系统有多种文件系统类型，文件系统的层次结构也不尽相同。</p>
<p><strong>用户调用接口</strong></p>
<p>操作系统为用户提供的与文件及目录有关的调用。此层由若干程序模块组成，每个模块对应一条系统调用。</p>
<p><strong>文件目录系统</strong></p>
<p>用来管理文件目录。</p>
<p><strong>存取控制验证模块</strong></p>
<p>实现文件保护。</p>
<p><strong>逻辑文件系统与文件信息缓冲区</strong></p>
<p>将用户要读写的逻辑记录转换成文件逻辑结构内的相应块号。</p>
<p><strong>物理文件系统</strong></p>
<p>把逻辑记录所在的相应块号转换成实际的物理地址。</p>
<p><strong>辅助分配模块</strong></p>
<p>管理辅助存储空间，及负责分配辅存空闲空间和回收辅存空间。</p>
<p><strong>设备管理程序模块</strong></p>
<p>主要功能是分配设备、分配设备读写缓存区、磁盘调度、启动设备、处理设备中断、释放设备读写缓存、释放设备。</p>
<h3 id="目录实现"><a class="header" href="#目录实现">目录实现</a></h3>
<p>目录项中提供了查找文件磁盘块所需的信息。目录的实现就是为了<strong>查找</strong>。基本实现方式有线性列表和哈希表两种。</p>
<p><strong>线性列表</strong></p>
<p>使用存储<strong>文件名</strong>和<strong>数据块指针</strong>的线性表。</p>
<p>创建文件时，必须首先搜索目录表以确定没有同名的文件存在，然后在目录表后增加一个目录项。删除文件则根据给定文件名搜索目录表，然后释放空间。</p>
<p>采用链表结构可以减小删除文件时间。</p>
<p><strong>哈希表</strong></p>
<p>根据文件名得到一个值，并返回一个指向线性列表中元素的指针。这种方法查找非常迅速，插入和删除也较简单，但需要一些预备措施来避免冲突。</p>
<p>目录查询是通过在磁盘上反复搜索完成的，需要大量I/O操作。为了减少I/O操作，把当前使用的文件目录复制到内存，降低了磁盘操作次数，提高了系统速度。</p>
<h3 id="文件实现文件分配方式"><a class="header" href="#文件实现文件分配方式">文件实现——文件分配方式</a></h3>
<p>文件的实现就是研究<strong>文件的物理结构</strong>，即文件数据在物理存储设备上如何分布和组织。文件分配方式指的是对<strong>磁盘非空闲块</strong>的管理；文件存储空间管理是对<strong>磁盘空闲块</strong>的管理。</p>
<p>文件分配是指如何为文件分配磁盘块。常用的有以下三种。一般情况下一种系统只支持一种方法。</p>
<p><strong>连续分配</strong></p>
<p>每个文件在磁盘上占有一组连续的块。磁盘地址定义了一个线性序列。这种排序使作业访问磁盘时需要的寻道数和寻道时间最少。</p>
<p>文件的连续分配可以用第一块的磁盘地址和连续块的数量来定义。</p>
<p>连续分配支持顺序访问和直接访问，优点是实现简单，存取速度快。缺点是文件长度不宜动态增加。</p>
<p><strong>链接分配</strong></p>
<p>采取离散分配方式，消除了外部碎片，显著提高了磁盘空间的利用率。文件动态增长时，可以动态地为其分配盘块，无须事先知道文件的大小，对文件的增、删、改也非常方便。链接分配分为隐式链接和显式链接。</p>
<p>（1）隐式链接</p>
<p>每个文件对应一个磁盘块的链表；磁盘块分布在任何地方，除最后一个盘块外，每个盘块都有指向下一个盘块的指针，这些指针对用户是透明的。目录包括文件的第一个指针和最后一个指针。</p>
<p>创建新文件时，目录中增加一个新条目。每个目录项都有一个指向文件首块的指针。该指针初始化为NULL表示空文件，大小字段为0。写文件通过空闲管理系统找到空闲块，将该块链接到文件的尾部，以便写入。读文件通过块到块的指针顺序读块。</p>
<p>隐式链接的缺点是无法直接访问盘块，且盘块指针会消耗一定的存储空间。指针还有可能丢失或损坏，导致文件数据丢失。</p>
<p>（2）显式链接</p>
<p>把用于连接文件各物理块的指针，从每个物理块的块末尾提取出来，显示地存放在内存的一张链表中。该表在整个磁盘中仅设置一张，称为<strong>文件分配表FAT</strong>。每个表项中存放对应块的下一块连接指针，即下一个盘块号。文件的第一个盘块号记录在目录中，后续盘块号通过FAT表查找。</p>
<p>FAT的表项与全部磁盘块一一对应，用特殊数字-1表示文件的最后一块，用-2表示这个磁盘块是空闲的。</p>
<p>FAT表在系统启动时就会被读入内存，因此查找的过程是在内存中进行的，既能提高检索速度，还能减少磁盘访问次数。</p>
<p><strong>索引分配</strong></p>
<p>索引分配支持直接访问。它把每个文件的所有盘块号都集中放在一起构成索引块（表）。</p>
<p>每个文件都有其索引块，这是一个磁盘块地址的数据。索引块的第i个条目指向文件的第i个块。文件的目录条目包括索引块的地址。</p>
<p>创建文件时，索引块的所有指针都设为空，首次写入第i块时，先从空闲块中取得一个块，再将其地址写入索引块的第i个条目。索引分配支持直接访问，且没有外部碎片问题。缺点是索引块增加了系统存储空间的开销。可以采用以下机制控制索引块的大小：</p>
<ul>
<li>链接方案</li>
<li>多层索引</li>
<li>混合索引</li>
</ul>
<h3 id="文件实现文件存储空间管理"><a class="header" href="#文件实现文件存储空间管理">文件实现——文件存储空间管理</a></h3>
<p><strong>文件存储器的划分与初始化</strong></p>
<p>一个文件存储在一个文件卷中。文件卷可以是物理盘的一部分也可以是整个物理盘。</p>
<p>一个文件卷中，文件数据信息空间（文件区）和文件控制信息空间（目录区）是分离的。由于存在多种文件表示和存放格式，现代操作系统中一般有很多不同的文件管理模块。逻辑卷在提供文件服务前，必须由对应的文件程序进行初始化，划分好目录区和文件区，建立空闲空间管理表格和存放逻辑卷信息的超级块。</p>
<p><strong>文件存储器空间管理</strong></p>
<p>文件存储设备分成许多大小相同的物理块，以块为单位交换信息，因此文件存储设备实际上是对空闲块的组织和管理，包括空闲块的组织、分配与回收。</p>
<ul>
<li>空闲表法</li>
</ul>
<p>属于连续分配方式，与内存的动态分配类似。为每个文件分配一块连续的存储空间。</p>
<p>系统为外存上所有空闲区建立一张空闲盘块表，每个空闲区对应于一个空闲表项其中包含表项序号、该空闲区第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列。</p>
<p>空闲盘区的分配与内存的动态分配类似，同样采用首次适应算法、循环首次适应算法等。</p>
<p>系统对用户释放的存储空间进行回收时，也采取类似于内存回收的方法。</p>
<ul>
<li>
<p>空闲链表法：将所有空闲盘区拉成一条空闲链，根据构成链所用的基本元素不同，可以分为：</p>
<ul>
<li>空闲盘块链：所有空闲空间以盘块为单位拉成一条链。用户请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给用户。用户释放存储空间是，系统将回收的盘块依次插入空闲盘块链的末尾。</li>
<li>空闲盘区链：将所有空闲盘区（每个盘区可包含若干盘块）拉成一条链。每个盘区上除了含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小的信息。分配盘区方法与内存动态分配类似。采用首次适应法。</li>
</ul>
</li>
<li>
<p>位示图法：用二进制的一位表示磁盘中一块的使用情况，磁盘上的所有盘块都有一个二进制位与之对应。当值为0时表示对应盘块空闲；当值为1时表示对应盘块已分配。盘块的分配方法为：</p>
<ul>
<li>
<p>顺序扫描位示图，从中找出一个或一组值为0的二进制位。</p>
</li>
<li>
<p>将找到的一个或一组二进制位转换为与之对应的盘块号。若找到的值为0的二进制位位于位示图的第i行、第j列，则其相应的盘块号应按下列公式计算：
$$
b=n(i-1)+j
$$</p>
</li>
<li>
<p>修改位示图，令$\text{map}[i,j]=1$</p>
</li>
</ul>
</li>
</ul>
<p>盘块的回收同理，将盘块号转换为位示图的行和列，然后修改位示图。</p>
<ul>
<li>成组链接法</li>
</ul>
<p>UNIX系统采用了这种方法，结合了空闲表和空闲链表两种方法，克服了表太大的缺点。思想为：把顺序的n个空闲扇区地址保存在第一个空闲扇区（这n个中的第一个）内，其最后一个空闲扇区（这n个中的最后一个）内则保存另一组顺序空闲扇区的地址。系统只需要保存一个指向第一个空闲扇区的指针。这种方式可以迅速找到大批空闲块地址。</p>
<h2 id="磁盘组织与管理"><a class="header" href="#磁盘组织与管理">磁盘组织与管理</a></h2>
<h3 id="磁盘的结构"><a class="header" href="#磁盘的结构">磁盘的结构</a></h3>
<p>磁头、磁道、扇区（每个512B，又称为盘块）。</p>
<p>磁盘安装在一个磁盘驱动器中，由磁头臂、主轴和其他电子设备组成。多个盘片垂直堆叠，组成磁盘组，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动。所有盘片上相对位置相同的磁道组成<strong>柱面</strong>。</p>
<p>按照这种物理结构组织，扇区就是磁盘可寻址的最小存储单位，磁盘地址用<strong>柱面号·盘面号·扇区号</strong>表示。</p>
<p>磁盘可分为：固定磁头磁盘、活动头磁盘、固定盘磁盘、可换盘磁盘。</p>
<h3 id="磁盘调度算法"><a class="header" href="#磁盘调度算法">磁盘调度算法</a></h3>
<p>一次磁盘读写操作的时间由寻道时间、旋转延迟时间和传输时间决定。</p>
<ul>
<li>寻找时间：读写信息前将磁头移动到指定磁道所需的时间。</li>
<li>旋转延迟时间：磁头定位到某一磁道的扇区所需的时间。</li>
<li>传输时间：从磁盘读出或向磁盘写入数据所经历的时间。</li>
</ul>
<p>在实际的磁盘I/O中，存取时间与磁盘调度算法密切相关。调度算法直接决定寻找时间，从而决定总的存取时间。</p>
<p>常用的磁盘调度算法：</p>
<p><strong>先来先服务算法FCFS</strong></p>
<p>根据进程请求访问磁盘的先后顺序进行调度。该算法具有公平性。但若有大量进程竞争使用磁盘，这种算法在性能上接近于随即调度。</p>
<p><strong>最短寻找时间优先算法SSTF</strong></p>
<p>该算法选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道，以便每次寻找时间最短。这种算法可能会产生饥饿现象，即距离较远的磁盘的访问可能被无限延期。</p>
<p><strong>扫描算法SCAN</strong></p>
<p>该算法在磁头<strong>当前移动方向上</strong>选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象。实际上就是规定了磁头运动方向的最短寻找时间优先算法。这个算法对最近扫描过的区域不公平，在访问局部性方面不如上两个算法。</p>
<p><strong>循环扫描算法C-SCAN</strong></p>
<p>在扫描算法的基础上规定磁头单向移动来提供服务，回返时直接快速移动至起始段而不服务任何请求。</p>
<p>另外减少延迟时间也能提高磁盘传输效率。可以对盘面扇区进行交替编号，对磁盘片组中的不同盘面错位命名。</p>
<h3 id="磁盘的管理"><a class="header" href="#磁盘的管理">磁盘的管理</a></h3>
<p><strong>磁盘初始化</strong></p>
<p>磁盘进行存储数据之前，必须分成扇区以便磁盘控制器能进行读和写操作，这个过程称为低级格式化（物理分区）。低级格式化为磁盘的每个扇区采用了特别的数据结构。每个扇区的数据由头、数据区域（512B）和尾部组成。头部和尾部包含了一些磁盘控制器所使用的信息。</p>
<p>为了使用磁盘存储文件，操作系统还需要要将自己的数据结构记录在磁盘上：第一步将磁盘分为由一个或多个柱面组成的分区；第二部对物理分区进行逻辑格式化（创建文件系统），操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括空闲和已分配的空间及一个初始为空的目录。</p>
<p><strong>引导块</strong></p>
<p>计算机启动时需要运行一个初始化程序（自举程序），它初始化各种硬件和操作系统。该操作系统找到磁盘上的操作系统内核，装入内存并转到起始地址，而从开始运行。</p>
<p><strong>坏块</strong></p>
<p>磁盘可能有一个或多个扇区损坏。</p>
<p>对于简单磁盘，坏扇区可以手工处理。系统可以在执行逻辑格式化的时候扫描磁盘以检查坏扇区。坏扇区会在FAT表上表明，程序不会使用。</p>
<p>对于复杂磁盘，其控制器维护一个磁盘坏块链表。该链表在出厂前进行低级格式化时就已经初始化，并在磁盘整个使用过程中不断更新。控制器可以用备用块来逻辑替代坏块，称为扇区备用。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="io管理概述"><a class="header" href="#io管理概述">I/O管理概述</a></h2>
<h3 id="io设备"><a class="header" href="#io设备">I/O设备</a></h3>
<p>I/O设备按照使用特性可以分为以下类型：</p>
<ul>
<li>人机交互类外部设备</li>
<li>存储设备</li>
<li>网络通信设备</li>
</ul>
<p>按照传输速率可分为：低速、中速、高速设备</p>
<p>按信息交换类型的单位分为：块设备、字符设备</p>
<h3 id="io控制方式-1"><a class="header" href="#io控制方式-1">I/O控制方式</a></h3>
<p>程序直接控制方式、中断驱动方式、DMA方式、通道控制方式。</p>
<p>该部分内容详见组成原理部分。</p>
<h3 id="io子系统的层次结构"><a class="header" href="#io子系统的层次结构">I/O子系统的层次结构</a></h3>
<p>整个I/O系统可以视为具有4个层次的系统结构，各层次及其功能如下：</p>
<p><strong>用户层I/O软件</strong></p>
<p>实现与用户交互的接口，用户可以直接调用在用户层提供的、与I/O操作有关的函数，对设备进行操作。</p>
<p><strong>设备独立性软件</strong></p>
<p>用于实现用户程序与设备驱动器的统一接口、设备命令、设备保护以及设备的分配与释放。</p>
<p>设备独立性也称设备无关性，使得应用程序独立于具体使用的物理设备。为实现独立性而引入<strong>逻辑设备</strong>和<strong>物理设备</strong>这两个概念。</p>
<p>应用程序中，使用逻辑设备名来请求使用某类设备；系统实际执行时，必须将逻辑设备名映射成物理设备名使用。</p>
<p>设备独立心性软件的主要功能可以分为：</p>
<ul>
<li>执行所有设备的公有操作。</li>
<li>向用户层（或文件曾）提供统一接口。</li>
</ul>
<p><strong>设备驱动程序</strong></p>
<p><strong>中断处理程序</strong></p>
<p>用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断进程。</p>
<p><strong>硬件设备</strong></p>
<p>包括一个机械部件（设备本身）和一个电子部件（又称适配器，即一块插入主板的印刷电路板）</p>
<h2 id="io核心子系统"><a class="header" href="#io核心子系统">I/O核心子系统</a></h2>
<h3 id="概述"><a class="header" href="#概述">概述</a></h3>
<p>I/O设备种类繁多，功能、速度差异大，需要多种方法来进行设备控制。这些方法共同组成了操作系统内核的I/O子系统，它将内核的其他方面从繁重的I/O设备管理中解放出来。该子系统主要有I/O调度、缓冲与高速缓存</p>
<h3 id="io调度概念"><a class="header" href="#io调度概念">I/O调度概念</a></h3>
<p>确定一个好的顺序来执行这些I/O请求。应用程序发布的系统调用顺序不一定是最佳选择，需要I/O调度来改善系统整体性能，使进程之间公平地共享设备访问，减少I/O完成所需要的平均等待时间。</p>
<p>操作系统为每个设备维护一个请求队列来实现调度。当一个应用程序执行阻塞I/O系统时，该请求就加到相应设备的队列上。I/O调度会重新安排队列顺序以改善系统总体效率和应用程序的平均响应时间。</p>
<h3 id="高速缓存与缓冲区"><a class="header" href="#高速缓存与缓冲区">高速缓存与缓冲区</a></h3>
<p><strong>磁盘高速缓存</strong></p>
<p>利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。<strong>逻辑上</strong>属于<strong>磁盘</strong>，<strong>物理上</strong>则驻留在<strong>内存</strong>中的盘块。</p>
<p>高速缓存在内存中分为两种形式：一种是在内存中单独开辟一个存储空间作为磁盘高速缓存，大小固定；另一种是把未利用的内存空间作为一个缓冲池，供请求分页系统和磁盘I/O时共享。</p>
<p><strong>缓冲区Buffer</strong></p>
<p>设备管理子系统引入缓冲区的主要目的是：</p>
<ul>
<li>缓和CPU与I/O设备间速度不匹配的矛盾</li>
<li>减少对CPU的中断频率，放宽对CPU中断先攻时间的限制</li>
<li>解决基本数据单元大小（数据粒度）不匹配的问题</li>
<li>提高CPU和I/O设备之间的并行性</li>
</ul>
<p>实现方法为：</p>
<ul>
<li>采用硬件缓冲器，成本较高</li>
<li>采用缓冲区（位于内存区域）</li>
</ul>
<p>根据系统设置缓冲器的个数，缓冲技术可以分为：</p>
<ul>
<li>单缓冲</li>
<li>双缓冲：提高了处理机和输入设备的并行操作的程度</li>
<li>循环缓冲</li>
<li>缓冲池</li>
</ul>
<h3 id="设备分配与回收"><a class="header" href="#设备分配与回收">设备分配与回收</a></h3>
<p><strong>设备分配概述</strong></p>
<p>根据用户的I/O请求分配所需的设备，分配的总原则是充分发挥设备的使用效率。</p>
<ul>
<li>独占式使用设备</li>
<li>分时式共享使用设备</li>
<li>以SPOOLing方式使用外部设备</li>
</ul>
<p><strong>设备分配的数据结构</strong></p>
<p><strong>设备分配的策略</strong></p>
<p><strong>设别分配的安全性</strong></p>
<h3 id="假脱机技术"><a class="header" href="#假脱机技术">假脱机技术</a></h3>
<p>为了缓和CPU的高速性与I/O设备低速性之间的矛盾，引入了脱机输入/输出技术。该技术利用专门的外围控制机，将低速I/O设备上的数据传送到高速磁盘上，或者相反。</p>
<p><strong>输入井和输出井</strong></p>
<p>是指在磁盘上开辟出的两个存储区域。二者用于模拟脱机输入/输出时的磁盘。</p>
<p><strong>输入缓冲区和输出缓冲区</strong></p>
<p>是在内存中开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入经。输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备。</p>
<p><strong>输入进程和输出进程</strong></p>
<div style="break-before: page; page-break-before: always;"></div><p>物理层：概念较多，易出选择题，还涉及一些通信原理。</p>
<p>数据链路层：考察重点，流量控制和可靠传输、介质访问控制(MAC)协议、广域网协议、以太网帧格式</p>
<p>网路层：重中之重，与其他章节结合出综合题。IPv4、路由算法</p>
<p>传输层：UDP、TCP，TCP报文分析、流量控制与拥塞控制机制出综合题。</p>
<p>应用层：掌握几个典型的应用层协议，与其他章节结合考综合题。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="计算机网络概述"><a class="header" href="#计算机网络概述">计算机网络概述</a></h2>
<h3 id="概念-1"><a class="header" href="#概念-1">概念</a></h3>
<p>将分散的、具有独立功能的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。</p>
<p>广义观点：</p>
<p>资源共享观点：以能够相互共享资源的方式互联起来的自治计算机系统的集合。</p>
<p>用户透明性观点：存在一个能为用户自动管理资源的网络操作系统。</p>
<h3 id="组成"><a class="header" href="#组成">组成</a></h3>
<p>组成部分上看：硬件、软件、协议</p>
<p>工作方式上看：边缘部分、核心部分</p>
<p>功能组成上看：通信子网、资源子网</p>
<h3 id="功能-3"><a class="header" href="#功能-3">功能</a></h3>
<p>数据通信</p>
<p>资源共享：可以是软件共享、数据共享，也可以是硬件共享</p>
<p>分布式处理：提高整个系统的利用率</p>
<p>提高可靠性：网络中各台计算机可以通过网络互为替代机</p>
<p>负载均衡：将工作任务均衡地分配给网络中的各台计算机</p>
<h3 id="分类-2"><a class="header" href="#分类-2">分类</a></h3>
<p>按分布范围：广域网、城域网、局域网、个人局域网</p>
<p>按传输技术：广播式网络、点对点网络(每条物理链路连接一对计算机)</p>
<p>按拓扑结构：总线型、星型、环形、网状</p>
<p>按使用者：公用网、专用网</p>
<p>按交换技术：电路交换网络(源结点和目的结点之间建立、报文交换网络、分组交换网络</p>
<p>按传输介质：有线、无线</p>
<h3 id="网络的性能指标"><a class="header" href="#网络的性能指标">网络的性能指标</a></h3>
<p><strong>带宽</strong></p>
<p>通信线路允许通过的信号频带范围</p>
<p><strong>时延</strong></p>
<p>数据从网络的一端传输到另一端所需要的总时间：</p>
<ul>
<li>发送时延：结点将分组的所有比特推向传输链路所需的时间，发送时延=分组长度/信道宽度</li>
<li>传播时延：电磁波在信道中传播一定的距离需要花费的时间，即一个比特从链路一端传播到另一端所需的时间，传播时延=信道长度/电磁波在信道上的传播速率</li>
<li>处理时延：数据在交换结点为存储转发而进行的一些处理所花费的时间</li>
<li>排队时延：分组在进入路由器后要先在输入队列中排队等待处理</li>
</ul>
<p>做题中<strong>处理时延和排队时延</strong>一般可以忽略不计。</p>
<p><strong>往返时延</strong></p>
<p>RTT，从发送端发送数据开始到发送端收到来自接收端的确认，总共经历的时延。</p>
<p><strong>吞吐量</strong></p>
<p>单位时间内通过耨个网络（或信道、接口）的数据量。</p>
<p><strong>速率</strong></p>
<p>主机在数字信道上传送数据的速率。</p>
<p><strong>信道利用率</strong></p>
<p>某一信道有百分之多少的时间是有数据通过的。</p>
<h2 id="体系结构与参考模型"><a class="header" href="#体系结构与参考模型">体系结构与参考模型</a></h2>
<h3 id="计算机网络分层结构"><a class="header" href="#计算机网络分层结构">计算机网络分层结构</a></h3>
<h3 id="协议接口服务的概念"><a class="header" href="#协议接口服务的概念">协议、接口、服务的概念</a></h3>
<p><strong>协议</strong></p>
<p>是控制两个或多个<strong>对等实体</strong>进行通信的规则的集合，不对等实体之间是没有协议的。</p>
<p>协议由语法、语义和同步三部分组成。</p>
<p>一个完整的协议通常应该有线路管理、差错控制、数据转换等功能。</p>
<p><strong>接口</strong></p>
<p>同一结点内相邻两层间交换信息的连接点，是一个系统内部的规定。</p>
<p><strong>服务</strong></p>
<p>服务是<strong>下层为紧邻的上层</strong>提供的功能调用，是垂直的。对等实体在协议的控制下，使得本层能为上一层提供服务，但要实现本层协议还需要下一层所提供的服务。</p>
<p>上层使用下层所提供的服务时必须<strong>与下层交换一些命令</strong>，这些命令被称为<strong>服务原语</strong>，OSI参考模型将原语划分为4类：</p>
<ul>
<li>请求</li>
<li>指示</li>
<li>响应</li>
<li>证实</li>
</ul>
<p>计算机网络提供的服务可以按照以下三种方式分类：</p>
<ul>
<li>面向连接服务与无连接服务</li>
<li>可靠服务和不可靠服务</li>
<li>有应答服务和无应答服务</li>
</ul>
<h3 id="osi参考模型和tcpip模型"><a class="header" href="#osi参考模型和tcpip模型">OSI参考模型和TCP/IP模型</a></h3>
<p><strong>OSI参考模型</strong></p>
<p>由国际标准化组织ISO提出的网络体系结构模型，称为开放系统互联参考模型。</p>
<p>OSI模型有7层，自下而上依次为：物理层、数据链路层（帧）、网络层（分组）、传输层、<strong>会话层、表示层</strong>、应用层。低三层称为<strong>通信子网</strong>，是为了联网而附加的通信设备，完成数据的传输功能；高三层统称<strong>资源子网</strong>，相当于计算机系统完成数据处理等功能。</p>
<ul>
<li>
<p>会话层：允许不同主机上的各个进程之间进行会话，会话层利用传输层提供的端到端的服务，向表示层提供它的增值服务；这种服务主要为表示层实体或用户建立连接并有序传输数据，这就是会话，也称<strong>建立同步(SYN)</strong></p>
</li>
<li>
<p>表示层：主要处理两个通信系统中交换信息的表示方式。不同机器采用的编码和表示方式不同，使用的数据结构也不同。表示层采用抽象的标准方法定义数据结构，并采用标准的编码方式。数据压缩、加密和解密也是表示层可提供的数据表示变换功能。</p>
</li>
</ul>
<p><strong>TCP/IP模型</strong></p>
<p>从低到高为网络接口层、网际层、传输层和应用层。</p>
<p><strong>OSI参考模型</strong>在<strong>网络层支持无连接和面向连接</strong>的通信，但在<strong>运输层仅有面向连接</strong>的通信；而<strong>TCP/IP模型</strong>认为可靠性是端到端的问题，因此其在<strong>网际层仅有一种无连接</strong>的通信模型，但在<strong>传输层支持无连接和面向连接</strong>两种模式。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="通信基础"><a class="header" href="#通信基础">通信基础</a></h2>
<h3 id="基本概念-12"><a class="header" href="#基本概念-12">基本概念</a></h3>
<p><strong>数据、信号与码元</strong></p>
<p>码元是指用一个固定时长的信号波形（数字脉冲）表示<strong>一位k进制数字</strong>，代表<strong>不同离散数值的基本波形</strong>。是数字通信中数字信号的计量单位，这个时长内的信号称为k进制码元，该时常称为码元宽度。</p>
<p>例如使用二进制编码时只有两种不同码元：一种代表0状态，另一种代表1状态</p>
<p><strong>信源、信道与信宿</strong></p>
<p>信道与电路不等同，一个信道可视为一条线路的逻辑部件，一般用来表示向某个方向传送信息的介质。因此一条线路往往包括一条发送信道和一条接收信道。</p>
<p>信道的划分：</p>
<ul>
<li>按传输信号形式分：
<ul>
<li>模拟信道</li>
<li>数字信道</li>
</ul>
</li>
<li>按传输介质分：
<ul>
<li>无线信道</li>
<li>有线信道</li>
</ul>
</li>
<li>信道上的传送信号有基带信号和宽带信号之分</li>
<li>按通信双方信息的交换方式分：
<ul>
<li>单向通信</li>
<li>半双工通信</li>
<li>全双工通信</li>
</ul>
</li>
</ul>
<p><strong>速率、波特与带宽</strong></p>
<h3 id="奈奎斯特定理与香农定理"><a class="header" href="#奈奎斯特定理与香农定理">奈奎斯特定理与香农定理</a></h3>
<p><strong>奈奎斯特定理</strong></p>
<p>具体信道所能通过的频率范围是有限的。信号中许多高频分量不能通过信道，否则在传输中会衰减，导致接收端收到的信号波形失去码元之间的清晰界限，这种现象称为<strong>码间串扰</strong>。</p>
<p>理想信道下的极限传输速率：
$$
2W\log_2 V
$$
<strong>香农定理</strong></p>
<h3 id="编码与调制"><a class="header" href="#编码与调制">编码与调制</a></h3>
<p>数据无论是数字的还是模拟的，为了传输都必须转变成信号。把数据变换为模拟信号的过程称为调制，把数据变换为数字信号的过程称为编码。</p>
<p><strong>数字数据编码为数字信号</strong></p>
<ul>
<li>归零编码（RZ）：高电平代表1，低电平代表0；每个时钟周期的中间均跳变到低电平，接收方根据该跳变调整本方的时钟基准，为传输双方提供了子同步机制；归零要占用一定带宽，因此传输速率会受到一定影响。</li>
<li>非归零编码（NRZ）：与RZ的区别是不用归零，一个周期可以全部用来传输数据，但NRZ编码无法传递时钟，双方难以同步，若想传输高速同步数据需要带有时钟线。</li>
<li>反向非归零编码（NRZI）：用信号的反转代表0，信号保持不变代表1。翻转的信号本身可以作为一种通知机制。这种编码既能传输时钟信号又能不损失系统带宽。USB2.0采用这种编码。</li>
<li>曼彻斯特编码：将一个码元分为两个相等间隔，前一个间隔为高电平后一个间隔为低电平代表码元1；码元0的表示相反。在每个码元的中间出现电平跳变，位中间的跳变既作为时钟信号又作为数据信号；他所占的频带宽度是原始基带宽度的两倍。以太网使用这种编码。</li>
<li>差分曼彻斯特编码：常用于局域网传输。若码元为1，则前半个码元的电平与上一个码元的后半部分相同；若码元为0，则情形相反。每个码元的中间都有一次电平跳变，可以实现自同步，且抗干扰好。</li>
<li>4B/5B编码</li>
</ul>
<p><strong>数字数据调制为模拟信号</strong></p>
<ul>
<li>幅移键控（ASK）：通过改变载波信号的<strong>幅值</strong>来表示数字0和1.</li>
<li>频移键控（FSK）：通过改变载波信号的<strong>频率</strong>来表示数字0和1.</li>
<li>相移键控（PSK）：改变载波信号的<strong>相位</strong>来表示数字0和1.</li>
<li>正交振幅调制（QAM）：频率相同的前提下，将ASK和PSK结合</li>
</ul>
<p><strong>模拟数据编码为数字信号</strong></p>
<p>包括三个步骤：采样、量化和编码。</p>
<p><strong>模拟信号调制为模拟信号</strong></p>
<p>为了实现传输的有效性，可能需要较高的频率。还可以使用频分复用技术，充分利用带宽。</p>
<h3 id="电路交换报文交换和分组交换"><a class="header" href="#电路交换报文交换和分组交换">电路交换、报文交换和分组交换</a></h3>
<p><strong>电路交换</strong></p>
<p>传输前两结点之间先建立一条专用（双方独占）的物理通信路径，这一路径在整数数据传输期间一直被占用，直到通信结束。</p>
<ul>
<li>
<p>技术优点：通信延时小；有序传输；没有冲突；适用范围广；实时性强；控制简单。</p>
</li>
<li>
<p>缺点：建立时间长；线路独占；灵活性差；难以规格化。</p>
</li>
</ul>
<p><strong>报文交换</strong></p>
<p>交换的单位是报文，报文携带有目标地址、源地址等信息。报文交换在交换结点采用的是<strong>存储转发</strong>的传输方式。</p>
<ul>
<li>优点：无需建立连接；动态分配线路；提高可靠性；提高线路利用率；提供多目标服务。</li>
<li>缺点：会引起转发时延；对报文的大小没有限制，要求网络结点有较大的缓存空间。</li>
</ul>
<p>报文交换在早期的电报通信网中使用，现在较少使用。</p>
<p><strong>分组交换</strong></p>
<p>解决了报文交换中大报文传输的问题。分组交换限制了每次传送的数据块大小的上限，把大数据块划分为合理的小数据块，再加上一些必要的控制信息，构成分组。网络结点根据控制信息把分组送到下一个结点。</p>
<ul>
<li>
<p>优点：无建立时延；线路利用率高；简化了存储管理；加速传输；减少了出错概率和重发数据量。</p>
</li>
<li>
<p>缺点：存在传输时延；需要传输额外信息量；当分组交换采用数据报服务时，可能会出现时序、丢失或重复分组。</p>
</li>
</ul>
<h3 id="数据报与虚电路"><a class="header" href="#数据报与虚电路">数据报与虚电路</a></h3>
<p><strong>数据报</strong></p>
<p>网络层数据报分组。</p>
<p>特点：</p>
<ul>
<li>发送分组前不需要建立连接</li>
<li>网络尽最大努力交付，不保证可靠性；为每个分组进行独立的路由选择，转发的路径可能不同，分组不一定按序到达目的结点。</li>
<li>发送的分组要包含完整的发送端和接收端地址，以便进行独立传输。</li>
<li>分组在交换结点存储转发时，需要排队等候处理。</li>
<li>网络具有冗余路径。</li>
<li>存储转发的延时一般较小，提高了网络吞吐量。</li>
<li>收发双方不独占某条链路</li>
</ul>
<p><strong>虚电路</strong></p>
<p>试图将数据报与电路交换结合起来。</p>
<h2 id="传输介质"><a class="header" href="#传输介质">传输介质</a></h2>
<h3 id="双绞线同轴电缆光纤无线传输介质"><a class="header" href="#双绞线同轴电缆光纤无线传输介质">双绞线、同轴电缆、光纤、无线传输介质</a></h3>
<p><strong>双绞线</strong></p>
<p>分为屏蔽和非屏蔽，最常用传输介质。</p>
<p>带宽取决于痛心啊粗细和双数距离。</p>
<p><strong>同轴电缆</strong></p>
<p>由内导体、绝缘层、网状编制屏蔽层、塑料外层构成。</p>
<p>分为50欧姆和75欧姆两类；50欧姆用于传送基带数字信号，又称基带同轴电缆；75欧姆用于传送宽带信号，又称宽带同轴电缆。</p>
<p><strong>光纤</strong></p>
<p>有光脉冲表示1，无光脉冲表示0.</p>
<p>单模光纤：直径只有光的一个波长大小，沿直线传播。</p>
<p>多模光纤：光的全反射特性。</p>
<p>光纤优点：</p>
<ul>
<li>通信容量大</li>
<li>传输损耗小</li>
<li>抗雷电和电磁特性好</li>
<li>无串音干扰</li>
<li>体积小，重量轻</li>
</ul>
<p><strong>无线传输介质</strong></p>
<ul>
<li>无线电波</li>
<li>微波、红外线和激光
<ul>
<li>微波通信频率高，频段范围宽，载波频率通常为2-40GHz</li>
</ul>
</li>
</ul>
<h3 id="物理接口的特性"><a class="header" href="#物理接口的特性">物理接口的特性</a></h3>
<ul>
<li>机械特性：接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置</li>
<li>电气特性：接口电缆各条线上出现的电压的范围</li>
<li>功能特性：某条线上某一电平的电压的意义</li>
<li>过程特性：对于不同功能的各种可能事件出现的顺序</li>
</ul>
<h2 id="物理层设备"><a class="header" href="#物理层设备">物理层设备</a></h2>
<h3 id="中继器"><a class="header" href="#中继器">中继器</a></h3>
<p>将数字信号整型并再转发出去。用来扩大网络规模。在10BASE5以太网规范中，互相串联的中继器个数不能超过4个，4个中继器只有三段可以接挂计算机。</p>
<h3 id="集线器"><a class="header" href="#集线器">集线器</a></h3>
<p>集线器(Hub)实质上是一个多端口的中继器，在网络中只起信号放大和转发的功能，目的是扩大网络的传输范围，不具备信号的定向传送能力，即信号的传输方向是固定的。。</p>
<h2 id="其他问题"><a class="header" href="#其他问题">其他问题</a></h2>
<p>基带传输、频带传输和宽带传输的区别：</p>
<ul>
<li>基带传输：在计算机内部或相邻设备之间近距离不经调制直接传输的方式。</li>
<li>频带传输：用数字信号对特定频率的载波进行调制，将其变成适合于传送的信号后再进行传输。常用于远距离或无线传输。</li>
<li>宽带传输：借助频带传输，可以将链路容量分解为两个或多个信道，每个信道可以携带不同的信号。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="数据链路层功能"><a class="header" href="#数据链路层功能">数据链路层功能</a></h2>
<h3 id="为网络层提供服务"><a class="header" href="#为网络层提供服务">为网络层提供服务</a></h3>
<ul>
<li><strong>无确认的无连接</strong>服务：源机器发送数据帧时不需要建立链路连接，目的机器收到数据帧时无需发回确认。数据链路层不重发丢失的帧，交给上层进行处理。</li>
<li><strong>有确认的无连接</strong>服务：源机器发送数据帧时不需要建立链路连接，目的机器接收到数据帧时必须发回确认；源机器在规定时间内未收到确认信号时，就重传丢失的帧，以提高传输的可靠性。</li>
<li><strong>有确认的面向连接</strong>服务：帧传输过程分为三个阶段：建立数据链路、传输帧、释放数据链路。目的机器对收到的每一帧都要给出确认，源机器收到确认后才能发送下一帧。</li>
</ul>
<h3 id="链路管理"><a class="header" href="#链路管理">链路管理</a></h3>
<p>链路层连接的建立、维持和释放。主要用于面向连接的服务。</p>
<h3 id="帧定界帧同步和透明传输"><a class="header" href="#帧定界帧同步和透明传输">帧定界、帧同步和透明传输</a></h3>
<p>两台机器之间传输信息时将网络层的分组封装成帧，以帧的格式进行传送。将一段数据前后分别添加首部和尾部的控制信息后，就构成了帧。这些控制信息的一个重要作用就是确定帧的界限。帧同步指的是接收方能够从接收到的二进制信息比特流中区分出帧的起始与终止。</p>
<p>为了提高传输速率，应当使帧的数据部分的长度尽可能大于首部和尾部的长度，每种数据链路层协议都规定了帧的数据部分的长度上限——最大传送单元（MTU）</p>
<h3 id="流量控制"><a class="header" href="#流量控制">流量控制</a></h3>
<p>用来解决收发双方各自的工作速率和缓存空间的差异。</p>
<p>流量控制在许多高层协议中也存在，只不过控制的对象不同。</p>
<h3 id="差错控制"><a class="header" href="#差错控制">差错控制</a></h3>
<p>由于噪声等原因，帧在传输过程中可能出现错误，差错控制能够让发送方确认接收方是否正确收到了由其发送的数据。这些错误可分为位错和帧错。</p>
<p>位错指某些位发生了错误，通常采用循环冗余校验（CRC）来发现错误，通过自动重传请求（ARQ）来重传错误。</p>
<h2 id="组帧"><a class="header" href="#组帧">组帧</a></h2>
<p>发送方根据一定的规则把网络层递交的分组封装成帧（称为组帧）。组帧主要为了解决帧定界、帧同步、透明传输等问题。</p>
<h3 id="字符计数法"><a class="header" href="#字符计数法">字符计数法</a></h3>
<p>在<strong>帧的头部</strong>使用一个计数字段来标明<strong>帧内字符数</strong>（包括计数字段）。目的结点通过数据链路层收到的字节计数值时，就知道后面跟的字节数，从而可以确定帧结束的位置。</p>
<p>这种方法的问题在于如果计数字段出错，就失去了帧边界划分的依据，接收方就无法判断所传输帧的结束位和下一帧的开始位，收发双方失去同步，造成灾难性后果。</p>
<h3 id="字符填充的首尾定界符法"><a class="header" href="#字符填充的首尾定界符法">字符填充的首尾定界符法</a></h3>
<p>使用特定字符来定界一帧的开始与结束。<strong>控制字符SOH</strong>放在帧的最前面，表示帧的首部开始，<strong>控制字符EOT</strong>表示帧的结束。为了使得信息位中出现的特殊字符不被误判为帧的首尾定界符，可在特殊字符前填充一个**转义字符(ESC)**来加以区分，以实现数据的透明传输。如果ECS也出现在数据中，那么仍在转义字符前插入一个转义字符。</p>
<h3 id="零比特填充的首尾标志法"><a class="header" href="#零比特填充的首尾标志法">零比特填充的首尾标志法</a></h3>
<p>这种方法允许数据帧包含任意个数的比特，也允许每个字符的编码包含任意个数的比特。它使用一个特定的比特模式，即01111110来标志一帧的开始和结束。为了不是信息位中出现的比特流01111110被误判为帧的首尾标志，发送方的数据链路层在信息位遇到<strong>5个连续的1时</strong>，自动在其后插入一个0；接收方则<strong>每收到5个1，自动删除后面紧跟的0</strong>，以此恢复信息。</p>
<p>这种方法很容易用硬件实现。</p>
<h3 id="违规编码法"><a class="header" href="#违规编码法">违规编码法</a></h3>
<p>物理层编码通常采用违规编码法。例如曼彻斯特编码方法将数据比特1编码成<strong>高-低</strong>电平对，将数据比特0编码成<strong>低-高</strong>电平对，而<strong>高-高</strong>和<strong>低-低</strong>电平对在数据比特中是违规的，利用这些违规的编码序列来定界帧的起始和终止。</p>
<p>由于字节计数法中计数字段的脆弱性和字符填充法实现上的复杂性和不兼容性，目前常采用的组帧方法为<strong>比特填充法和违规编码法</strong>。</p>
<p>局域网802.11就是用了这种编码。</p>
<h2 id="差错控制-1"><a class="header" href="#差错控制-1">差错控制</a></h2>
<p>这里只讨论比特差错。</p>
<p>利用编码技术进行差错控制，主要有<strong>自动重传请求ARQ</strong>和<strong>前向纠错FEC</strong>两类。ARQ中接收端检测出差错时就设法通知发送方进行重传；FEC接收端不但能发现错误，还能确定比特串的错误位置，从而加以纠正。</p>
<h3 id="检错编码"><a class="header" href="#检错编码">检错编码</a></h3>
<p>检错编码都采用冗余编码技术，核心思想为在有效数据被发送前，按照某种关系附加一定的冗余位，构成符合某一规则的码字后再发送。当要发送的有效数据发生变化时，相应的冗余位也随之变化，接收端根据收到的码字是否符合原来的规则判断是否出错。</p>
<p><strong>奇偶校验码</strong></p>
<p>由n-1位信息位和1位校验元组成。</p>
<ul>
<li>奇校验：附加一个校验元后，码长为n的码字中1的个数为奇数</li>
<li>偶校验：附加一个校验元后，码长为n的码字中1的个数为偶数</li>
</ul>
<p>只能检测<strong>奇数位</strong>的出错情况，但并不知道是哪些位出错了。</p>
<p><strong>循环冗余码CRC</strong></p>
<blockquote>
<p>注：循环冗余编码是由纠错功能的，但数据链路层仅使用了它的检错功能，检测到帧出错就直接丢弃。</p>
</blockquote>
<h3 id="纠错编码"><a class="header" href="#纠错编码">纠错编码</a></h3>
<p>在发送的数据块上附加足够的冗余信息，使接收方能够推导出发送方实际送出的应该是什么样的比特。</p>
<p><strong>海明码</strong></p>
<p>在有效信息位中加入几个校验位形成海明码，并把海明码的每个二进制位分配到几个奇偶校验组中，当某一位出错后，就会引起有关的几个校验位的值发生变化，这样不但能发现错位，还能指出错位的位置，然后直接进行纠错。</p>
<p>以数据码1010为例讲述海明码的编码原理：</p>
<ul>
<li>确定海明码的位数：</li>
</ul>
<p>设n为有效信息位数，k为校验位的位数，则n和k应该满足：
$$
n+k\leq 2^k -1 
$$
海明码位数为$n+k=7\leq 2^3-1$成立，则n、k有效。设信息位为$D_4D_3D_2D_1$（1010），校验位为$P_1P_2P_3$，共三位，对应的海明码为$H_7H_6H_5H_4H_3H_2H_1$。</p>
<ul>
<li>确定校验位的分布</li>
</ul>
<p>规定校验位$P_i$在海明位号为$2^{i-1}$的位置上，其余各位为信息位：</p>
<p>$P_1$的海明位号为1，即$H_1$为$P_1$；</p>
<p>$P_2$的海明位号为2，即$H_2$为$P_2$；</p>
<p>$P_3$的海明位号为4，即$H_4$为$P_3$；</p>
<p>将信息位按照原来的顺序插入，则分布如下：</p>
<ul>
<li>分组以形成校验关系</li>
</ul>
<p>每个数据位用多个校验位进行校验，但要满足：被校验<strong>数据位的海明位号</strong>等于校验该数据位的各<strong>校验位的海明位号之和</strong>。</p>
<p><img src="https://raw.githubusercontent.com/eternityqjl/blogGallery/master/%E6%B5%B7%E6%98%8E%E7%A0%81%E6%A0%A1%E9%AA%8C%E5%88%86%E7%BB%84.jpg" alt="" /></p>
<ul>
<li>校验位取值</li>
</ul>
<p>校验位$P_i$的值为第i组所有位（由该校验位校验的所有数据为）的异或：
$$
P_1=D_1\oplus D_2\oplus D_4 = 0 \
P_2=D_1\oplus D_3\oplus D_4 = 1 \
P_3=D_2\oplus D_3\oplus D_4 = 0 \
$$
所以1010对应的海明码为1010010</p>
<ul>
<li>海明码的校验原理：</li>
</ul>
<p>每个校验组分别利用校验位和参与形成该校验位的信息位进行奇偶校验检查，构成k各校验方程：
$$
S_1=P_1\oplus D_1\oplus D_2\oplus D_4 \
S_2=P_2\oplus D_1\oplus D_3\oplus D_4 \
S_3=P_3\oplus D_2\oplus D_3\oplus D_4 \
$$
若$S_1S_2S_3$的值为000，则说明无错；否则说明出错，这个数就是错误的位号，如$S_1S_2S_3=001$，说明第一位出错，直接将该位取反就可以纠错。</p>
<h2 id="流量控制与可靠传输机制"><a class="header" href="#流量控制与可靠传输机制">流量控制与可靠传输机制</a></h2>
<h3 id="流量控制可靠传输与滑动窗口机制"><a class="header" href="#流量控制可靠传输与滑动窗口机制">流量控制、可靠传输与滑动窗口机制</a></h3>
<p>流量控制涉及对链路上帧的发送速率的控制，使得接收方有足够的缓冲空间来接受每个帧。</p>
<p>流量控制的基本方法是由<strong>接收方</strong>控制发送方发送数据的速率，常见方式有：停止-等待协议、滑动窗口协议。</p>
<p><strong>停止-等待协议</strong></p>
<p>发送方每发送一帧，都要等待接收方的应答信号，之后才能发送下一帧；接收方每接受一帧，都要反馈一个应答信号，表示可接受下一帧，如果接收方不反馈，发送方就要一直等待下去。传输效率很低。</p>
<p><strong>滑动窗口基本原理</strong></p>
<p>任意时刻，发送方维持一组连续的允许发送的帧的序号，称为发送窗口；接收方也维持一组连续的允许接收帧的序号，称为接收窗口。发送窗口用来对发送方进行流量控制，发送窗口的大小$W_T$代表在还未收到对方确认信息的情况下发送方最多还能发送多少个数据帧。在接收方，只有收到的数据帧的序号落入接收窗口内时，才允许将该帧收下，若接收到的数据帧落在接收窗口外，则将其丢弃。</p>
<p><strong>可靠传输机制</strong></p>
<p>数据链路层的可靠传输常使用<strong>确认</strong>和<strong>超时重传</strong>两种机制完成。</p>
<p>确认是一种无数据的控制帧，这种控制帧使得接收方让发送方知道哪些内容被正确接受，有时为了提高传输效率，将确认捎带在一个回复帧中。</p>
<p>超时重传是指发送方在发送完一个帧后就启动一个<strong>定时器</strong>，在一定时间内如果没有得到发送的数据帧的确认帧，就重新发送该数据帧，直到发送成功为止。</p>
<p>自动重传请求ARQ通过接收方请求发送方发送出错的数据帧来恢复出错的帧。ARQ分为三种：停止-等待ARQ、后退N帧ARQ、选择性重传ARQ。后两种协议是滑动窗口技术和ARQ技术的结合。</p>
<p>数据链路层中流量控制机制和可靠传输机制是交织在一起的。</p>
<blockquote>
<p>注：现有的实际有线网络很少采用可靠传输，大多数教材把这部分内容放在第5章讨论，这里按照408考纲。</p>
</blockquote>
<h3 id="单帧滑动窗口与停止-等待协议"><a class="header" href="#单帧滑动窗口与停止-等待协议">单帧滑动窗口与停止-等待协议</a></h3>
<p>停止-等待协议相当于<strong>发送窗口和接收窗口大小均为1</strong>的滑动窗口协议。</p>
<p>该协议中，除了数据帧丢失外，还可能存在以下差错：</p>
<ul>
<li>到达目的站的帧已遭到破坏，接收方将该帧丢弃。源站配备了计时器，计时器满且未收到确认时就重传该帧。</li>
<li>数据帧正确传输而确认帧遭到破坏。发送方会重传该帧，接收方丢弃收到的同样的数据帧，并重传一个该帧的确认帧。</li>
</ul>
<p>该种协议的信道利用率很低。</p>
<h3 id="多帧滑动窗口与后退n帧协议gbn"><a class="header" href="#多帧滑动窗口与后退n帧协议gbn">多帧滑动窗口与后退N帧协议（GBN）</a></h3>
<p>发送方可以连续的发送帧。当接收方检测到失序的信息帧后，要求发送方重发最后一个正确接收的信息帧之后的所有未被确认的帧。</p>
<p>即相当于接收方只允许<strong>按顺序</strong>接收帧。</p>
<p>后退N帧协议的<strong>接收窗口为1</strong>，可以保证<strong>按序</strong>接收数据帧。若采用n比特对帧编号，则其发送窗口的尺寸$W_T$应满足$1\leq W_T\leq 2^n-1$，若发送窗口的尺寸大于$2^n-1$，则会造成接收方无法分辨新帧和旧帧。</p>
<p>这种协议提高了信道利用率但重传时会把原来已经传送正确的数据帧进行重传，这种方式又降低了效率。</p>
<p>当信道的传输质量很差导致误码率较大时，后退N帧协议不一定优于停止-等待协议。</p>
<h3 id="多帧滑动窗口与选择重传协议sr"><a class="header" href="#多帧滑动窗口与选择重传协议sr">多帧滑动窗口与选择重传协议（SR）</a></h3>
<p>为了进一步提高信道的利用率，可以设法<strong>只重传出现差错的数据帧或计时器超时的数据帧</strong>。此时必须加大接收窗口，以便先收下发送序号不连续但仍处在接收窗口中的那些数据。这就是<strong>选择重传ARQ</strong>。</p>
<p>一般情况下，SR协议的接收窗口和发送窗口的<strong>大小是相同</strong>的。</p>
<p><strong>信道效率（信道利用率）</strong>：从时间角度的定义，是对发送方而言的，指发送方在<strong>一个发送周期的时间内</strong>，有效地发送数据所占的时间占整个发送周期地比率。</p>
<p><strong>信道吞吐率</strong>=信道利用率*发送方地发送速率</p>
<h2 id="介质访问控制mac"><a class="header" href="#介质访问控制mac">介质访问控制MAC</a></h2>
<p>为使用介质的每个结点<strong>隔离来自同一信道上其他结点所传送的信号</strong>，以协调活动结点的传输。用来决定广播信道中<strong>信道分配</strong>的协议属于数据链路层的一个子层，成为MAC子层。</p>
<p>采取一定的措施，使得两对结点之间的通信不会发生互相干扰的情况。</p>
<p>常见的介质访问控制方法有：</p>
<ul>
<li>静态划分信道：
<ul>
<li>信道划分介质访问控制</li>
</ul>
</li>
<li>动态分配信道：
<ul>
<li>随机访问介质访问控制</li>
<li>轮询访问介质访问控制</li>
</ul>
</li>
</ul>
<h3 id="信道划分"><a class="header" href="#信道划分">信道划分</a></h3>
<p>多路复用技术：通过在一条介质上同时携带<strong>多个传输信号</strong>的方法提高传输系统的利用率。多路复用技术把多个信号组合在一条物理链路中进行传输，提高了信道利用率。</p>
<p>信道划分的实质就是通过<strong>分时、分频、分码等</strong>方法把原来的一条广播信道在逻辑上划分为多条两个结点之间通信互不干扰的子信道。</p>
<p><strong>频分多路复用FDM</strong></p>
<p>将多路基带信号调制到不同频率的载波上，再叠加形成一个符合信号的多路复用技术。可将物理信道的总带宽分割成若干与传输信号带宽相同的子信道，每个子信道传输一种信号。</p>
<p>每个子信道分配的带宽可以不同，但总和不能超过物理信道总带宽。为了防止子信道之间的干扰，相邻信道之间需要加入保护频带。</p>
<blockquote>
<p>数字信号中，带宽是指单位时间内链路能够通过的数据量。是波特率的俗称，波特率是系统传输数据的速度；即表示信道容量。</p>
</blockquote>
<p><strong>时分多路复用TDM</strong></p>
<p>将一条物理信道按照时间划分为<strong>若干时间片</strong>，轮流地分配给多个信号使用。每个时间片由复用的一个信号占用，不像FDM那样同一时间同时发送多路信号。利用每个信号在时间上的交叉，就可以在一条物理信道上传输多个信号。</p>
<p>统计时分多路复用STDM是TDM的一种改进，采用STDM帧，并不固定分配时隙，而是按需动态分配时隙，只有终端有数据传送时才会分配到时间片，这样可以提高线路的利用率。</p>
<p><strong>波分多路复用WDM</strong></p>
<p>即<strong>光的频分多路复用</strong>，是在一根光纤中传输多种不同波长（频率）的光信号，由于波长不同，各路光信号互不干扰，最后再用波长分解复用器将各路波长分解出来。</p>
<p>光波处于频谱的高频段，有很高的带宽。</p>
<p><strong>码分多路复用CDM</strong>
采用不同的编码来区分各路原始信号。与TDM和FDM不同，它既共享了信道频率，又共享了时间。</p>
<p>更常用的名称是<strong>码分多址CDMA</strong>，原理是将每个比特时间再划分为m个短的时间槽，称为码片，通常m值为64或128.每个站点（终端）被指派一个唯一的m位码片序列，发送1时，站点发送它的<strong>码片序列</strong>；发送0时，站点发送该<strong>码片序列的反码</strong>。当两个或多个站点同时发送时，各路数据在信道中<strong>线性相加</strong>；为从信道中分理出各路信号，要求各个站点的码片序列<strong>相互正交</strong>。</p>
<p>主要用于移动通信系统，例如3G时代的CDMA网络。</p>
<h3 id="随机访问"><a class="header" href="#随机访问">随机访问</a></h3>
<p>随机访问介质控制协议中，不采用集中控制方式解决发送信息的次序问题，所有用户能根据自己的意愿随机地发送信息，占用全部信道速率。</p>
<p>为了解决随机接入发生的碰撞，每个用户需要按照一定的规则<strong>反复地重传</strong>它的帧，直到该帧无碰撞地通过。核心思想是：胜利者通过争用获得信道，从而获得信息的发送权。</p>
<p>随机介质访问控制实质上是一种将<strong>广播信道</strong>转化为<strong>点到点信道</strong>的行为。</p>
<p><strong>ALOHA协议</strong></p>
<p>夏威夷大学早期研制的随机接入系统，是Additive Link On-line HAwaii system的缩写，分为<strong>纯ALOHA</strong>协议和<strong>时隙ALOHA</strong>协议。</p>
<ol>
<li><strong>纯ALOHA协议</strong></li>
</ol>
<p>基本思想是：当网络中任何一个站点需要发送数据时，可以<strong>不进行任何检测</strong>就发送数据，如果在一段时间内未收到确认，那么该站点就认为传输过程中发生了冲突。发送站点需要等待一段时间后再发送数据，直到发送成功。</p>
<p>当碰撞发生后，碰撞双方（也可以是多方）所发送的数据出现了差错，因而都需要进行重传，但各站不能马上重传；这里采用的重传策略是等待一段<strong>随机的时间</strong>，然后进行重传，若再次发生碰撞，则需再等待一段随机的时间，直到重传成功。</p>
<p>纯ALOHA网络的吞吐量很低，为了克服这一缺点，在原始纯ALOHA的基础上改进产生了时隙ALOHA协议。</p>
<ol start="2">
<li><strong>时隙ALOHA协议</strong></li>
</ol>
<p>该协议把各站在时间上<strong>同步</strong>起来，并将时间划分为一段段等长的时隙（Slot），规定只能在<strong>每个时隙的开始</strong>时才能发送一帧。这样避免了用户发送数据的随意性，减少了数据冲突的可能性，提高了信道利用率。</p>
<p>时隙的长度$T_0$使得每个帧正好在一个时隙内发送完毕。每个帧到达后，一般要在缓存中等待一段小于$T_0$的时间，然后才能发送出去。发生碰撞后的重传策略与纯ALOHA相同。</p>
<p>时隙ALOHA的吞吐量相比于纯ALOHA网络提升了一倍。</p>
<p><strong>CSMA协议</strong></p>
<p><strong>载波侦听多路访问</strong>协议。ALOHA协议中每个站点都是随心所欲地发送数据，即使其他站点正在发送也照发不误，因此发生碰撞的概率仍然很大。</p>
<p>CSMA的思想是：每个站点在<strong>发送前都先侦听</strong>一下共用信道，发现信道空闲后再发送，会大大降低冲突的可能，提高信道利用率。这相当于在ALOHA协议上提出的一种改进，多了一个载波侦听装置。</p>
<p>根据侦听方式和侦听到信道忙后的处理方式不同分为：</p>
<ol>
<li><strong>1-坚持 CSMA</strong></li>
</ol>
<p>1-persistent CSMA，一个节点要发送数据时，先侦听信道，如果空闲则<strong>立即发送</strong>；如果信道忙，则等待，同时<strong>继续侦听直到信道空闲</strong>；如果发生冲突，则随机等待一段时间后再重新开始侦听信道。</p>
<p>1-坚持的含义是：侦听到信道空闲后，发送帧的概率为1，既立即发送。</p>
<p>另外，<strong>传播时延</strong>对1-坚持CSMA的性能影响较大，结点A发送数据时，可能还未发送到结点B，结点B也要发送数据，侦听到信道空闲，立即发送数据，结果必然导致冲突。</p>
<ol start="2">
<li><strong>非坚持 CSMA</strong></li>
</ol>
<p>基本思想是：一个结点要发送数据，首先侦听信道；如果空闲，<strong>立即发送数据</strong>；如果信道忙，<strong>放弃侦听，等待一个随机时间后</strong>再重复上述过程。</p>
<p>非坚持CSMA在侦听到信道忙后就放弃了侦听，降低了多个结点等待信道空闲后同时发送数据导致冲突的概率，但会增加数据传送的时延。</p>
<ol start="3">
<li><strong>p-坚持 CSMA</strong></li>
</ol>
<p>用于时分信道。基本思想：一个结点要发送数据，首先侦听信道；如果信道忙就<strong>持续侦听</strong>，直到信道空闲；如果信道空闲，<strong>以概率p发送数据</strong>，以概率1-p推迟到下一个时隙；如果下一个时隙信道仍然空闲，仍以概率p发送数据，以概率1-p推迟到下一个时隙。这个过程一直持续到数据发送成功或检测到信道繁忙为止。</p>
<p>这样的方法能降低多个结点检测到信道空闲后同时发送数据的冲突概率；采取侦听是为了克服非坚持CSMA协议中由于随机等待而造成延迟时间较长的缺点。</p>
<p><strong>CSMA/CD协议</strong></p>
<p>载波侦听多路访问/<strong>碰撞检测</strong>(Collision Detection)协议是CSMA协议的改进方案，适用于总线型网络或半双工网络。一般用于<strong>有线局域网</strong>，如以太网Ethernet。</p>
<p>载波侦听就是发送前侦听总线上是否有其他数据在发送，如果有就暂时不发送，等到信道空闲再发送。碰撞检测就是<strong>边发送边侦听</strong>，适配器一边发送数据一边检测信道上信号电压的变化情况。</p>
<p>CSMA/CD的工作流程概括为：<strong>先听后发，边听边发，冲突停发，随机重发</strong>。具体工作流程如下：</p>
<ul>
<li>适配器从网络层获得一个分组，封装成以太网帧，放入适配器缓存，准备发送。</li>
<li>适配器侦听到信道空闲，开始发送该帧；如果侦听到信道忙，则持续侦听到信道上没有信号能量，然后发送帧。</li>
<li>发送过程中，适配器持续检测信道，如果一直未检测到碰撞，则成功发送完毕；如果检测到碰撞，则中止发送数据，并发送一个拥塞信号，让所有用户都知道。</li>
<li>中止发送后，适配器执行<strong>指数退避算法</strong>，等待一段随机时间后返回第二步。</li>
</ul>
<p>CSMA/CD中的站不可能同时进行发送和接收，因此采用该协议的以太网只能进行<strong>半双工通信</strong>。</p>
<blockquote>
<p>半双工（half-duplex）：允许两台设备之间双向传输数据，但不能同时进行。</p>
<p>全双工（full-duplex）：允许两台设备同时进行双向传输。</p>
</blockquote>
<p>把以太网端到端往返时间$2\tau$称为<strong>争用期</strong>（又称冲突窗口或碰撞窗口），每个站在发送数据后，经过争用期这段时间后还未检测到碰撞，则确定这次发送不会碰撞。</p>
<p>为了确保发送站在发送数据的同时能检测到可能存在的碰撞，需要在发送完帧之前就能收到自己发送出去的数据，即帧的传输时延至少要两倍于信号在总线中的传播时延，所以CSMA/CD总线网中所有数据帧都要大于一个<strong>最小帧长</strong>：</p>
<p><strong>最小帧长=总线传播时延*数据传输速率*2</strong></p>
<p>如果发生冲突，则一定在最小帧长发送的时间范围内，以太网中凡是小于最小帧长的帧都被判定为无效帧，收到这种帧时要立即丢弃。</p>
<p>除了检测冲突外，CSMA/CD还能从冲突中恢复，一旦发生冲突，再次立即发送是没有意义的。这里采用<strong>二进制指数退避算法</strong>来解决碰撞问题：</p>
<ul>
<li>确定基本退避时间，一般取争用期时间$2\tau$</li>
<li>定义参数k，它等于重传次数，但不超过10，即$k=\min [重传次数, 10]$，当重传次数不超过10，k为重传次数；当重传次数大于10时，k就不再增加，一直等于10</li>
<li>从离散整数集合$[0,1,...,2^k-1]$中随机取出一个数r，重传所需的退避时间就是r倍的基本退避时间，即$2r\tau$</li>
<li>当重传达到16次仍然不能成功，说明<strong>网络太拥挤</strong>，认为此帧<strong>永远无法正确发出</strong>，抛弃此帧并<strong>向高层报告</strong>。</li>
</ul>
<p>该方法能够使重传所需的推迟的平均时间随着重传次数的增大而增大，能够降低发生碰撞的概率，利于系统稳定。</p>
<p><strong>CSMA/CA协议</strong></p>
<p>载波侦听多路访问/<strong>碰撞避免</strong>(Collision Avoidance)协议，用于无线局域网802.11。</p>
<p>CSMA/CD把碰撞检测改为了<strong>碰撞避免</strong>，指的是设计者要尽量降低发生碰撞的概率。相比于CSMA/CA作出这样的修改主要有以下原因：</p>
<ul>
<li>无线网络接收信号的强度往往小于发送信号的强度，且在无线介质上信号强度的动态变化范围很大，<strong>实现碰撞检测的代价较大</strong>。</li>
<li>无线通信中，并非所有站点都能听见对方，存在<strong>隐蔽站</strong>问题。</li>
</ul>
<p>无线信道的质量远不如有线通信，802.11使用链路层<strong>确认/重传(ARQ)方案</strong>，站点每次通过无线局域网发送完一帧，都要在收到对方的确认帧后才能发送下一帧。</p>
<p>为避免碰撞，802.11规定所有站发送完成后，必须再等待一段很短的时间（继续监听）才能发送下一帧，这段时间称为<strong>帧间间隔IFS</strong>，长短取决于要发送帧的类型。802.11使用以下三种IFS：</p>
<ul>
<li>SIFS（短IFS）：用于<strong>分隔属于一次对话的各帧</strong>，使用SIFS的帧类型有：ACK帧、CTS帧、分片后的数据帧、回答AP探询的帧</li>
<li>PIFS（点协调IFS）：中等长度的IFS，在<strong>PCF操作</strong>中使用</li>
<li>DIFS（分布式协调IFS）：最长的IFS，用于<strong>异步帧竞争访问</strong>的时延</li>
</ul>
<p>CSMA/CA的退避算法与CSMA/CD的稍有不同。信道从忙态变为空闲时，任何一个站都要发送数据帧，不仅都要等待一个时间间隔，而且要进入争用窗口，计算随机退避时间以便再次试图接入信道，降低了碰撞发生的概率。</p>
<p>当且仅当检测到信道空闲并且这个数据帧是要发送的第一个数据帧时，才不使用退避算法。其他情况都要使用退避算法。具体为：发送第一个帧前检测到信道忙；每次重传；每次发送成功后发送下一个帧。</p>
<p>另：<strong>处理隐蔽站问题：RTS和CTS</strong></p>
<p>两个站A和B都在AP的覆盖范围内，但二者相距较远，彼此听不到对方。当A和B都检测到信道冲突时，都向AP发送数据，导致发生碰撞，这就是隐蔽站问题。</p>
<p>为了避免该问题，802.11允许发送站<strong>对信道进行预约</strong>，源站发送数据帧前先广播一个<strong>短请求发送RTS控制帧</strong>，其中包括源地址、目的地址和这个通信所持续的时间，该帧能被范围内包括AP在内的所有站点听到。如果信道空闲，则AP广播一个<strong>允许发送CTS控制帧</strong>，其中包括从RTS帧复制的通信所需时间，该帧也能发送到包括A和B在内的所有站点。B和其他站点听到CTS后，在CTS帧指明的时间范围内将<strong>抑制发送</strong>。CTS帧有两个目的：给源站明确发送的许可；指示其他站点在预约期内不要发送。</p>
<p>这种机制绘制的网络效率有所下降，但这两种帧都很短，与数据帧相比开销不大；如果不使用这种帧，一旦发生碰撞则导致帧重发，浪费的时间更多。</p>
<h3 id="轮询访问令牌传递协议"><a class="header" href="#轮询访问令牌传递协议">轮询访问：令牌传递协议</a></h3>
<p>轮询访问中，用户不能随机地发送信息，要通过一个集中控制的监控站，以循环方式轮询每个结点，再决定信道的分配。当某个结点在使用信道时，其他结点都不能使用信道。令牌传递协议主要用于<strong>令牌环局域网</strong>中。</p>
<p>一个令牌在各结点间以某个固定次序交换。</p>
<p>该协议适合<strong>负载很高</strong>的广播信道，即多个结点在同一时刻发送数据概率很大的信道。</p>
<h2 id="局域网"><a class="header" href="#局域网">局域网</a></h2>
<h3 id="体系结构"><a class="header" href="#体系结构">体系结构</a></h3>
<p>在一个较小范围内（例如一个学校）通过双绞线等介质把计算机、外部设备等连接起来，组成互联网络。</p>
<p>局域网的特性主要由：拓扑结构、传输介质、介质访问控制方式组成。</p>
<ul>
<li>常见拓扑：星形、环形、总线形、星形和总线形混合</li>
<li>传输介质：双绞线、铜缆、光纤</li>
<li>介质访问控制：CSMA/CD、令牌总线、令牌环</li>
</ul>
<h3 id="以太网和8023"><a class="header" href="#以太网和8023">以太网和802.3</a></h3>
<p>以太网采用<strong>总线形</strong>拓扑，所有计算机共享一条总线，信息以广播方式发送。以太网简化了通信流程并使用CSMA/CD方式进行访问控制。</p>
<p>简化通信的措施：</p>
<ul>
<li>采用无连接的工作方式，不对数据帧进行编码，不要求接收方发送确认，尽最大努力交付，提供不可靠服务，对于差错纠正由高层完成</li>
<li>发送的数据使用曼彻斯特编码，每个码元的中间出现一次电压转换，接收端利用这种方式能很快地提取出位同步信号。</li>
</ul>
<blockquote>
<p>曼彻斯特编码：从高电平到低电平的跳变代表1，而从低电平到高电平的跳变代表0。信号的保持不会超过一个比特位的时间间隔。即使是0或1的序列，信号也将在每个时间间隔的中间发生跳变。这种跳变将允许接收设备的时钟与发送设备的时钟保持一致。</p>
</blockquote>
<p><strong>以太网传输介质与网卡</strong></p>
<p>常用传输介质：粗缆、细缆、双绞线和光纤</p>
<table><thead><tr><th align="center">参数</th><th align="center">10BASE5</th><th align="center">10BASE2</th><th align="center">10BASE-T</th><th align="center">10BASE-FL</th></tr></thead><tbody>
<tr><td align="center">传输媒体</td><td align="center">粗缆</td><td align="center">细缆</td><td align="center">非屏蔽双绞线</td><td align="center">光纤对</td></tr>
<tr><td align="center">编码</td><td align="center">曼彻斯特编码</td><td align="center">曼彻斯特编码</td><td align="center">曼彻斯特编码</td><td align="center">曼彻斯特编码</td></tr>
<tr><td align="center">拓扑结构</td><td align="center">总线形</td><td align="center">总线形</td><td align="center">星形</td><td align="center">点对点</td></tr>
<tr><td align="center">最大段长</td><td align="center">500m</td><td align="center">185m</td><td align="center">100m</td><td align="center">2000m</td></tr>
<tr><td align="center">最多结点数目</td><td align="center">100</td><td align="center">30</td><td align="center">2</td><td align="center">2</td></tr>
</tbody></table>
<p>计算机与外界局域网通过网卡（适配器）相连，每个适配器都有唯一的MAC地址。</p>
<p><strong>MAC帧</strong></p>
<p>长6字节，由分隔的12个十六进制数组成。</p>
<p>以太网帧格式有Ethernet V2和802.3两种。这里介绍V2：</p>
<p><strong>高速以太网</strong></p>
<h3 id="ieee-80211"><a class="header" href="#ieee-80211">IEEE 802.11</a></h3>
<p>无线局域网可分为两类：有固定基础设施无线局域网和无固定设施移动自组织网络。固定设施指固定的基站。</p>
<h3 id="令牌环网"><a class="header" href="#令牌环网">令牌环网</a></h3>
<p>令牌环网的每一站通过电缆与环接口干线耦合器TCU相连。TCU的主要作用是传递所有经过的帧，为接入站发送和接收数据提供接口。与此对应的TCU的状态也有两个：收听状态和发送状态。</p>
<h2 id="广域网"><a class="header" href="#广域网">广域网</a></h2>
<h3 id="基本概念-13"><a class="header" href="#基本概念-13">基本概念</a></h3>
<p>覆盖范围很广（远超一个城市的范围）的长距离网络。连接广域网的各结点交换机的链路都是高速链路，它可以是长达几千公里的光缆线路，也可以是长达几万米的点对点卫星链路。广域网首要考虑的问题是通信容量足够大。</p>
<p>广域网由一些结点交换机及连接这些交换机的链路组成。结点交换机的功能是将分组存储并转发。结点之间都是点到点连接。为了提高可靠性，通过一个结点交换机与多个结点交换机连接。</p>
<p>广域网使用的协议主要在网络层。</p>
<h3 id="ppp协议"><a class="header" href="#ppp协议">PPP协议</a></h3>
<p>Point-to-Point Protocal，是使用串行线路通信的<strong>面向字节</strong>的而协议，该协议应用在直接连接的两个结点的链路上。</p>
<h3 id="hdlc协议"><a class="header" href="#hdlc协议">HDLC协议</a></h3>
<p>高级数据链路控制协议（High-level Data Link Control）是ISO制定的<strong>面向比特</strong>的数据链路层协议。该协议不依赖于任何一种字符编码集；数据报文可透明传输，用于透明传输的<strong>0比特插入法</strong>易于硬件实现。</p>
<h2 id="数据链路层设备"><a class="header" href="#数据链路层设备">数据链路层设备</a></h2>
<h3 id="以太网交换机"><a class="header" href="#以太网交换机">以太网交换机</a></h3>
<p>是一个多端口的网桥，工作在数据链路层。交换机能经济地将网络分成小的冲突域，为每个工作站提供更高的带宽。</p>
<p>以太网交换机还能方便地实现虚拟局域网VLAN，VLAN不仅能隔离冲突域，还能隔离广播域。</p>
<p><strong>原理</strong></p>
<p>检测从以太端口来的源和目的地的MAC地址，然后与系统内的动态查找表进行比较，若数据帧的源MAC地址不在查找表中，则将该地址加入查找表，并将数据帧发送给响应目的端口。</p>
<p><strong>特点</strong></p>
<ul>
<li>每个端口直接与单台主机相连，工作在全双工。</li>
<li>以太网交换机同时连接多对端口，每对端口连接的主机都能无碰撞地传输数据。</li>
<li>是一种即插即用设备。</li>
<li>使用ASIC，交换速度快</li>
</ul>
<p><strong>两种交换模式</strong></p>
<p>直通式和存储转法式。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="网络层的功能"><a class="header" href="#网络层的功能">网络层的功能</a></h2>
<h2 id="路由算法"><a class="header" href="#路由算法">路由算法</a></h2>
<h2 id="ipv4"><a class="header" href="#ipv4">IPv4</a></h2>
<h3 id="ipv4分组"><a class="header" href="#ipv4分组">IPv4分组</a></h3>
<p><strong>IPv4分组格式</strong></p>
<p><strong>IP数据报分片</strong></p>
<p>当IP数据报的总长度大于链路层MTU时，就需要将IP数据报中的数据分装在两个或多个较小的IP数据报中，这些较小的数据报称为片。</p>
<p>片在目的地网络层被重新组装。目的主机使用IP首部中的<strong>标识、标志和片偏移</strong>字段完成对片的重组。</p>
<h3 id="ipv4地址与nat"><a class="header" href="#ipv4地址与nat">IPv4地址与NAT</a></h3>
<p>私有IP地址网段：</p>
<ul>
<li>A类：1个，10.0.0.0~10.255.255.255</li>
<li>B类：16个，172.16.0.0~172.31.255.255</li>
<li>C类：256个，192.168.0.0~192.168.255.255</li>
</ul>
<h3 id="子网划分与子网掩码cidr"><a class="header" href="#子网划分与子网掩码cidr">子网划分与子网掩码、CIDR</a></h3>
<h3 id="arpdhcp与icmp"><a class="header" href="#arpdhcp与icmp">ARP、DHCP与ICMP</a></h3>
<p><strong>地址解析协议ARP</strong></p>
<p>完成从IP地址到MAC地址的映射。每台主机上都有一个ARP高速缓存，用来存放局域网内各主机和路由器到MAC地址的映射表，称为ARP表。</p>
<p>ARP表工作在网络层。</p>
<p><strong>动态主机配置协议DHCP</strong></p>
<p>DHCP是应用层协议，基于UDP。</p>
<p>该协议用于给主机动态地分配IP地址，提供了即插即用的联网机制。</p>
<p>工作原理：使用客户/服务器模式。需要IP的主机在启用时向DHCP服务器广播发送发现报文，这时主机成为DHCP客户。本地网络上所有主机都能收到此广播报文，但只有DHCP服务器才能回答该报文。DHCP服务器先从其数据库中找到该计算机的配置信息，若找到，则返回找到的信息。若找不到则从IP池中去一个地址分配给该计算机。</p>
<p><strong>网际控制报文协议ICMP</strong></p>
<p>在网络层采用该协议来让主机或路由器<strong>报告差错和异常情况</strong>。</p>
<p>ICMP报文作为IP层数据报的数据，加上数据报的首部，组成IP数据报发送出去。</p>
<ul>
<li>
<p>ICMP差错报文（用于目的主机或到目的主机路径上的路由器向源主机报告差错和异常）</p>
<ul>
<li>终点不可达</li>
<li>源点抑制</li>
<li>时间超过</li>
<li>参数问题</li>
<li>改变路由（重定向）</li>
</ul>
</li>
<li>
<p>ICMP询问报文</p>
<ul>
<li>回送请求和回答报文</li>
<li>时间戳请求和回答报文</li>
<li>地址掩码请求和回答报文</li>
<li>路由器询问和通告报文</li>
</ul>
</li>
</ul>
<p>ICMP最常用的应用是分组网间探测PING和Traceroute。</p>
<h2 id="ipv6"><a class="header" href="#ipv6">IPv6</a></h2>
<h2 id="路由协议"><a class="header" href="#路由协议">路由协议</a></h2>
<h3 id="自治系统"><a class="header" href="#自治系统">自治系统</a></h3>
<p>自治系统（AS）：单一技术管理下的一组路由器。这些路由器使用同一种AS内部的路由选择协议。</p>
<p>一个自治系统内的所有网络都由同一个单位管辖，一个自治系统内的所有路由器都是连通的。</p>
<h3 id="域内路由与域间路由"><a class="header" href="#域内路由与域间路由">域内路由与域间路由</a></h3>
<p><strong>内部网关协议IGP</strong></p>
<p>在一个自治系统内部使用的路由选择协议，使用最多的是RIP和OSPF。</p>
<p><strong>外部网关协议EGP</strong></p>
<p>源站和目的站处于不同自治系统中时使用一种协议将信息从一个自治系统传送到另一个自治系统。使用最多的是BGP-4.</p>
<h3 id="路由信息协议rip"><a class="header" href="#路由信息协议rip">路由信息协议（RIP）</a></h3>
<p>分布式的基于<strong>距离向量</strong>的路由选择协议。</p>
<h3 id="开放最短路径优先ospf协议"><a class="header" href="#开放最短路径优先ospf协议">开放最短路径优先（OSPF）协议</a></h3>
<p>使用分布式链路状态路由算法。</p>
<p>OSPF向本自治系统内所有路由器发送信息，使用的是泛洪法。</p>
<h3 id="边界网关协议bgp"><a class="header" href="#边界网关协议bgp">边界网关协议（BGP）</a></h3>
<h2 id="ip组播"><a class="header" href="#ip组播">IP组播</a></h2>
<h3 id="组播概念"><a class="header" href="#组播概念">组播概念</a></h3>
<h3 id="ip组播地址"><a class="header" href="#ip组播地址">IP组播地址</a></h3>
<h3 id="igmp与组播路由算法"><a class="header" href="#igmp与组播路由算法">IGMP与组播路由算法</a></h3>
<h2 id="移动ip"><a class="header" href="#移动ip">移动IP</a></h2>
<h2 id="网络层设备"><a class="header" href="#网络层设备">网络层设备</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="传输层提供的服务"><a class="header" href="#传输层提供的服务">传输层提供的服务</a></h2>
<h2 id="udp"><a class="header" href="#udp">UDP</a></h2>
<h3 id="udp数据报"><a class="header" href="#udp数据报">UDP数据报</a></h3>
<p><strong>概述</strong></p>
<p>UDP的优点：</p>
<ul>
<li>无需建立连接</li>
<li>无连接状态</li>
<li>分组首部开销小</li>
<li>应用层能更好地控制发送的数据和发送时间。UDP没有拥塞控制。</li>
<li>UDP支持一对一、一对多、多对多的交互通信。</li>
</ul>
<p>UDP常用于一次性传输较少数据的网络应用。</p>
<p><strong>首部格式</strong></p>
<p>UDP的首部长度为8B。由4个字段组成，每个字段的长度都是2B：</p>
<ul>
<li>源端口：源端口号。不需要时可以全0。</li>
<li>目的端口：目的端口号。终点交付报文时用到。</li>
<li>长度：UDP数据报的长度（包括首部和数据），所以最小长度为8</li>
<li>校验和：检测UDP数据报在传输时是否有错。该字段可选，源主机不想校验时令该字段为全0.</li>
</ul>
<h3 id="udp校验"><a class="header" href="#udp校验">UDP校验</a></h3>
<h2 id="tcp"><a class="header" href="#tcp">TCP</a></h2>
<h3 id="协议特点"><a class="header" href="#协议特点">协议特点</a></h3>
<ul>
<li>面向连接</li>
<li>每条TCP连接只能有两个端点，即点对点连接</li>
<li>TCP提供可靠交付，保证传送的数据无差错、不丢失、不重复且有序</li>
<li>TCP提供全双工通信，连接的两端都有发送缓存和接收缓存</li>
<li>TCP是面向字节流的，即把应用程序发送的数据视为一连串的字节流</li>
</ul>
<h3 id="tcp报文段"><a class="header" href="#tcp报文段">TCP报文段</a></h3>
<p>TCP报文既可以运载数据又可以用来建立连接、释放连接和应答。</p>
<p>一个TCP报文段分为首部和数据两部分。首部是固定的20B，最后有4N字节的可选项。</p>
<ul>
<li>源端口和目的端口：各占2B</li>
<li>序号：占4B，TCP连接传输的字节流中每个字节都按顺序编号。序号字段指的是本报文段发送的数据的<strong>第一个字节的序号</strong>。</li>
<li>确认号：占4B，期望收到<strong>对方下一个报文段的第一个数据字节的序号</strong>。若确认号为N，则表示到序号N-1为止的所有数据都已正确收到</li>
<li>数据偏移：占4位，表示首部长度，单位为32位（4B），即例如该字段的值为15时，达到TCP首部的最大长度60B</li>
<li>保留：占6位，保留为今后使用，目前应置为0.</li>
<li>紧急位URG：URG=1时表示紧急指针字段有效。告诉系统此报文段有紧急数据，相当于高优先级。URG需要和紧急指针配合使用，即从数据第一个字节到紧急指针所指的字节就是紧急数据。</li>
<li>确认位ACK：当ACK=1时确认号字段才有效，为0时无效。</li>
<li>推送位PSH：接收方TCP收到PSH=1的报文段就尽快交付给应用程序，不再等到整个缓存都填满后再向上交付。</li>
<li>复位位（RST）：RST=1时表明TCP连接出现严重差错，必须释放连接，重新建立连接</li>
<li>同步位（SYN）：SYN=1时表示这是一个连接请求或连接接收报文。当SYN=1，ACK=0时是一个请求连接报文，对方若同意建立连接，则应在响应报文中使用SYN=1，ACK=1</li>
<li>终止位FIN：用来释放一个连接，当FIN=1时表示传输完成，要求释放传输连接</li>
<li>窗口：占2B，指出现在允许对方发送的数据量，因为接收方的缓存有限</li>
<li>校验和：占2B，该字段的检验范围包括首部和数据两部分。计算检验和时同样要再前面加上12B的伪首部。</li>
<li>紧急指针：占2B，指出本报文段中紧急数据共有多少字节。</li>
<li>选项：长度可变。TCP最初只规定了一种选项：最大报文段长度（MSS），MSS仅仅指出数据段的最大长度</li>
<li>填充：为了使整个首部长度是4B的整数倍</li>
</ul>
<h3 id="tcp连接管理"><a class="header" href="#tcp连接管理">TCP连接管理</a></h3>
<p><strong>三次握手建立TCP连接</strong></p>
<ul>
<li>第一步：客户机的TCP向服务器的TCP发送连接请求报文段。该报文段的同步位<strong>SYN置为1</strong>，同时选择一个初始序号seq=x。SYN报文段不能携带数据，但要消耗掉一个序号。这是客户机进入SYN-SENT同步已发送状态。</li>
<li>第二步：服务器的TCP收到连接请求后，如果同意建立连接，则向客户机发回确认，并为该TCP分配缓存和变量。在确认报文段中，<strong>SYN和ACK都置为1</strong>，确认号是ack=x+1，同时为自己选择一个初始序号seq=y。确认报文不能携带数据，但也要消耗一个序号。此时服务器进入SYN-RCVD同步收到状态。</li>
<li>第三步：客户机收到确认报文后，还要向服务器给出确认，并为该TCP连接分配缓存和变量。确认报文段的<strong>ACK置为1</strong>，确认号ack=y+1，序号seq=x+1.该报文段可以携带数据，若不携带则不消耗序号。此时TCP客户进程进入ESTABLISH已建立连接状态。</li>
</ul>
<p><strong>四次握手释放TCP连接</strong></p>
<ul>
<li>第一步：客户端TCP发送连接释放报文段，并停止发送数据，终止位<strong>FIN置为1</strong>，序号seq=u，等于之前已经传送的数据的最后一个字节的序号加1，FIN报文段即使不携带数据也要消耗一个序号。此时TCP客户机进入FIN-WAIT-1状态。</li>
<li>第二步：服务器收到连接释放报文后即发出确认，确认号ack=u+1，序号seq=v，等于前面已经传输过的数据的最后一个字节的序号加1.然后服务器进入CLOSE-WAIT状态。此时从客户机到服务器的连接就释放了，TCP连接处于半关闭状态。</li>
<li>第三步：若服务器已经没有要向客户机发送的数据，就通知TCP释放连接，此时其发出<strong>FIN=1</strong>的连接释放报文段，该报文段的序号为w（在半关闭的时候可能又传输了一些数据），还需重复上次已经发送的确认号ack=u+1.此时服务器进入LAST-ACK状态。</li>
<li>第四步：客户机收到连接释放报文段后，要发送确认。把确认报文中的<strong>确认位ACK置为1</strong>，确认号ack=w+1，序号seq=u+1。此时连接还未释放，要等到计时器的设置时间2MSL（最长报文寿命）后客户机才进入CLOSED状态。</li>
</ul>
<h3 id="tcp可靠传输"><a class="header" href="#tcp可靠传输">TCP可靠传输</a></h3>
<p><strong>序号</strong></p>
<p>序号字段用来保证数据能有序提交给应用层。序号建立在字节流之上。</p>
<p><strong>确认</strong></p>
<p>TCP首部的确认号是期望收到对方的下一个数据段的数据的第一个字节的序号。</p>
<p>发送缓冲区会继续存储那些已经发送但未收到的确认报文段，以便在需要时重传。</p>
<p>TCP默认使用累计确认，即TCP只确认数据流中至第一个丢失字节为止的字节。</p>
<p><strong>重传</strong></p>
<p>发生超时和冗余ACK时会导致重传。</p>
<ul>
<li>超时：TCP没发送一个报文段，就对该报文段设置一次计时器，如果计时器设置的时间到期还未收到确认，就重传这一报文段。TCP采用一种自适应算法来计算超时重传时间，TCP保留一个往返时间RTT的加权平均值，会随着新测量RTT样本值的变化而变化。重传时间应略大于这个加权平均值。</li>
<li>冗余ACK：超时重传存在一个问题是超时周期往往太长。发送方通常可以在超时时间发生之前通过冗余ACK检测丢包情况。冗余ACK就是再次确认某个报文段的ACK，发送方先前已经受到过该报文段的确认。当比期望序号大的失序报文段到达时，就发送一个冗余ACK，指明下一个期待字节的序号。TCP规定当发送方收到对同一个报文段的<strong>3个冗余ACK</strong>时，就认为跟在这个被确认报文段后的报文段<strong>已经丢失</strong>。</li>
</ul>
<h3 id="tcp流量控制"><a class="header" href="#tcp流量控制">TCP流量控制</a></h3>
<p>TCP提供流量控制服务来消除发送方（发送速率太快）使得接收方缓存区溢出的可能性。是一个速度匹配服务。</p>
<p>TCP提供一种基于滑动窗口协议的流量控制机制。</p>
<p>接收方根据自己接收缓存的大小，动态调整发送方的发送窗口大小，称为<strong>接收窗口rwnd</strong>。即调整TCP报文段首部中窗口字段的值来限制发送方向网络注入报文的速率。同时发送方根据当前网络拥塞程度的估计而却认定窗口值，称为<strong>拥塞窗口cwnd</strong>。</p>
<p>发送窗口的实际大小取rwnd和cwnd中较小的一个。</p>
<p>传输层和数据链路层流量控制的区别：传输层定义端到端用户之间的流量控制，数据链路层定义两个中间的相邻结点的流量控制。数据链路层的滑动窗口大小不能动态变化，而传输层可以。</p>
<h3 id="tcp拥塞控制"><a class="header" href="#tcp拥塞控制">TCP拥塞控制</a></h3>
<p>拥塞控制是让<strong>网络能够承受现有网络负荷</strong>，是一个全局性的过程，涉及所有主机、路由器。流量控制指点到点的通信量的控制，是一个<strong>端到端</strong>的问题，它所做的是抑制发送端发送数据的速率，以便使得接收端来得及接收。</p>
<p>因特网标准定义了进行拥塞控制的4种方法：慢开始、拥塞避免、快重传和快恢复。</p>
<p>发送方既要考虑接收方的接收能力，又要考虑全局网络的拥塞程度，因此TCP协议要求发送方维护两个窗口：</p>
<ul>
<li>接收窗口rwnd：接收方根据目前接收缓存的大小所许诺的最新窗口值，反映接收方的容量。由接收方根据其放在TCP首部窗口字段通知发送方。</li>
<li>拥塞窗口cwnd：发送饭根据自己估算的网络拥塞程度而设置的窗口值，反映当前网络的容量。</li>
</ul>
<p>发送窗口的上限值应该取以上两者中较小的一个。</p>
<p><strong>慢开始算法</strong></p>
<p>TCP刚建立好连接并开始发送报文段时，先令拥塞窗口cwnd=1，即一个最大报文段长度MSS。每收到<strong>一个对新报文段的确认</strong>后，将cwnd增加1.用这样的方法逐步增大发送方的cwnd，使得分组注入网络的速率更加合理。</p>
<p>此时拥塞窗口cwnd呈指数式增长，直到增大到一个规定的慢开始门限ssthresh（阈值），然后改用拥塞避免算法。</p>
<p><strong>拥塞避免算法</strong></p>
<p>拥塞避免算法让拥塞窗口cwnd缓慢增加，没经过一个往返时延RTT就把发送方的拥塞窗口cwnd加1，使得拥塞窗口按线性规律增加。这比满开始算法的增长速率慢得多。</p>
<p><strong>网络拥塞处理</strong></p>
<p>无论在慢开始阶段还是拥塞避免阶段，只要发送方判断网络出现拥塞，就要把慢开始门限ssthresh设置为出现拥塞时的发送方的cwnd值的一半（不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。</p>
<p>这样能够迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完。</p>
<p>窗口数量变化图见书上P223</p>
<p><strong>快重传</strong></p>
<p>是对以上的慢开始和拥塞避免算法的改进。</p>
<p>前面可靠传输中介绍的冗余ACK也用于网络拥塞的检测。当发送方连续收到3个重复的ACK报文时，直接重传对方尚未收到的报文段，不必等待那个报文段设置的重传计时器超时。</p>
<p><strong>快恢复</strong></p>
<p>与慢开始不同的是，发生拥塞后，把ssthresh值设置为此时发生方cwnd的一般，然后把cwnd值设置为慢开始门限ssthresh改变后的数值，然后执行拥塞避免（加法增大）算法。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="网络应用模型"><a class="header" href="#网络应用模型">网络应用模型</a></h2>
<h3 id="客户服务器模型"><a class="header" href="#客户服务器模型">客户/服务器模型</a></h3>
<p>服务器处于接受请求的状态、客户机发出服务请求，等待接收结果。</p>
<p>常见该模型的应用由Web、文件传输协议FTP、远程登陆、电子邮件。</p>
<h3 id="p2p模型"><a class="header" href="#p2p模型">P2P模型</a></h3>
<p>P2P的思想是整个网络中的传输内容不再被保留在中心服务器上，每个结点都同时有上传、下载功能。</p>
<p>任意一对计算机——称为对等方，直接相互通信。本质上看P2P仍然是客户/服务器模型。</p>
<p>相比于C/S的优点为：</p>
<ul>
<li>减轻了服务器计算压力</li>
<li>多个客户机之间可以直接共享文档</li>
<li>网络健壮性强</li>
</ul>
<p>缺点：会占用较多内存，对硬盘造成损伤。</p>
<h2 id="域名系统dns"><a class="header" href="#域名系统dns">域名系统DNS</a></h2>
<p>DNS采用客户/服务器模型，协议运行在UDP上，使用53号端口。</p>
<h3 id="层次域名空间"><a class="header" href="#层次域名空间">层次域名空间</a></h3>
<p>域名中的标号注意事项：</p>
<ul>
<li>除连字符-外不能使用其他标点符号</li>
<li>每个标号不超过63个字符，多标号组成的完整域名不超过255个字符</li>
</ul>
<p>顶级域名分为：</p>
<ul>
<li>国家顶级域名</li>
<li>通用等级域名</li>
<li>基础结构域名：这种顶级域名只有一个，即arpa，用于反向域名解析。</li>
</ul>
<h3 id="域名服务器"><a class="header" href="#域名服务器">域名服务器</a></h3>
<p>域名服务器被设计成一个联机分布式的数据库系统，采用客户/服务器模型。</p>
<p>DNS中使用了大量域名服务器，他们以层次方式组成，采用分布式涉及的DNS。</p>
<p><strong>根域名服务器</strong></p>
<p>所有顶级域名</p>
<p><strong>顶级域名服务器</strong></p>
<p>.com</p>
<p><strong>授权域名服务器</strong></p>
<p>google.com</p>
<p><strong>本地域名服务器</strong></p>
<p>许多域名的缓存</p>
<h3 id="域名解析过程"><a class="header" href="#域名解析过程">域名解析过程</a></h3>
<p>域名解析是把域名映射成IP或把IP映射成域名的过程。前者称为正向解析，后者称为反向解析。当客服端需要域名解析时，通过本机的DNS客户端构造一个DNS请求报文，以UDP数据报方式发往本地域名服务器。</p>
<p>域名解析有两种方式：递归查询和递归与迭代相结合的查询。</p>
<p>递归查询：本地域名服务器只需向根域名服务器查询一次，后面几次查询都是递归在其他几个域名服务器中进行的。这种方式给根域名服务器造成的负载过大，在实际中不使用。</p>
<p>常用迭代与递归相结合的方式。<strong>主机向本地域名服务器</strong>的查询采用<strong>递归</strong>，<strong>本地域名服务器向根域名服务器</strong>的查询采用<strong>迭代</strong>查询。</p>
<h2 id="文件传输协议ftp"><a class="header" href="#文件传输协议ftp">文件传输协议FTP</a></h2>
<h3 id="工作原理"><a class="header" href="#工作原理">工作原理</a></h3>
<p>该协议是互联网中使用最广泛的文件传输协议。FTP提供交互式的访问，允许客户指明文件类型与格式，允许文件具有存取权限。</p>
<p>FTP提供以下功能：</p>
<ul>
<li>提供各不同种类主机系统之间的文件传输能力</li>
<li>以用户权限管理的方式提供用户对远程FTP服务器上文件管理的能力</li>
<li>以匿名FTP的方式提供公用文件的共享能力</li>
</ul>
<p>FTP采用客户/服务器的工作方式，使用TCP可靠传输。一个FTP服务器进程可以为多个客户同时提供服务。FTP的服务器进程由一个主进程和若干从属进程组成，主进程负责接收新的请求，从属进程负责处理单个请求。</p>
<p>工作步骤如下：</p>
<ul>
<li>打开熟知端口21</li>
<li>等待客户进程发送连接请求</li>
<li>启动从属进程来处理客户进程发来的请求</li>
<li>回到等待状态，继续接收其他客户进程请求</li>
</ul>
<h3 id="控制连接与数据连接"><a class="header" href="#控制连接与数据连接">控制连接与数据连接</a></h3>
<p>FTP工作时候使用两个并行的TCP连接：一个是控制连接（端口号21），一个是数据连接（端口号20）。</p>
<p><strong>控制连接</strong></p>
<p>服务器监听21号端口，等待客户连接。控制连接用来传输控制信息，并且控制信息以7位ASCII格式传送。控制连接并不用来传送文件。在传输文件时还可以使用控制连接，因此控制连接在整个会话期间一直保持打开状态。</p>
<p><strong>数据连接</strong></p>
<p>数据连接有两种传送模式：</p>
<ul>
<li>
<p>主动模式PORT</p>
</li>
<li>
<p>被动模式PASV</p>
</li>
</ul>
<h2 id="电子邮件"><a class="header" href="#电子邮件">电子邮件</a></h2>
<h3 id="电子邮件系统组成结构"><a class="header" href="#电子邮件系统组成结构">电子邮件系统组成结构</a></h3>
<h3 id="电子邮件的格式与mime"><a class="header" href="#电子邮件的格式与mime">电子邮件的格式与MIME</a></h3>
<h3 id="smtp与pop3"><a class="header" href="#smtp与pop3">SMTP与POP3</a></h3>
<h2 id="万维网www"><a class="header" href="#万维网www">万维网WWW</a></h2>
<h3 id="概念与组成"><a class="header" href="#概念与组成">概念与组成</a></h3>
<p>万维网是一个分布式、联机式的信息存储空间，该空间中用一个全域<strong>统一资源定位符URL</strong>标识资源。这些资源通过HTTP协议传送给使用者，使用者通过单击URL获得资源。</p>
<p>核心内容为：</p>
<ul>
<li>URL</li>
<li>HTTP</li>
<li>HTML</li>
</ul>
<h3 id="超文本传输协议http"><a class="header" href="#超文本传输协议http">超文本传输协议HTTP</a></h3>
<p>HTTP有请求报文和响应报文两类。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
